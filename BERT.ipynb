{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b11fdb82b5a40d4a98f326fd8e4e745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_704752b443df474cb97e54aea46985bc",
              "IPY_MODEL_205d8fad8d8f49dab1dddeb150f013fd",
              "IPY_MODEL_0028f0191b6b41059542e293eaca28e7"
            ],
            "layout": "IPY_MODEL_4e19b0472efc4c36b54363de01dad668"
          }
        },
        "704752b443df474cb97e54aea46985bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb945a23753a4099bf187c0aec0ed44f",
            "placeholder": "​",
            "style": "IPY_MODEL_5bb203b9782a43a188ee15535d3d8728",
            "value": "config.json: 100%"
          }
        },
        "205d8fad8d8f49dab1dddeb150f013fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b11e90eabb948f387ead33bb9976b62",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aca66a119cd4f8f8232a6699927972d",
            "value": 570
          }
        },
        "0028f0191b6b41059542e293eaca28e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9147369bfa66476da0ce834f7db43d0f",
            "placeholder": "​",
            "style": "IPY_MODEL_ccb40f6e3a914e06880d7368a2658190",
            "value": " 570/570 [00:00&lt;00:00, 57.7kB/s]"
          }
        },
        "4e19b0472efc4c36b54363de01dad668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb945a23753a4099bf187c0aec0ed44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb203b9782a43a188ee15535d3d8728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b11e90eabb948f387ead33bb9976b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aca66a119cd4f8f8232a6699927972d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9147369bfa66476da0ce834f7db43d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb40f6e3a914e06880d7368a2658190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc179d657b848349d5cfd636c1e3e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e166cbe35215468283ce262ef205ddce",
              "IPY_MODEL_d72afe914b1c4303bbad9acac7e83a37",
              "IPY_MODEL_77b978347a48449dbef27a2efc2a3d17"
            ],
            "layout": "IPY_MODEL_135c7c3f24d54b74bae271cd06f6bb65"
          }
        },
        "e166cbe35215468283ce262ef205ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d97de5dde394f22b8ad31f919043224",
            "placeholder": "​",
            "style": "IPY_MODEL_a2dc215aa36f485090b62e57da1ee380",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d72afe914b1c4303bbad9acac7e83a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7235955c386e4d82b08a8171d567904d",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fbd8bf0586b46cd87f58dd4cfeab6da",
            "value": 48
          }
        },
        "77b978347a48449dbef27a2efc2a3d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0952a6a5ee84454b604c5e561380c72",
            "placeholder": "​",
            "style": "IPY_MODEL_fe17c8d3e334404ea3ad108194e7d143",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.66kB/s]"
          }
        },
        "135c7c3f24d54b74bae271cd06f6bb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d97de5dde394f22b8ad31f919043224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2dc215aa36f485090b62e57da1ee380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7235955c386e4d82b08a8171d567904d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fbd8bf0586b46cd87f58dd4cfeab6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0952a6a5ee84454b604c5e561380c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe17c8d3e334404ea3ad108194e7d143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca66f480062644808bbd94906d1f138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4314a384aaec4fb8b066407ed555248b",
              "IPY_MODEL_c20efaccaa4443afbf1852a7ef0b7997",
              "IPY_MODEL_1275cc93ca5445dca0227c99f355d4dc"
            ],
            "layout": "IPY_MODEL_b15f90ea390e436fb133ef2c12585fe2"
          }
        },
        "4314a384aaec4fb8b066407ed555248b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a69df3e82642cc8eee3b862c3623da",
            "placeholder": "​",
            "style": "IPY_MODEL_40fe4184e7c74ef5a7ef3c5a26ad9699",
            "value": "vocab.txt: "
          }
        },
        "c20efaccaa4443afbf1852a7ef0b7997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37174384e2b747348596b4a883b2be03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c72f28503c42aa9e64a6db86115e0c",
            "value": 1
          }
        },
        "1275cc93ca5445dca0227c99f355d4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106fc24b01f042039785cb5cffac1c73",
            "placeholder": "​",
            "style": "IPY_MODEL_27c18f1877784e80a9e7807efdf0b5da",
            "value": " 232k/? [00:00&lt;00:00, 12.1MB/s]"
          }
        },
        "b15f90ea390e436fb133ef2c12585fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a69df3e82642cc8eee3b862c3623da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40fe4184e7c74ef5a7ef3c5a26ad9699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37174384e2b747348596b4a883b2be03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "62c72f28503c42aa9e64a6db86115e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "106fc24b01f042039785cb5cffac1c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c18f1877784e80a9e7807efdf0b5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "263a24663ad94ca2a73100c92ad5802e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd2eadb2d0b4f6794f1ee1bd8535e00",
              "IPY_MODEL_035d857ab72049b982b1a136eb7d69cb",
              "IPY_MODEL_ed02f5656e064ad1908901fd1cf74f53"
            ],
            "layout": "IPY_MODEL_b64531f1ac4f44bebffe53d2f54ce6f5"
          }
        },
        "ccd2eadb2d0b4f6794f1ee1bd8535e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b1466fc8f74982ad0e9e5ff496cd02",
            "placeholder": "​",
            "style": "IPY_MODEL_41115563e3604a629491f2fa1880e7bd",
            "value": "tokenizer.json: "
          }
        },
        "035d857ab72049b982b1a136eb7d69cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9afa61177bfd4ec7aa9caf0ac79522ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3743d5cdb22f44cdb147084eb194f0bc",
            "value": 1
          }
        },
        "ed02f5656e064ad1908901fd1cf74f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70784c26fb6b42f981146269bb85b1a9",
            "placeholder": "​",
            "style": "IPY_MODEL_7ffc2791e7e248f2b0717a227f8b3b74",
            "value": " 466k/? [00:00&lt;00:00, 28.0MB/s]"
          }
        },
        "b64531f1ac4f44bebffe53d2f54ce6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b1466fc8f74982ad0e9e5ff496cd02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41115563e3604a629491f2fa1880e7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9afa61177bfd4ec7aa9caf0ac79522ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3743d5cdb22f44cdb147084eb194f0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70784c26fb6b42f981146269bb85b1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffc2791e7e248f2b0717a227f8b3b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4200b9132ff84d42975af593d332b53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_694ba1f192354a4ea0466e6ce0f12fa9",
              "IPY_MODEL_854e51b8a9f94d709075b267877af549",
              "IPY_MODEL_91ab4c7573b6499b800a7f35a5a69df9"
            ],
            "layout": "IPY_MODEL_a15d882dd38b4ed7939c5219b7baa690"
          }
        },
        "694ba1f192354a4ea0466e6ce0f12fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b91e78b5c6548769255f2046979ea78",
            "placeholder": "​",
            "style": "IPY_MODEL_22f7bce7483d49589c4174274e013b2a",
            "value": "model.safetensors: 100%"
          }
        },
        "854e51b8a9f94d709075b267877af549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e9611fa3df436bbe48f2913aea0421",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30dc69f98f18449c86fa9fa643837e81",
            "value": 440449768
          }
        },
        "91ab4c7573b6499b800a7f35a5a69df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14bbefe5baf54e20bb07c3f797f8f0a8",
            "placeholder": "​",
            "style": "IPY_MODEL_3b616c580dc54b6cb0e09f36614dd815",
            "value": " 440M/440M [00:07&lt;00:00, 60.5MB/s]"
          }
        },
        "a15d882dd38b4ed7939c5219b7baa690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b91e78b5c6548769255f2046979ea78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f7bce7483d49589c4174274e013b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e9611fa3df436bbe48f2913aea0421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dc69f98f18449c86fa9fa643837e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14bbefe5baf54e20bb07c3f797f8f0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b616c580dc54b6cb0e09f36614dd815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01b34c12ab684531b069da04bd38ece3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed8f9cc1d97e4e22a3690fac6f039f6f",
              "IPY_MODEL_28ee26adad6e4fa7bcdb9f75fbe270b5",
              "IPY_MODEL_43c6a8b3c5674fb5acabd2d21115ae90"
            ],
            "layout": "IPY_MODEL_47e95e0ca8734ddd955bf2e0450931d3"
          }
        },
        "ed8f9cc1d97e4e22a3690fac6f039f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd4eeb589fdc44e2b051939dbc91949d",
            "placeholder": "​",
            "style": "IPY_MODEL_a246f4a67af84331ab02aac791134715",
            "value": "Loading weights: 100%"
          }
        },
        "28ee26adad6e4fa7bcdb9f75fbe270b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab813acc197c419d98b1af4088051a75",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2209e4f7d16c489f904b04f86fa3f722",
            "value": 199
          }
        },
        "43c6a8b3c5674fb5acabd2d21115ae90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3667a75ee24358a071f8bc62e1764d",
            "placeholder": "​",
            "style": "IPY_MODEL_39f3f1f759394ed2987d8d0bfc106a72",
            "value": " 199/199 [00:00&lt;00:00, 589.59it/s, Materializing param=bert.pooler.dense.weight]"
          }
        },
        "47e95e0ca8734ddd955bf2e0450931d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4eeb589fdc44e2b051939dbc91949d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a246f4a67af84331ab02aac791134715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab813acc197c419d98b1af4088051a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2209e4f7d16c489f904b04f86fa3f722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac3667a75ee24358a071f8bc62e1764d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f3f1f759394ed2987d8d0bfc106a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22e5271e152e428890d102b68ea60acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ef4f0bd34bb48489a17d8401784d7bc",
              "IPY_MODEL_1e1e0d77e6a945429ec2acf340435b1d",
              "IPY_MODEL_7784e9bf37eb4beca3cb9d661773fcdc"
            ],
            "layout": "IPY_MODEL_534e1c433a8c46f4b88902f97d62c583"
          }
        },
        "5ef4f0bd34bb48489a17d8401784d7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cda448a628e41e899cdd753fa9a5f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b1fd950e1e74b40b23179198695c8e4",
            "value": "Map: 100%"
          }
        },
        "1e1e0d77e6a945429ec2acf340435b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91da17095459474faa7467a796506e3e",
            "max": 867,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd0f4a1662ce4aa29b1778996d4c7924",
            "value": 867
          }
        },
        "7784e9bf37eb4beca3cb9d661773fcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd735a53bcb49268890485366020078",
            "placeholder": "​",
            "style": "IPY_MODEL_56530b7ea63641e8b6584745acbb6d2c",
            "value": " 867/867 [01:08&lt;00:00, 12.65 examples/s]"
          }
        },
        "534e1c433a8c46f4b88902f97d62c583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cda448a628e41e899cdd753fa9a5f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1fd950e1e74b40b23179198695c8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91da17095459474faa7467a796506e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd0f4a1662ce4aa29b1778996d4c7924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dd735a53bcb49268890485366020078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56530b7ea63641e8b6584745acbb6d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c9137772fff440992f7899da331cbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db349704cfad43108e4040745e9f6b98",
              "IPY_MODEL_2ccd4c286cff4117a994d0f835f776cd",
              "IPY_MODEL_718d898431934d4da0748e454a9893da"
            ],
            "layout": "IPY_MODEL_00c95e8387bb4da09512c51a5661f24f"
          }
        },
        "db349704cfad43108e4040745e9f6b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd91960025a84084bfe4ec396195776c",
            "placeholder": "​",
            "style": "IPY_MODEL_faa69db8dd4341688b167052bc34e1c1",
            "value": "Map: 100%"
          }
        },
        "2ccd4c286cff4117a994d0f835f776cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bd088d751d54c2f8fb36618b7e922aa",
            "max": 97,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85ed2af400744119b7b595e46712a3ec",
            "value": 97
          }
        },
        "718d898431934d4da0748e454a9893da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3493f9a27744e8aaf7b4308167c645d",
            "placeholder": "​",
            "style": "IPY_MODEL_e5db58b7f309424e8178b5e2f045a29f",
            "value": " 97/97 [00:06&lt;00:00, 14.60 examples/s]"
          }
        },
        "00c95e8387bb4da09512c51a5661f24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd91960025a84084bfe4ec396195776c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa69db8dd4341688b167052bc34e1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bd088d751d54c2f8fb36618b7e922aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ed2af400744119b7b595e46712a3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3493f9a27744e8aaf7b4308167c645d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5db58b7f309424e8178b5e2f045a29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f257ea429f46cfb71fb49e5b57db0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d6312732a814f70babe00ddfeca5b1b",
              "IPY_MODEL_81352711a554447ba65a5ec6da009d42",
              "IPY_MODEL_69898a8fe490401286a57d4cf3259eba"
            ],
            "layout": "IPY_MODEL_85761e51f53b4126b24ad82ddd38bbcc"
          }
        },
        "0d6312732a814f70babe00ddfeca5b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c205abfba6249f89e9998e1f52178df",
            "placeholder": "​",
            "style": "IPY_MODEL_fc207b48240944cc961381890be21a5e",
            "value": "Loading weights: 100%"
          }
        },
        "81352711a554447ba65a5ec6da009d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e273e60f8c7e48ca810e1d6749e70bea",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32b775ef2ee94d39a78e5d666f079f9b",
            "value": 199
          }
        },
        "69898a8fe490401286a57d4cf3259eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77180ee27204ddcbc26feb109461a0b",
            "placeholder": "​",
            "style": "IPY_MODEL_634710a9278e48599f25b123feb75d05",
            "value": " 199/199 [00:00&lt;00:00, 415.67it/s, Materializing param=bert.pooler.dense.weight]"
          }
        },
        "85761e51f53b4126b24ad82ddd38bbcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c205abfba6249f89e9998e1f52178df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc207b48240944cc961381890be21a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e273e60f8c7e48ca810e1d6749e70bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b775ef2ee94d39a78e5d666f079f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e77180ee27204ddcbc26feb109461a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634710a9278e48599f25b123feb75d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "yQ5YRBXTzIlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DypgEClPiFQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4ed941-32df-4827-abd7-a964443cb4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4AK5_bBiiItL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('/content/drive/MyDrive/Project_final/arxiv_half.csv')"
      ],
      "metadata": {
        "id": "0vNFHRQuiKxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_small = df.sample(frac=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gea4EUbATxNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output_path = '/content/drive/MyDrive/Project_final/arxiv_0.2.csv'\n",
        "#df_small.to_csv(output_path, index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "0jA99UGwU_YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/arxiv_0.2.csv')"
      ],
      "metadata": {
        "id": "p_RFzUz1V47w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "jH27-8Tyywah",
        "outputId": "1c023f19-6fe8-4ebc-e8bb-e5e7f60cb373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0      Breaking Speaker Recognition with PaddingBack   \n",
              "1              Infinite-Dimensional Diffusion Models   \n",
              "2  Computational Argumentation-based Chatbots: a ...   \n",
              "3  Optimal Control of Malware Propagation in IoT ...   \n",
              "4  Reflected Schrödinger Bridge for Constrained G...   \n",
              "\n",
              "                                             authors  \\\n",
              "0               Zhe Ye,Diqun Yan,Li Dong,Kailai Shen   \n",
              "1  Jakiw Pidstrigach,Youssef Marzouk,Sebastian Re...   \n",
              "2  Federico Castagna,Nadin Kokciyan,Isabel Sassoo...   \n",
              "3  Mousa Tayseer Jafar,Lu-Xing Yang,Gang Li,Xiaof...   \n",
              "4  Wei Deng,Yu Chen,Nicole Tianjiao Yang,Hengrong...   \n",
              "\n",
              "                                            subjects  \\\n",
              "0  Cryptography and Security (cs.CR); Sound (cs.S...   \n",
              "1  Machine Learning (stat.ML); Machine Learning (...   \n",
              "2                    Artificial Intelligence (cs.AI)   \n",
              "3                  Cryptography and Security (cs.CR)   \n",
              "4  Machine Learning (stat.ML); Machine Learning (...   \n",
              "\n",
              "                              html_url  \\\n",
              "0  https://arxiv.org/html/2308.04179v2   \n",
              "1  https://arxiv.org/html/2302.10130v3   \n",
              "2  https://arxiv.org/html/2401.03454v1   \n",
              "3  https://arxiv.org/html/2401.11076v1   \n",
              "4  https://arxiv.org/html/2401.03228v1   \n",
              "\n",
              "                                           full_text  \\\n",
              "0  \\theta}(x_{i}),y_{i}), underitalic_θ start_ARG...   \n",
              "1  Infinite-Dimensional Diffusion Models \\name Ja...   \n",
              "2  In recent years, cutting-edge technologies hav...   \n",
              "3  prefix=Mousa Tayseer, orcid=0000-0002-0408-054...   \n",
              "4  \\mathrm{w}}_{t}+\\mathrm{d}\\mathbf{L}_{t},\\qqua...   \n",
              "\n",
              "                                     source_page_url  \n",
              "0  https://arxiv.org/list/cs/2023-08?skip=0&show=...  \n",
              "1  https://arxiv.org/list/cs/2023-02?skip=6000&sh...  \n",
              "2  https://arxiv.org/list/cs/2024-01?skip=0&show=...  \n",
              "3  https://arxiv.org/list/cs/2024-01?skip=4000&sh...  \n",
              "4  https://arxiv.org/list/cs/2024-01?skip=6000&sh...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc41b374-dd0a-4785-8398-062394b1dca7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>subjects</th>\n",
              "      <th>html_url</th>\n",
              "      <th>full_text</th>\n",
              "      <th>source_page_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Breaking Speaker Recognition with PaddingBack</td>\n",
              "      <td>Zhe Ye,Diqun Yan,Li Dong,Kailai Shen</td>\n",
              "      <td>Cryptography and Security (cs.CR); Sound (cs.S...</td>\n",
              "      <td>https://arxiv.org/html/2308.04179v2</td>\n",
              "      <td>\\theta}(x_{i}),y_{i}), underitalic_θ start_ARG...</td>\n",
              "      <td>https://arxiv.org/list/cs/2023-08?skip=0&amp;show=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Infinite-Dimensional Diffusion Models</td>\n",
              "      <td>Jakiw Pidstrigach,Youssef Marzouk,Sebastian Re...</td>\n",
              "      <td>Machine Learning (stat.ML); Machine Learning (...</td>\n",
              "      <td>https://arxiv.org/html/2302.10130v3</td>\n",
              "      <td>Infinite-Dimensional Diffusion Models \\name Ja...</td>\n",
              "      <td>https://arxiv.org/list/cs/2023-02?skip=6000&amp;sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Computational Argumentation-based Chatbots: a ...</td>\n",
              "      <td>Federico Castagna,Nadin Kokciyan,Isabel Sassoo...</td>\n",
              "      <td>Artificial Intelligence (cs.AI)</td>\n",
              "      <td>https://arxiv.org/html/2401.03454v1</td>\n",
              "      <td>In recent years, cutting-edge technologies hav...</td>\n",
              "      <td>https://arxiv.org/list/cs/2024-01?skip=0&amp;show=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Optimal Control of Malware Propagation in IoT ...</td>\n",
              "      <td>Mousa Tayseer Jafar,Lu-Xing Yang,Gang Li,Xiaof...</td>\n",
              "      <td>Cryptography and Security (cs.CR)</td>\n",
              "      <td>https://arxiv.org/html/2401.11076v1</td>\n",
              "      <td>prefix=Mousa Tayseer, orcid=0000-0002-0408-054...</td>\n",
              "      <td>https://arxiv.org/list/cs/2024-01?skip=4000&amp;sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Reflected Schrödinger Bridge for Constrained G...</td>\n",
              "      <td>Wei Deng,Yu Chen,Nicole Tianjiao Yang,Hengrong...</td>\n",
              "      <td>Machine Learning (stat.ML); Machine Learning (...</td>\n",
              "      <td>https://arxiv.org/html/2401.03228v1</td>\n",
              "      <td>\\mathrm{w}}_{t}+\\mathrm{d}\\mathbf{L}_{t},\\qqua...</td>\n",
              "      <td>https://arxiv.org/list/cs/2024-01?skip=6000&amp;sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc41b374-dd0a-4785-8398-062394b1dca7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc41b374-dd0a-4785-8398-062394b1dca7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc41b374-dd0a-4785-8398-062394b1dca7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2801,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2801,\n        \"samples\": [\n          \"A Stepwise Distillation Learning Strategy for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks\",\n          \"HYVE: Hybrid Vertex Encoder for Neural Distance Fields\",\n          \"Spatiotemporal-Linear: Towards Universal Multivariate Time Series Forecasting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2799,\n        \"samples\": [\n          \"Cordula Reisch,Hendrik Ranocha\",\n          \"Bowen Li,Jun Zou\",\n          \"Puoya Tabaghi,Michael Khanzadeh,Yusu Wang,Sivash Mirarab\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subjects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 835,\n        \"samples\": [\n          \"Theoretical Economics (econ.TH); Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT)\",\n          \"Computational Complexity (cs.CC); Quantum Physics (quant-ph)\",\n          \"Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"html_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2801,\n        \"samples\": [\n          \"https://arxiv.org/html/2309.09809v3\",\n          \"https://arxiv.org/html/2310.06644v3\",\n          \"https://arxiv.org/html/2312.14869v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2782,\n        \"samples\": [\n          \"Mechanism Design for Large Language Models \\u2020 \\u2020 thanks: An extended abstract appeared in the Proceedings of WWW 2024. The work of Haifeng Xu was done as Visiting Faculty at Google Research. We thank Dirk Bergemann, Marina Halac, Philipp Strack, Elliot Lipnowski, Yang Cai, Vasilis Syrgkanis, Negin Gorezaei, Ido Cohen, Yoav Nagel, Yael Shemesh as well as the participants of the Yale Economics Seminar, the Stanford MS&E Seminar, and the WWW 2024 conference for invaluable comments and suggestions to improve this manuscript. We are specially grateful to Yong Cheng from Google DeepMind for his expert guidance on the LLM-related details and literature. Paul D\\u00fctting Google Research, {duetting,mirrokni,renatoppl,szuo}@google.com . Vahab Mirrokni \\u2020 Renato Paes Leme \\u2020 Haifeng Xu University of Chicago & Google Research, haifengxu@uchicago.edu . Song Zuo \\u2020 Abstract We investigate auction mechanisms for AI-generated content, focusing on applications like ad creative generation. In our model, agents\\u2019 preferences over stochastically generated content are encoded as large language models (LLMs). We propose an auction format that operates on a token-by-token basis, and allows LLM agents to influence content creation through single dimensional bids. We formulate two desirable incentive properties and prove their equivalence to a monotonicity condition on output aggregation. This equivalence enables a second-price rule design, even absent explicit agent valuation functions. Our design is supported by demonstrations on a publicly available LLM. 1 Introduction In the current web ecosystem, auctions are the primary mechanism used to decide which ads (and commercial content more broadly) are displayed to users (Edelman et al . , 2007 ; Varian, 2007 ) . In these auctions, advertisers bid for the opportunity to display their ad creatives alongside organic content. Many of the web formats such as text, banners, video, apps, \\u2026 have their own subtleties which led to the development of new auction tools to handle them. Our goal in this paper is to investigate auction mechanisms to support the emerging format of AI-generated content. More specifically, we explore the use of auctions as a tool for influencing the output of large language models (LLMs) (e.g., Brown et al . , 2020 ) . We consider a situation where a certain space in the web (which could be a part of a webpage, an UI element of an AI-chatbot, the dialog of a certain character in a video or a game, etc.) is designated for commercial content and different advertisers can bid to influence the content in that space. Each advertiser has an LLM that can generate content for that space, and is willing to pay a certain amount of money for the right to have their content displayed. A simple design is to collect bids from advertisers and let the highest bidder choose whatever content they wish to publish in that space. While simple, this design does not exploit the flexibility of LLMs which is to combine different concepts in a creative way. Consider this example. First, we ask an LLM to produce different ads for the fictitious Stingray Resort and the equally fictitious Maui Airlines: \\u2022 \\u201c Experience the magic of Hawaii at Stingray Resort, where stunning views, luxurious accommodations, and endless activities await. Book your stay today and create unforgettable memories in the heart of paradise .\\u201d \\u2022 \\u201c Fly to Hawaii with Maui Airlines and experience the beauty of the Aloha State. We offer affordable flights to all the major islands, so you can start your Hawaiian vacation sooner. Book your flight today and let the island spirit take over! \\u201d For that use case, however, the LLM is flexible enough to produce a joint ad for both: \\u2022 \\u201cFly to paradise with Maui Airlines and experience the magic of Hawaii at Stingray Resort. Stunning views, luxurious accommodations, and endless activities await. Book your dream vacation today and create unforgettable memories.\\u201d One can envision an auction mechanism that allows both Stingray Resort and Maui Airlines to submit their LLMs and bids, with these inputs determining their prominence in the final outcome. 1 1 1 While this work\\u2019s main focus is to create ad creatives that merge content from different advertisers, our designed auction mechanism for merging LLM outputs could also be used in other contexts. 1.1 Unique Challenges LLMs (Brown et al . , 2020 ; Thoppilan et al . , 2022 ; Google et al . , 2023 ) are an emerging technology with new and unconventional aspects, many of which have direct implications to auction design (e.g., how preferences are represented/expressed). Our goal is to identify some of the key challenges and take a first step in designing mechanisms to address them: \\u2022 Modelling and Expressing Preferences. Auction theory typically models preferences via value functions that assign a value to each outcome. LLMs, however, as generative models , do not directly assign values. Instead, they succinctly encode preferences over outcomes within a stateless neural network model that predicts continuation probabilities. \\u2022 Necessity of Randomization. LLMs crucially rely on randomization. When forced to output tokens deterministically, LLMs often have a worse performance compared to situations that sample from a distribution (see, e.g., (Holtzman et al . , 2019 ) , for a performance comparison of different decoding strategies). Therefore, an auction that aggregates LLM outputs should preferably also output distributions. \\u2022 Technical Compatibility. Auction solutions should be compatible with current LLM technology, utilizing readily available information and integrating seamlessly. Ideally, the allocation and payments should be obtained from simple manipulations of the LLM outputs. \\u2022 Computational Efficiency. LLM models are expensive to query, so the auction computation should not add too much overhead. In particular, auctions should not increase the number of calls to inference the models beyond the minimum necessary. 1.2 Our Contributions The Token Auction Model. Our first contribution is a formalism (\\u201cThe Token Auction Model\\u201d) for studying this problem. Tokens are the units making up sentences and paragraphs. 2 2 2 More generally, one can consider tokens forming parts of images (Ramesh et al . , 2021 ; Yu et al . , 2022 ) and videos (Sun et al . , 2019 ) . For the purpose of this paper, we will stick with text generation. Examples of tokens include (sub-)words, symbols, numbers, and special tokens indicating the beginning and ending of the text. In particular, any piece of text (potentially incomplete) can be represented as an array of tokens, and any array of tokens also encodes a piece of text. One salient feature of the state-of-the-art LLMs is that they are stateless, i.e., they maintain no internal memory or state. Instead, they simply map a prefix string to a distribution over the next token. The output is then created in an autoregressive manner. Given an input prompt, the output is generated by repeatedly feeding the current sequence of tokens into the LLM, sampling a continuation token, and appending it to the sequence of tokens. The proposed token auction operates on a token-by-token basis, and serves to aggregate several LLMs to generate a joint output. We assume the designer has access to algorithmic LLM agents represented by their respective text generation functions (the functions that map a sequence of tokens to a distribution over the next token). In addition, we allow each LLM agent to submit a single dimensional bid. The auction output will be an aggregated distribution together with a payment rule that defines payments for each agent. 3 3 3 See our discussion later this section on the rationale of the indirect mechanism formulation. This approach may seem counterintuitive initially, as advertisers typically focus on the final generated text rather than individual word choices. This seems to suggest a dynamic planning of the generated token sequence. However, existing LLMs do not reason about full pieces of text, nor do they plan ahead; instead, their preferences are expressed as desired distributions over merely the next token. In other terms, we can think of an LLM as a succinct distillation of an agent\\u2019s complex combinatorial preferences over sequences of tokens into a generative token-by-token model. 4 4 4 See our discussion in Section 4 , and Propositions 4.1 and 4.3 for additional support for the stateless approach. The problem of aggregating LLMs forces the designer to understand the preferences of the agents away from the distilled LLM. This appears to be a very difficult problem. Specifically, we believe it is implausible or at least impractical to assume an individual agent can meaningfully manipulate the distribution over tokens at any given stage, to direct the produced text to a more preferred one. Our auction formulation seeks to strike a balance: By truthfully revealing the LLM to the designer, the agent gives the auction mechanism a hint as to what their preferred distribution is. The bids, in turn, can be used to tradeoff between agents, and in particular help the designer determine their relative weights. Simple and Robust Token Auctions. Motivated by the challenges in modeling agents\\u2019 preferences over generated distributions, we take a robust design approach aiming for token auctions that provide desirable incentive properties, while imposing minimal assumptions on the agents\\u2019 preferences over distributions. Specifically, we model agents\\u2019 preferences as entailing partial orders over distributions. Based on this partial preference order 5 5 5 Partial orders are more general than total orders, and hence our key results (such as Lemma 3.7 , Lemma 3.6 , and Theorem 3.5 ) apply to any complete preference order model. , we formulate two desirable incentive properties, which we consider minimal requirements: \\u2022 Payment monotonicity : Given two different bids by the same agent, a final distribution is closer to the desired distribution if and only if the payment is higher. \\u2022 Consistent aggregation: If for two different bids of the same agent, the final distribution is closer to the preferred distribution for some bids of the other agents, then it should be so for all bids of the other agents. We show that any mechanism with these two properties is strategically equivalent to a mechanism that satisfies a monotonicity requirement on the distribution aggregation function. We then investigate whether it is possible to equip such distribution aggregation functions with payment rules that satisfy additional incentive properties. Specifically, we investigate whether such aggregation rules admit an analogue of the second-price payment rule . In the single-item second-price (or Vickrey) auction (Vickrey, 1961 ) , the payment corresponds to the critical bid where an agent transitions from losing to winning. To port this notion to our setting, we show that under robust preferences (see Definition 2.1 ) any monotone aggregation rule can be written as a distribution over deterministic allocations from bids to tokens such that there is a critical bid where the allocation transitions from a less preferred to a more preferred token. Such a critical bid then serves as a natural candidate for a payment rule. This hence leads to an analogue of the second-price auction for our token auction model that only requires ordinal preferences. The resulting class of auctions is applicable whenever the agent valuations are compatible with the partial order, and provides robust incentives for all of these. Designing Aggregation Functions. We then move to designing concrete aggregation functions. Our approach considers aggregated loss functions inspired by state-of-the-art LLM training, and derives optimal distribution aggregation functions that minimizes such aggregated loss functions. We focus on specific forms of aggregated loss functions based on KL-divergence, a commonly used loss function in LLMs. We consider two natural formulations inspired by current LLM training, and show that the corresponding optimal aggregation rules are the weighted (log-space) convex combination of the target distributions from all participants. The linear and log-linear aggregation rules we identify have different pros and cons. Both share the advantage that they are optimal for the respective aggregated loss functions. The linear rule turns out to be monotone with respect to robust preferences, and is therefore compatible with the robust incentives approach. However, the log-linear rule is not. Demonstration. We conclude with demonstrations to support our token auction formulation, obtained by prompt-tuning of a publicly available LLM. A two-advertiser demonstrative example is considered, under both the linear and log-linear aggregation rules. We show how the combined output varies as a function of \\u03bb = b 1 / ( b 1 + b 2 ) \\ud835\\udf06 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 \\\\lambda=\\\\nicefrac{{b_{1}}}{{(b_{1}+b_{2})}} italic_\\u03bb = / start_ARG italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG , where b 1 subscript \\ud835\\udc4f 1 b_{1} italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and b 2 subscript \\ud835\\udc4f 2 b_{2} italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are the advertisers\\u2019 bids. Both approaches lead to meaningful and interpretable texts that smoothly transition from favoring one to favoring another advertiser, with a joint ad produced for intermediate values of \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb . Discussion/Design Choices. An alternative to our approach of designing an indirect mechanism would be to aim for a direct mechanism . Such a mechanism, instead of asking agents for a scalar bid along with query access to the agents\\u2019 LLMs, would elicit the agents\\u2019 full preferences directly. However, this appears unrealistic in our new domain due to multiple reasons: (1) Allocation outcomes in our setting are a high-dimensional distribution, whereas a classic mechanism\\u2019s allocation is typically a subset of items, and often a single item in tractable setups. (2) While it is reasonable in the classic setup to elicit a valuation for an item or a subset of items, it does not appear realistic to elicit a high-dimensional utility function over all possible token distributions. (3) Eliciting full preferences over any token distribution would require solving a problem that is strictly harder than what current LLMs are trained to do (namely, merely output the most preferred distribution). This level of complexity might go beyond current technological capabilities and would likely be computationally inefficient. 1.3 Additional Related Work To the best of our knowledge, the exact research question and our approaches in this work have not been previously studied. However, our work is indeed connected to a few lines of research. Related LLM Research. Our work shares some similarities with the literature on fine-tuning LLMs, with reinforcement learning from human feedback (RLHF) as a representative approach (Wei et al . , 2021 ; Bakker et al . , 2022 ; Ouyang et al . , 2022 ; Bai et al . , 2022 ) . At a high level, fine-tuning and RLHF seek to align a generally pre-trained LLM with certain desirable behaviors. This is in spirit analogous to our goal of designing LLMs to better align with a group of agents\\u2019 overall preferences. However, our research challenges and methods are both different from those in the fine-tuning literature. Specifically, fine-tuning refines the underlying model\\u2019s parameters whereas our approach is one-layer up and directly aggregates the token distributions from multiple models. The main challenge we address is the potential incentive misalignment while eliciting LLM agents\\u2019 preferences, whereas human labelers or other models that generate reward feedback for RLHF are assumed to be genuine and do not misrepresent their own preferences. The literature on in-context learning (Brown et al . , 2020 ; Wei et al . , 2022 , 2023 ) is similar to us in the sense that this approach also does not change the model parameters. A main difference to our work is that this literature seeks to influence token distributions by conditioning on better-generated prefix contexts, whereas we directly aggregate distributions from multiple LLM agents. Connections in Mechanism Design. Our work is related to the literature on (combinatorial) public projects (Papadimitriou et al . , 2008 ; Dughmi, 2011 ) . The connection is that one can view the output of the aggregated LLM in our situation as a public project that benefits the agents to different degrees. Similar to these earlier studies, a core challenge in our problem is to elicit preferences about the public project from unknown agents. However, the design problem in our case is fundamentally different \\u2014 we choose a high-dimensional distribution from an \\u211d T superscript \\u211d \\ud835\\udc47 \\\\mathbb{R}^{T} blackboard_R start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT space with only partial knowledge about agents\\u2019 preferences, whereas previous work has focused on the problem of choosing from a discrete (often exponentially large) set with clear agent valuation functions (Papadimitriou et al . , 2008 ; Dughmi, 2011 ) . Another related stream of work includes (Freeman et al . , 2019 ; Goel et al . , 2019 ) , which studies the problem of truthfully aggregating budget proposals. Their mechanisms output a distribution over budgets that best serves the population, just like our mechanisms output distributions over tokens. However, the objectives and techniques between our work and theirs are both different. First, their problem is mechanism design without money, whereas our problem has monetary transfers involved. A direct consequence of this first difference is that their mechanisms will treat every participant with equal weight, whereas the weights of our participants are determined by their bids. Second, the research on truthful budget proposal aggregations typically assumes explicit valuation functions (e.g., l 1 subscript \\ud835\\udc59 1 l_{1} italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT distance between preferred and output distributions), under which the VCG mechanism is truthful. Their main research question hence is to study additional properties of the mechanisms such as Pareto-efficiency and certain fairness properties (Freeman et al . , 2019 ) . Assuming such an explicit valuation function does not appear realistic in our problem, so our core research question is to design robust mechanisms that enjoy good incentive properties simultaneously for a broad range of valuation functions. From this perspective, our work also bears some similarity to the rich literature on robust mechanism design. Most of this literature still assume existence of value functions with uncertainty modeled by Bayesian beliefs or in a max-min sense (Bergemann and Morris, 2005 , 2012 ; Roughgarden and Talgam-Cohen, 2016 ; Carroll, 2015 ; D\\u00fctting et al . , 2019 ) . However, assuming such a valuation function over tokens or their distributions does not appear realistic in creatives generation, thus our model is more similar to a worst-case style consideration during which we only assume partial (\\u201cobvious\\u201d) preferences. Follow-Up Work. Several papers follow-up on our work, by studying mechanism design problems for LLMs. Dubey et al . ( 2024 ) consider bidders that bid for placement of their content within a summary generated by a large language model. Soumalias et al . ( 2024 ) design a truthful mechanism that generates several samples from a reference LLM, and incentivizes bidders to truthfully reveal their preferences. Mordo et al . ( 2024 ) consider sponsored question answering, in which an organic answer to a search query is fused with an ad to create a sponsored answer, and advertisers bid on the sponsored answers. 2 Preliminaries In this section, we first provide an abstraction of typical generative models and then introduce the basic formalism of the mechanism design problem we study. For concreteness we adopt a terminology that suits the important LLM use case where the creative is text. 2.1 Abstraction of Large Language Models Large language models (LLMs) (Brown et al . , 2020 ; Thoppilan et al . , 2022 ; Google et al . , 2023 ) can be abstracted as functions mapping from a partial sentence to the distribution of the next token that extends the partial sentence. Formally, let T \\ud835\\udc47 T italic_T be the set of tokens and \\u0394 \\u2062 ( T ) \\u0394 \\ud835\\udc47 \\\\Delta(T) roman_\\u0394 ( italic_T ) be the set of distributions over T \\ud835\\udc47 T italic_T . Let T \\u2217 = T \\u222a T 2 \\u222a \\u22ef \\u222a T K superscript \\ud835\\udc47 \\ud835\\udc47 superscript \\ud835\\udc47 2 \\u22ef superscript \\ud835\\udc47 \\ud835\\udc3e T^{*}=T\\\\cup T^{2}\\\\cup\\\\cdots\\\\cup T^{K} italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT = italic_T \\u222a italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \\u222a \\u22ef \\u222a italic_T start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT denote the set of sequences of tokens, where K \\ud835\\udc3e K italic_K is the maximum sequence length that the LLM can handle. Each LLM is modeled as a function f : T \\u2217 \\u2192 \\u0394 \\u2062 ( T ) : \\ud835\\udc53 \\u2192 superscript \\ud835\\udc47 \\u0394 \\ud835\\udc47 f:T^{*}\\\\rightarrow\\\\Delta(T) italic_f : italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) that maps any sequence of tokens to a distribution over the next token. Autoregressive Text Generation. A prompt is an initial set of tokens s 0 \\u2208 T \\u2217 subscript \\ud835\\udc60 0 superscript \\ud835\\udc47 s_{0}\\\\in T^{*} italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT provided with instructions of what text to generate. An LLM produces a text in response to the prompt by sampling a token \\u03c4 1 \\u223c f \\u2062 ( s 0 ) similar-to subscript \\ud835\\udf0f 1 \\ud835\\udc53 subscript \\ud835\\udc60 0 \\\\tau_{1}\\\\sim f(s_{0}) italic_\\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \\u223c italic_f ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) and constructing s 1 = s 0 \\u2295 \\u03c4 1 subscript \\ud835\\udc60 1 direct-sum subscript \\ud835\\udc60 0 subscript \\ud835\\udf0f 1 s_{1}=s_{0}\\\\oplus\\\\tau_{1} italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \\u2295 italic_\\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (where \\u2295 direct-sum \\\\oplus \\u2295 is the operation to append a token to an array). We then repeat the process of \\u03c4 k \\u223c f \\u2062 ( s k ) similar-to subscript \\ud835\\udf0f \\ud835\\udc58 \\ud835\\udc53 subscript \\ud835\\udc60 \\ud835\\udc58 \\\\tau_{k}\\\\sim f(s_{k}) italic_\\u03c4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \\u223c italic_f ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and s k = s k \\u2212 1 \\u2295 \\u03c4 k subscript \\ud835\\udc60 \\ud835\\udc58 direct-sum subscript \\ud835\\udc60 \\ud835\\udc58 1 subscript \\ud835\\udf0f \\ud835\\udc58 s_{k}=s_{k-1}\\\\oplus\\\\tau_{k} italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT \\u2295 italic_\\u03c4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT until a special end-of-sentence token is sampled. If at some point the sequence of tokens becomes too long (larger than K \\ud835\\udc3e K italic_K ) we trim s k subscript \\ud835\\udc60 \\ud835\\udc58 s_{k} italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT to its length- K \\ud835\\udc3e K italic_K suffix. Note that LLMs are stateless: They lack internal memory beyond the generated token sequence, and each token is sampled independently. Training of LLMs. An LLM f \\ud835\\udc53 f italic_f is parameterized by a neural network structure M \\ud835\\udc40 M italic_M and a set of weights W \\ud835\\udc4a W italic_W . The weights are often obtained by three stages of optimization (see first three rows in Table 1 ). The initial stage is very computationally intensive but task independent. Subsequent stages are less costly and their goal is to adapt the general purposed model obtained in the first stage to more specific tasks. Each of the stages usually minimizes a different loss function over a different dataset. The details of the training process are not particularly relevant to our discussion, though a more detailed discussion can be found in Section 4.1 . We will note, however, that some of the mechanisms we discuss for combining the inputs of different LLMs resemble the functional forms used in the reinforcement learning and fine-tuning steps. Training/Learning stages Data Cost Goal Pre-training \\u2217 superscript Pre-training \\u2217 \\\\text{Pre-training}^{\\\\ast} Pre-training start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT General texts from web, books, etc Very high A common baseline shared across downstream tasks Instruction fine-tuning \\u2020 superscript Instruction fine-tuning \\u2020 \\\\text{Instruction fine-tuning}^{\\\\dagger} Instruction fine-tuning start_POSTSUPERSCRIPT \\u2020 end_POSTSUPERSCRIPT Task specific data Medium Optimize the behavior for specific tasks RLHF \\u2021 superscript RLHF \\u2021 \\\\text{RLHF}^{{\\\\ddagger}} RLHF start_POSTSUPERSCRIPT \\u2021 end_POSTSUPERSCRIPT Human evaluations Medium Security control, reducing harmful behavior, etc In-context few-shot learning Carefully designed prompts as inputs Very low Effectively influence the behavior in real-time \\u2217 \\u2217 \\\\ast \\u2217 Brown et al . ( 2020 ) ; Google et al . ( 2023 ) \\u2020 \\u2020 \\\\dagger \\u2020 Wei et al . ( 2021 ) \\u2021 \\u2021 {\\\\ddagger} \\u2021 Ouyang et al . ( 2022 ) Table 1: Common Training Stages of LLMs. 2.2 Token Auctions for LLMs We now formalize the mechanism design problem of combining the output of different LLM-represented algorithmic agents. As discussed in the introduction, we will design an auction to act on the token-by-token generation stage. Our goal is to keep the auction technically aligned with the state-of-the-art LLM systems. Robust Modeling of LLM Agents\\u2019 Preferences. A key challenge in designing mechanisms for LLM agents is comparing their \\u201cutilities\\u201d over different output distributions. To illustrate, suppose an LLM agent\\u2019s preferred distribution over two tokens is p = ( 0.6 , 0.4 ) \\ud835\\udc5d 0.6 0.4 p=(0.6,0.4) italic_p = ( 0.6 , 0.4 ) , and consider two possible generated distribution outcomes: q 1 = ( 0.5 , 0.5 ) subscript \\ud835\\udc5e 1 0.5 0.5 q_{1}=(0.5,0.5) italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ( 0.5 , 0.5 ) and q 2 = ( 0.8 , 0.2 ) subscript \\ud835\\udc5e 2 0.8 0.2 q_{2}=(0.8,0.2) italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( 0.8 , 0.2 ) . Between q 1 subscript \\ud835\\udc5e 1 q_{1} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and q 2 subscript \\ud835\\udc5e 2 q_{2} italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , it is unclear which one this LLM agent would prefer since while q 2 subscript \\ud835\\udc5e 2 q_{2} italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT appears more distant from p \\ud835\\udc5d p italic_p than q 1 subscript \\ud835\\udc5e 1 q_{1} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , it has a higher probability on the first token which appears more preferably by the LLM\\u2019s initial distribution p \\ud835\\udc5d p italic_p . Despite this incomparability between q 1 subscript \\ud835\\udc5e 1 q_{1} italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and q 2 subscript \\ud835\\udc5e 2 q_{2} italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , it does appear clear that q 2 subscript \\ud835\\udc5e 2 q_{2} italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT would be less preferred by the LLM than q 3 = ( 0.7 , 0.3 ) subscript \\ud835\\udc5e 3 0.7 0.3 q_{3}=(0.7,0.3) italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = ( 0.7 , 0.3 ) . This is because q 3 subscript \\ud835\\udc5e 3 q_{3} italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT deviates from p \\ud835\\udc5d p italic_p along the same directions as q 2 subscript \\ud835\\udc5e 2 q_{2} italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT for each entry (i.e., both increase or both decrease), but deviates less in terms of the absolute value of deviation. The above observation illustrates that while it is difficult to model LLM agents\\u2019 complete preferences over all the generated distributions, it seems natural to assume certain partial order over the distributions. This motivates us to consider a robust modeling of LLM agents\\u2019 preferences through general partial orders, and sometimes, the following specific notion of robust preferences . Definition 2.1 (Robust Preferences over Distributions) . Consider any LLM agent i \\ud835\\udc56 i italic_i with preferred distribution p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , and any two aggregation distribution q , q \\u2032 \\u2208 \\u0394 \\u2062 ( T ) \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 \\u0394 \\ud835\\udc47 q,q^{\\\\prime}\\\\in\\\\Delta(T) italic_q , italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u2208 roman_\\u0394 ( italic_T ) . We say q \\ud835\\udc5e q italic_q is (weakly) robustly preferred over q \\u2032 superscript \\ud835\\udc5e \\u2032 q^{\\\\prime} italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT by agent i \\ud835\\udc56 i italic_i , or formally, q \\u2ab0 i q \\u2032 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 q\\\\succeq_{i}q^{\\\\prime} italic_q \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , if \\u2200 t \\u2208 T , for-all \\ud835\\udc61 \\ud835\\udc47 \\\\displaystyle\\\\forall t\\\\in T, \\u2200 italic_t \\u2208 italic_T , | q \\u2062 ( t ) \\u2212 p i \\u2062 ( t ) | \\u2264 | q \\u2032 \\u2062 ( t ) \\u2212 p i \\u2062 ( t ) | \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 superscript \\ud835\\udc5e \\u2032 \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\\\displaystyle\\\\,\\\\,\\\\,\\\\,\\\\,\\\\,|q(t)-p_{i}(t)|\\\\leq|q^{\\\\prime}(t)-p_{i}(t)| | italic_q ( italic_t ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) | \\u2264 | italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ( italic_t ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) | (1) and \\u2062 ( q \\u2062 ( t ) \\u2212 p i \\u2062 ( t ) ) \\u2062 ( q \\u2032 \\u2062 ( t ) \\u2212 p i \\u2062 ( t ) ) \\u2265 0 . and \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 superscript \\ud835\\udc5e \\u2032 \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 0 \\\\displaystyle\\\\text{and }\\\\,\\\\,\\\\,\\\\,(q(t)-p_{i}(t))(q^{\\\\prime}(t)-p_{i}(t))\\\\geq 0. and ( italic_q ( italic_t ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) ) ( italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ( italic_t ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) ) \\u2265 0 . (2) Moreover, if q \\u2260 q \\u2032 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 q\\\\neq q^{\\\\prime} italic_q \\u2260 italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , then q \\ud835\\udc5e q italic_q is strictly preferred over q \\u2032 superscript \\ud835\\udc5e \\u2032 q^{\\\\prime} italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT by i \\ud835\\udc56 i italic_i , i.e., q \\u227b i q \\u2032 subscript succeeds \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 q\\\\succ_{i}q^{\\\\prime} italic_q \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT . In other words, q \\ud835\\udc5e q italic_q is robustly preferred by i \\ud835\\udc56 i italic_i over q \\u2032 superscript \\ud835\\udc5e \\u2032 q^{\\\\prime} italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT when (1) the deviation of q \\ud835\\udc5e q italic_q from p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is smaller than the deviation of q \\u2032 superscript \\ud835\\udc5e \\u2032 q^{\\\\prime} italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT from p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for every entry; and (2) these deviations are along the same direction for every entry. Note that Definition 2.1 only specifies a partial ordering among aggregated distributions. Thus it is possible that two distributions are not comparable, i.e., q \\u22e1 i q \\u2032 subscript not-succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 q\\\\not\\\\succeq_{i}q^{\\\\prime} italic_q \\u22e1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT and q \\u2032 \\u22e1 i q subscript not-succeeds-or-equals \\ud835\\udc56 superscript \\ud835\\udc5e \\u2032 \\ud835\\udc5e q^{\\\\prime}\\\\not\\\\succeq_{i}q italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u22e1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q . Token Auctions. Our goal is to design simple, practical auction mechanisms that work well under minimal assumptions about the agents\\u2019 private preferences. Specifically, we seek to design token auction mechanisms \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 , where q \\ud835\\udc5e q italic_q is a distribution aggregation function and z \\ud835\\udc67 z italic_z is a payment function. A token auction mechanism operates on a token-by-token basis, and lets n \\ud835\\udc5b n italic_n algorithmic LLM agents influence the output distribution and payments through scalar bids. The bid profile of all agents is denoted as \\ud835\\udc83 = ( b 1 , \\u2026 , b n ) \\u2208 \\u211a + n \\ud835\\udc83 subscript \\ud835\\udc4f 1 \\u2026 subscript \\ud835\\udc4f \\ud835\\udc5b subscript superscript \\u211a \\ud835\\udc5b \\\\boldsymbol{b}=(b_{1},\\\\ldots,b_{n})\\\\in\\\\mathbb{Q}^{n}_{+} bold_italic_b = ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \\u2026 , italic_b start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) \\u2208 blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT where any bid b i \\u2208 \\u211a + subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a b_{i}\\\\in\\\\mathbb{Q}_{+} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT is a non-negative rational number. We assume that the initial prompt s 0 \\u2208 T \\u2217 subscript \\ud835\\udc60 0 superscript \\ud835\\udc47 s_{0}\\\\in T^{*} italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT , and the text aggregation functions f 1 , \\u2026 , f n subscript \\ud835\\udc53 1 \\u2026 subscript \\ud835\\udc53 \\ud835\\udc5b f_{1},\\\\ldots,f_{n} italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \\u2026 , italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of the n \\ud835\\udc5b n italic_n LLM agents are publicly known. Distribution Aggregation Function. This is the first ingredient to a token auction mechanism. A distribution aggregation function q \\ud835\\udc5e q italic_q takes as input a vector of bids \\ud835\\udc83 \\u2208 \\u211a + n \\ud835\\udc83 subscript superscript \\u211a \\ud835\\udc5b \\\\boldsymbol{b}\\\\in\\\\mathbb{Q}^{n}_{+} bold_italic_b \\u2208 blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and n \\ud835\\udc5b n italic_n distributions \\ud835\\udc91 \\u2208 \\u0394 \\u2062 ( T ) n \\ud835\\udc91 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\\\boldsymbol{p}\\\\in\\\\Delta(T)^{n} bold_italic_p \\u2208 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and maps these to a distribution over tokens: aggregation function: q : \\u211a + n \\u00d7 \\u0394 \\u2062 ( T ) n \\u2192 \\u0394 \\u2062 ( T ) . : aggregation function: \\ud835\\udc5e \\u2192 subscript superscript \\u211a \\ud835\\udc5b \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\u0394 \\ud835\\udc47 \\\\text{aggregation function:}\\\\quad q:\\\\mathbb{Q}^{n}_{+}\\\\times\\\\Delta(T)^{n}% \\\\rightarrow\\\\Delta(T). aggregation function: italic_q : blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u00d7 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) . For fixed bids, a distribution aggregation function can be used in the same way as a text aggregation function. Namely, starting from the initial prompt s 0 \\u2208 T \\u2217 subscript \\ud835\\udc60 0 superscript \\ud835\\udc47 s_{0}\\\\in T^{*} italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT , we can repeatedly sample \\u03c4 k subscript \\ud835\\udf0f \\ud835\\udc58 \\\\tau_{k} italic_\\u03c4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT from distribution q k = q \\u2062 ( ( b 1 , \\u2026 , b n ) , ( f 1 \\u2062 ( s k \\u2212 1 ) , \\u2026 , f n \\u2062 ( s k \\u2212 1 ) ) ) subscript \\ud835\\udc5e \\ud835\\udc58 \\ud835\\udc5e subscript \\ud835\\udc4f 1 \\u2026 subscript \\ud835\\udc4f \\ud835\\udc5b subscript \\ud835\\udc53 1 subscript \\ud835\\udc60 \\ud835\\udc58 1 \\u2026 subscript \\ud835\\udc53 \\ud835\\udc5b subscript \\ud835\\udc60 \\ud835\\udc58 1 q_{k}=q((b_{1},\\\\ldots,b_{n}),(f_{1}(s_{k-1}),\\\\ldots,f_{n}(s_{k-1}))) italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_q ( ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \\u2026 , italic_b start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) , ( italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT ) , \\u2026 , italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT ) ) ) for each k \\u2265 1 \\ud835\\udc58 1 k\\\\geq 1 italic_k \\u2265 1 to generate s k = s k \\u2212 1 \\u2295 \\u03c4 k subscript \\ud835\\udc60 \\ud835\\udc58 direct-sum subscript \\ud835\\udc60 \\ud835\\udc58 1 subscript \\ud835\\udf0f \\ud835\\udc58 s_{k}=s_{k-1}\\\\oplus\\\\tau_{k} italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT \\u2295 italic_\\u03c4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT . Note the alignment with LLMs, which already produce the distributions f i \\u2062 ( s k \\u2212 1 ) subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc60 \\ud835\\udc58 1 f_{i}(s_{k-1}) italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT ) for i \\u2208 [ n ] \\ud835\\udc56 delimited-[] \\ud835\\udc5b i\\\\in[n] italic_i \\u2208 [ italic_n ] . No additional calls to the LLMs are needed. Payment Function. In addition to the distribution aggregation function, we seek to design payment functions. Here, we want to operate on a token-by-token basis and seek a stage-independent design akin to the stage independence of state-of-the-art LLMs\\u2019 token generation. Formally, for each agent i \\ud835\\udc56 i italic_i , we aim to define a pricing function: \\u03b6 i : \\u211a + n \\u00d7 \\u0394 \\u2062 ( T ) n \\u00d7 T \\u2192 \\u211d , : pricing function: subscript \\ud835\\udf01 \\ud835\\udc56 \\u2192 subscript superscript \\u211a \\ud835\\udc5b \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\ud835\\udc47 \\u211d \\\\displaystyle\\\\text{pricing function:}\\\\quad\\\\zeta_{i}:\\\\mathbb{Q}^{n}_{+}\\\\times% \\\\Delta(T)^{n}\\\\times T\\\\rightarrow\\\\mathbb{R}, pricing function: italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u00d7 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \\u00d7 italic_T \\u2192 blackboard_R , with the interpretation that for bids \\ud835\\udc83 \\u2208 \\u211a + n \\ud835\\udc83 subscript superscript \\u211a \\ud835\\udc5b \\\\boldsymbol{b}\\\\in\\\\mathbb{Q}^{n}_{+} bold_italic_b \\u2208 blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , distributions \\ud835\\udc91 \\u2208 \\u0394 \\u2062 ( T ) n \\ud835\\udc91 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\\\boldsymbol{p}\\\\in\\\\Delta(T)^{n} bold_italic_p \\u2208 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , and token t \\u223c q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) similar-to \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 t\\\\sim q(\\\\boldsymbol{b},\\\\boldsymbol{p}) italic_t \\u223c italic_q ( bold_italic_b , bold_italic_p ) , the payment from agent i \\ud835\\udc56 i italic_i is \\u03b6 i \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 , t ) subscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc83 \\ud835\\udc91 \\ud835\\udc61 \\\\zeta_{i}(\\\\boldsymbol{b},\\\\boldsymbol{p},t) italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p , italic_t ) . These pricing functions naturally lead to expected payments by taking expectations over tokens. Namely, for each agent i \\ud835\\udc56 i italic_i , we define payment function: z i : \\u211a + n \\u00d7 \\u0394 \\u2062 ( T ) n \\u2192 \\u211d , : payment function: subscript \\ud835\\udc67 \\ud835\\udc56 \\u2192 subscript superscript \\u211a \\ud835\\udc5b \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\u211d \\\\displaystyle\\\\text{payment function:}\\\\quad z_{i}:\\\\mathbb{Q}^{n}_{+}\\\\times% \\\\Delta(T)^{n}\\\\rightarrow\\\\mathbb{R}, payment function: italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u00d7 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \\u2192 blackboard_R , as the function that takes as input a vector of bids \\ud835\\udc83 \\u2208 \\u211a + n \\ud835\\udc83 subscript superscript \\u211a \\ud835\\udc5b \\\\boldsymbol{b}\\\\in\\\\mathbb{Q}^{n}_{+} bold_italic_b \\u2208 blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and distributions \\ud835\\udc91 \\u2208 \\u0394 \\u2062 ( T ) n \\ud835\\udc91 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\\\boldsymbol{p}\\\\in\\\\Delta(T)^{n} bold_italic_p \\u2208 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , and maps these to z i \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) = \\ud835\\udd3c t \\u223c q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\u2061 [ \\u03b6 i \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 , t ) ] subscript \\ud835\\udc67 \\ud835\\udc56 \\ud835\\udc83 \\ud835\\udc91 subscript \\ud835\\udd3c similar-to \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 subscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc83 \\ud835\\udc91 \\ud835\\udc61 z_{i}(\\\\boldsymbol{b},\\\\boldsymbol{p})=\\\\operatorname{\\\\mathbb{E}}_{t\\\\sim q(% \\\\boldsymbol{b},\\\\boldsymbol{p})}[\\\\zeta_{i}(\\\\boldsymbol{b},\\\\boldsymbol{p},t)] italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p ) = blackboard_E start_POSTSUBSCRIPT italic_t \\u223c italic_q ( bold_italic_b , bold_italic_p ) end_POSTSUBSCRIPT [ italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p , italic_t ) ] . Discussion. Token auctions provide a suitable abstraction for analyzing the strategic aspects of LLM aggregation. Fully expressing agent preferences over all generated content is impractical. Representing agents as LLMs is a plausible approach, as LLMs distill preferences into token distributions. Thus, auctioning tokens based on LLM-expressed preferences is a natural mechanism. At the same time, the detailed functioning of LLMs remains rather opaque, and it seems implausible that agents could meaningfully misreport the outcome distributions of their LLMs in order to achieve a more desirable aggregated output. Our auction formulation offers a middle ground. We assume the designer has access to the LLMs, but let the agents influence the aggregation process through a single dimensional bid. 3 Incentives in Token Auctions In this section, we examine the strategic properties of token auctions. Our goal is robust incentive properties that rely on as few assumptions about the agents\\u2019 preferences as possible. We first formulate two natural properties that any reasonable mechanism should satisfy, and show that they are essentially equivalent to a monotonicity requirement on the distribution aggregation function. We then show that, when agents have robust preferences (see Definition 2.1 ), for any such monotone distribution aggregation function, it is possible to define a natural second-price payment rule. 3.1 Desirable Incentive Properties We begin by formulating two conditions that reasonable token auction mechanisms should satisfy with respect to general partial orders \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . The first is a monotonicity condition on the payment function. It requires that agents\\u2019 pay increases if and only if they obtain better distributions. Definition 3.1 (Payment Monotonicity) . Mechanism \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 satisfies payment monotonicity , if for all \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p , \\ud835\\udc83 \\u2212 i , b i , b i \\u2032 subscript \\ud835\\udc83 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 \\\\boldsymbol{b}_{-i},b_{i},b^{\\\\prime}_{i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT we have z i \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2265 z i \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u21d4 q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) . iff subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc67 \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 z_{i}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\geq z_{i}(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\iff q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p})\\\\succeq_{i}q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}). italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2265 italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u21d4 italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . It is a natural incentive constraint because if the payment function is not monotone, then bidders will likely manipulate their bids in order to induce better distribution with lower payment. The following is a useful implication of payment monotonicity. Given \\ud835\\udc91 , \\ud835\\udc83 \\u2212 i \\ud835\\udc91 subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{p},\\\\boldsymbol{b}_{-i} bold_italic_p , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , if i \\ud835\\udc56 i italic_i \\u2019s two bids b i , b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i},b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT lead to the same aggregated distribution, i.e., q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-% i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , then as a consequence of payment monotonicity the payment must also be the same. The second incentive constraint is about the consistency of the aggregation function. Intuitively, the relative preference between two bids should not be influenced by the bids of other agents. Definition 3.2 (Consistent Aggregation) . The distribution aggregation function q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 q(\\\\boldsymbol{b},\\\\boldsymbol{p}) italic_q ( bold_italic_b , bold_italic_p ) is said to be consistent if it admits consistent ordering across all \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT . Formally, if q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u227b i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript succeeds \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succ_{i}q(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) for some \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , then for all \\ud835\\udc83 \\u2212 i \\u2032 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\\\boldsymbol{b}^{\\\\prime}_{-i} bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i \\u2032 , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i \\u2032 , \\ud835\\udc91 ) subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}^{\\\\prime}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b^{\\\\prime}_{i% },\\\\boldsymbol{b}^{\\\\prime}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . Similar to payment monotonicity, this requirement of consistent aggregation is imposed to avoid bidders\\u2019 concerns that the same bid can lead to better or worse distributions, depending on the opponents\\u2019 bids. To rule out such behavior, consistency requires that whenever bids b i , b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i},b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are such that b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is strictly preferred over b i \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b^{\\\\prime}_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for some opposing bids \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , then it better be that b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is weakly preferred over b i \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b^{\\\\prime}_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all opposing bids \\ud835\\udc83 \\u2212 i \\u2032 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\\\boldsymbol{b}^{\\\\prime}_{-i} bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT . 3.2 Monotone Aggregation Functions Next we show a \\u201crevelation principle\\u201d type of result, stating that if one is interested in mechanisms satisfying the desirable incentive properties stated above (Definition 3.1 and Definition 3.2 ), then one can without loss of generality focus on monotone aggregation functions as captured in the following definition for any partial order \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Definition 3.3 (Monotone Aggregation Function) . The distribution aggregation function q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 q(\\\\boldsymbol{b},\\\\boldsymbol{p}) italic_q ( bold_italic_b , bold_italic_p ) is called monotone if any higher bid from any agent i \\ud835\\udc56 i italic_i leads to a more preferred aggregated distribution for i \\ud835\\udc56 i italic_i . Formally, for all \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p , \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and b i \\u2265 b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\geq b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) . subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}). italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . We are now ready to state our main finding in this subsection with the following definition of strategic equivalence from one mechanism \\u2133 \\u2133 \\\\mathcal{M} caligraphic_M to another \\u2133 ~ ~ \\u2133 \\\\tilde{\\\\mathcal{M}} over~ start_ARG caligraphic_M end_ARG . In words, the aggregated distribution outcome and all agents\\u2019 payments will be the same under mechanism \\u2133 \\u2133 \\\\mathcal{M} caligraphic_M and \\u2133 ~ ~ \\u2133 \\\\tilde{\\\\mathcal{M}} over~ start_ARG caligraphic_M end_ARG after each agent i \\ud835\\udc56 i italic_i applies some strategy mapping \\u03c0 i subscript \\ud835\\udf0b \\ud835\\udc56 \\\\pi_{i} italic_\\u03c0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Formally, Definition 3.4 (Strategic Equivalence) . A mechanism \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 is strategically equivalent to another mechanism \\u2133 ~ = \\u27e8 q ~ , z ~ \\u27e9 ~ \\u2133 ~ \\ud835\\udc5e ~ \\ud835\\udc67 \\\\tilde{\\\\mathcal{M}}=\\\\langle\\\\tilde{q},\\\\tilde{z}\\\\rangle over~ start_ARG caligraphic_M end_ARG = \\u27e8 over~ start_ARG italic_q end_ARG , over~ start_ARG italic_z end_ARG \\u27e9 , if \\u2200 \\ud835\\udc91 \\u2208 \\u0394 \\u2062 ( T ) n for-all \\ud835\\udc91 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\\\forall\\\\boldsymbol{p}\\\\in\\\\Delta(T)^{n} \\u2200 bold_italic_p \\u2208 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , there exists a profile \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 of strategy mappings with \\u03c0 i : \\u211a + \\u2192 \\u211a + : subscript \\ud835\\udf0b \\ud835\\udc56 \\u2192 subscript \\u211a subscript \\u211a \\\\pi_{i}:\\\\mathbb{Q}_{+}\\\\to\\\\mathbb{Q}_{+} italic_\\u03c0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u2192 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT for every agent i \\ud835\\udc56 i italic_i (i.e., \\u03c0 \\u2062 ( \\ud835\\udc83 ) = ( \\u03c0 1 \\u2062 ( b 1 ) , \\u2026 , \\u03c0 n \\u2062 ( b n ) ) \\ud835\\udf0b \\ud835\\udc83 subscript \\ud835\\udf0b 1 subscript \\ud835\\udc4f 1 \\u2026 subscript \\ud835\\udf0b \\ud835\\udc5b subscript \\ud835\\udc4f \\ud835\\udc5b \\\\pi(\\\\boldsymbol{b})=(\\\\pi_{1}(b_{1}),\\\\ldots,\\\\pi_{n}(b_{n})) italic_\\u03c0 ( bold_italic_b ) = ( italic_\\u03c0 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , \\u2026 , italic_\\u03c0 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ) ), such that \\u2200 \\ud835\\udc83 \\u2208 \\u211a + n , q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) = q ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) formulae-sequence for-all \\ud835\\udc83 superscript subscript \\u211a \\ud835\\udc5b \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 ~ \\ud835\\udc5e \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 \\\\forall\\\\boldsymbol{b}\\\\in\\\\mathbb{Q}_{+}^{n},~{}q(\\\\boldsymbol{b},\\\\boldsymbol{p})% =\\\\tilde{q}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p}) \\u2200 bold_italic_b \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_q ( bold_italic_b , bold_italic_p ) = over~ start_ARG italic_q end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) and z \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) = z ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) . \\ud835\\udc67 \\ud835\\udc83 \\ud835\\udc91 ~ \\ud835\\udc67 \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 z(\\\\boldsymbol{b},\\\\boldsymbol{p})=\\\\tilde{z}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p}). italic_z ( bold_italic_b , bold_italic_p ) = over~ start_ARG italic_z end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) . Theorem 3.5 (Revelation Principle) . Any mechanism \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 with a consistent distribution aggregation function q \\ud835\\udc5e q italic_q and a monotone payment function z \\ud835\\udc67 z italic_z is strategically equivalent to a mechanism \\u2133 ~ = \\u27e8 q ~ , z ~ \\u27e9 ~ \\u2133 ~ \\ud835\\udc5e ~ \\ud835\\udc67 \\\\tilde{\\\\mathcal{M}}=\\\\langle\\\\tilde{q},\\\\tilde{z}\\\\rangle over~ start_ARG caligraphic_M end_ARG = \\u27e8 over~ start_ARG italic_q end_ARG , over~ start_ARG italic_z end_ARG \\u27e9 which has a monotone distribution aggregation function q ~ ~ \\ud835\\udc5e \\\\tilde{q} over~ start_ARG italic_q end_ARG and a monotone payment function z ~ ~ \\ud835\\udc67 \\\\tilde{z} over~ start_ARG italic_z end_ARG . Theorem 3.5 can be viewed as a revelation principle in the sense that it simplifies the design choice of aggregation functions. Monotone aggregation functions are a strict subset of consistent aggregation functions since monotonicity directly implies a total order over possible aggregated distributions Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = { q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) : b i \\u2208 \\u211a + } \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } , with the order naturally determined by the real-numbers\\u2019 order on i \\ud835\\udc56 i italic_i \\u2019s bid b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT hence this order will be consistent across different \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p . In this sense, one might think that consistency \\u2014 which does not impose any restriction when q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) is not strictly preferred over q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2014 might be a significantly weaker requirement on aggregation functions than monotonicity which requires a total and consistent order. Theorem 3.5 shows that this is not the case \\u2014 they are essentially the same as long as the natural incentive requirement of payment monotonicity is also imposed. The proof of Theorem 3.5 hinges on the following two lemmas, Lemma 3.6 and Lemma 3.7 . Together these two lemmas imply the existence of a strategy mapping, under which the resulting aggregation function becomes monotone. The proof of the theorem is completed by applying the same mapping to the payment function, and noting that this ensures payment monotonicity. We defer the formal proofs of these results to Appendix A . Lemma 3.6 . For any distribution aggregation function q \\ud835\\udc5e q italic_q , there exists a payment function z \\ud835\\udc67 z italic_z such that mechanism \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 is payment-monotone if and only if \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT establishes a total order over Q \\u2062 ( \\ud835\\udc1b \\u2212 i , \\ud835\\udc29 ) = { q \\u2062 ( b i , \\ud835\\udc1b \\u2212 i , \\ud835\\udc29 ) : b i \\u2208 \\u211a + } \\ud835\\udc44 subscript \\ud835\\udc1b \\ud835\\udc56 \\ud835\\udc29 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc1b \\ud835\\udc56 \\ud835\\udc29 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } for any fixed \\ud835\\udc1b \\u2212 i subscript \\ud835\\udc1b \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc29 \\ud835\\udc29 \\\\boldsymbol{p} bold_italic_p . Lemma 3.7 . Consider any consistent aggregation function q \\ud835\\udc5e q italic_q . Suppose \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT defines a total order over the aggregation set Q \\u2062 ( \\ud835\\udc1b \\u2212 i , \\ud835\\udc29 ) = { q \\u2062 ( b i , \\ud835\\udc1b \\u2212 i , \\ud835\\udc29 ) : b i \\u2208 \\u211a + } \\ud835\\udc44 subscript \\ud835\\udc1b \\ud835\\udc56 \\ud835\\udc29 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc1b \\ud835\\udc56 \\ud835\\udc29 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } induced by agent i \\ud835\\udc56 i italic_i \\u2019s bid for any fixed \\ud835\\udc1b \\u2212 i subscript \\ud835\\udc1b \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc29 \\ud835\\udc29 \\\\boldsymbol{p} bold_italic_p , then there exist a profile \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 of strategy mappings such that q \\u2062 ( \\ud835\\udc1b , \\ud835\\udc29 ) = q ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc1b ) , \\ud835\\udc29 ) \\ud835\\udc5e \\ud835\\udc1b \\ud835\\udc29 ~ \\ud835\\udc5e \\ud835\\udf0b \\ud835\\udc1b \\ud835\\udc29 q(\\\\boldsymbol{b},\\\\boldsymbol{p})=\\\\tilde{q}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p}) italic_q ( bold_italic_b , bold_italic_p ) = over~ start_ARG italic_q end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) for some monotone aggregation function q ~ \\u2062 ( \\u22c5 , \\u22c5 ) ~ \\ud835\\udc5e \\u22c5 \\u22c5 \\\\tilde{q}(\\\\cdot,\\\\cdot) over~ start_ARG italic_q end_ARG ( \\u22c5 , \\u22c5 ) . We conclude this subsection by giving two natural examples used in today\\u2019s machine learning practice: an example of a monotone aggregation function and a non-monotone one, both with respect to robust preferences (see Definition 2.1 ). Example 3.8 (Linear Aggregation) . Consider q \\ud835\\uddaa\\ud835\\uddab \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc83 \\ud835\\udc91 q_{\\\\mathsf{KL}}(\\\\boldsymbol{b},\\\\boldsymbol{p}) italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p ) defined as q \\ud835\\uddaa\\ud835\\uddab = 1 B \\u2062 \\u2211 i \\u2208 [ n ] b i \\u22c5 p i , where \\u2062 B = \\u2211 i \\u2208 [ n ] b i . formulae-sequence subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab 1 \\ud835\\udc35 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 where \\ud835\\udc35 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle q_{\\\\mathsf{KL}}=\\\\frac{1}{B}\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot p_{i},~{}\\\\text{% where}~{}B=\\\\sum_{i\\\\in[n]}b_{i}. italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_B end_ARG \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where italic_B = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . It is easy to verify that this is a monotone aggregation function with respect to robust preferences. Example 3.9 (Log-linear Aggregation) . Consider the aggregation function q \\u00af \\ud835\\uddaa\\ud835\\uddab \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc83 \\ud835\\udc91 \\\\bar{q}_{\\\\mathsf{KL}}(\\\\boldsymbol{b},\\\\boldsymbol{p}) over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p ) defined by the following equations: \\u2200 t \\u2208 T , ln \\u2061 q \\u00af \\ud835\\uddaa\\ud835\\uddab \\u2062 ( t ) = 1 B \\u2062 \\u2211 i \\u2208 [ n ] b i \\u22c5 ln \\u2061 p i \\u2062 ( t ) \\u2212 C , formulae-sequence for-all \\ud835\\udc61 \\ud835\\udc47 subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc61 1 \\ud835\\udc35 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\ud835\\udc36 \\\\textstyle\\\\forall t\\\\in T,~{}\\\\ln\\\\bar{q}_{\\\\mathsf{KL}}(t)=\\\\frac{1}{B}\\\\sum_{i\\\\in[% n]}b_{i}\\\\cdot\\\\ln p_{i}(t)-C, \\u2200 italic_t \\u2208 italic_T , roman_ln over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_t ) = divide start_ARG 1 end_ARG start_ARG italic_B end_ARG \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 roman_ln italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) - italic_C , where B = \\u2211 i \\u2208 [ n ] b i \\ud835\\udc35 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b subscript \\ud835\\udc4f \\ud835\\udc56 B=\\\\sum_{i\\\\in[n]}b_{i} italic_B = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and C = ln \\u2062 \\u2211 t \\u2208 T e 1 B \\u2062 \\u2211 i \\u2208 [ n ] b i \\u22c5 ln \\u2061 p i \\u2062 ( t ) \\ud835\\udc36 subscript \\ud835\\udc61 \\ud835\\udc47 superscript \\ud835\\udc52 1 \\ud835\\udc35 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 C=\\\\ln\\\\sum_{t\\\\in T}e^{\\\\frac{1}{B}\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot\\\\ln p_{i}(t)} italic_C = roman_ln \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_B end_ARG \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 roman_ln italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_POSTSUPERSCRIPT . The following two-agent example shows that q \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\\\bar{q}_{\\\\mathsf{KL}} over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT is not monotone: p 1 = ( .5 , .4 , .1 ) subscript \\ud835\\udc5d 1 .5 .4 .1 p_{1}=(.5,.4,.1) italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ( .5 , .4 , .1 ) and p 2 = ( .5 , .1 , .4 ) subscript \\ud835\\udc5d 2 .5 .1 .4 p_{2}=(.5,.1,.4) italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( .5 , .1 , .4 ) . When b 1 = b 2 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 b_{1}=b_{2} italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , q \\u00af \\ud835\\uddaa\\ud835\\uddab = ( .25 , .04 , .04 ) / .9 = ( 5 / 9 , 2 / 9 , 2 / 9 ) subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab .25 .04 .04 .9 5 9 2 9 2 9 \\\\bar{q}_{\\\\mathsf{KL}}=(\\\\sqrt{.25},\\\\sqrt{.04},\\\\sqrt{.04})/.9=(5/9,2/9,2/9) over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT = ( square-root start_ARG .25 end_ARG , square-root start_ARG .04 end_ARG , square-root start_ARG .04 end_ARG ) / .9 = ( 5 / 9 , 2 / 9 , 2 / 9 ) . Fix b 2 = 1 subscript \\ud835\\udc4f 2 1 b_{2}=1 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 , either b 1 \\u2192 0 \\u2192 subscript \\ud835\\udc4f 1 0 b_{1}\\\\rightarrow 0 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \\u2192 0 or b 1 \\u2192 \\u221e \\u2192 subscript \\ud835\\udc4f 1 b_{1}\\\\rightarrow\\\\infty italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \\u2192 \\u221e , q \\u00af \\ud835\\uddaa\\ud835\\uddab \\u2062 ( t 1 ) = .5 < 5 / 9 subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc61 1 .5 5 9 \\\\bar{q}_{\\\\mathsf{KL}}(t_{1})=.5<5/9 over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = .5 < 5 / 9 . Hence q \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\\\bar{q}_{\\\\mathsf{KL}} over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT is not monotone with respect to robust preferences. 3.3 Second Price Payment Rules Next, we investigate whether monotone aggregation functions admit a \\u201csecond-price\\u201d payment rule, capturing the Vickrey auction\\u2019s concept of the \\u201cminimum bid to win\\u201d. In the Vickrey auction, the payment corresponds to the critical bid where an agent transitions from losing to winning. To port this notion to our setting, we will show in Theorem 3.12 that, under robust preferences, any monotone aggregation rule can be written as a distribution over deterministic allocations from bids to tokens such that there is a critical bid where the allocation transitions from a less preferred to a more preferred token. Such a critical bid becomes then a natural candidate for the payment. We will show that besides being payment monotone it has other desirable properties, such as a Myerson-style characterization (Myerson, 1981 ) in terms of the total variation distance between the preferred distribution and the outcome. To define our payment rule, we first introduce the notion of stable sampling. 3.3.1 Stable Sampling To design the payment for bidder i \\ud835\\udc56 i italic_i , we analyze a monotone distribution aggregation function q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 q(\\\\boldsymbol{b},\\\\boldsymbol{p}) italic_q ( bold_italic_b , bold_italic_p ) from i \\ud835\\udc56 i italic_i \\u2019s perspective, fixing the distributions \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p and the bids of other agents \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT . To simplify the notation, we refer to q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) as q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . We define an implementation of q \\u2062 ( \\u22c5 ) \\ud835\\udc5e \\u22c5 q(\\\\cdot) italic_q ( \\u22c5 ) as a function \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 that maps b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and an exogenous random variable r \\u223c \\u211b similar-to \\ud835\\udc5f \\u211b r\\\\sim\\\\mathcal{R} italic_r \\u223c caligraphic_R (independent of \\ud835\\udc83 \\ud835\\udc83 \\\\boldsymbol{b} bold_italic_b and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p ) to a token t \\u2208 T \\ud835\\udc61 \\ud835\\udc47 t\\\\in T italic_t \\u2208 italic_T . Here, r \\ud835\\udc5f r italic_r is the random source used for implementing the random sampling of token t \\ud835\\udc61 t italic_t . Hence when r \\ud835\\udc5f r italic_r is fixed, \\u03c3 \\u2062 ( b i , r ) \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f \\\\sigma(b_{i},r) italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) is fully deterministic. We say that \\u03c3 : \\u211a + \\u00d7 \\u211b \\u2192 T : \\ud835\\udf0e \\u2192 subscript \\u211a \\u211b \\ud835\\udc47 \\\\sigma:\\\\mathbb{Q}_{+}\\\\times\\\\mathcal{R}\\\\rightarrow T italic_\\u03c3 : blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u00d7 caligraphic_R \\u2192 italic_T is a valid implementation of q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) if: Pr r \\u223c R \\u2061 [ \\u03c3 \\u2062 ( b i , r ) = t ] = q t \\u2062 ( b i ) , \\u2200 t \\u2208 T . formulae-sequence subscript Pr similar-to \\ud835\\udc5f \\ud835\\udc45 \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 for-all \\ud835\\udc61 \\ud835\\udc47 \\\\textstyle\\\\Pr_{r\\\\sim R}[\\\\sigma(b_{i},r)=t]=q_{t}(b_{i}),\\\\forall t\\\\in T. roman_Pr start_POSTSUBSCRIPT italic_r \\u223c italic_R end_POSTSUBSCRIPT [ italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) = italic_t ] = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , \\u2200 italic_t \\u2208 italic_T . Next we define what it means for an implementation to be a \\u201cstable\\u201d sampling. It is useful to partition the token set T \\ud835\\udc47 T italic_T into T + = { t \\u2208 T : q t \\u2062 ( 0 ) \\u2264 ( p i ) t } subscript \\ud835\\udc47 conditional-set \\ud835\\udc61 \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 T_{+}=\\\\{t\\\\in T:q_{t}(0)\\\\leq(p_{i})_{t}\\\\} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT = { italic_t \\u2208 italic_T : italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) \\u2264 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } and T \\u2212 = { t \\u2208 T : q t \\u2062 ( 0 ) > ( p i ) t } subscript \\ud835\\udc47 conditional-set \\ud835\\udc61 \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 T_{-}=\\\\{t\\\\in T:q_{t}(0)>(p_{i})_{t}\\\\} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT = { italic_t \\u2208 italic_T : italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) > ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } corresponding to undersampled ( T + subscript \\ud835\\udc47 T_{+} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ) and oversampled ( T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT ) tokens. The monotonicity of aggregation function q \\ud835\\udc5e q italic_q turns out to be equivalent to the monotonicity of q t \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 q_{t}(b_{i}) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , as formalized in the following lemma (proof in Appendix B ). Lemma 3.10 . Under agents\\u2019 robust preferences, a distribution aggregation function q \\ud835\\udc5e q italic_q is monotone, if and only if for every agent i \\ud835\\udc56 i italic_i and b i \\u2208 \\u211d + subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211d b_{i}\\\\in\\\\mathbb{R}_{+} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , 1. \\u2200 t \\u2208 T + for-all \\ud835\\udc61 subscript \\ud835\\udc47 \\\\forall t\\\\in T_{+} \\u2200 italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , q t \\u2062 ( b i ) \\u2264 ( p i ) t subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i})\\\\leq(p_{i})_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u2264 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and q t subscript \\ud835\\udc5e \\ud835\\udc61 q_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT weakly increases in b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ; 2. \\u2200 t \\u2208 T \\u2212 for-all \\ud835\\udc61 subscript \\ud835\\udc47 \\\\forall t\\\\in T_{-} \\u2200 italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT , q t \\u2062 ( b i ) \\u2265 ( p i ) t subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i})\\\\geq(p_{i})_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u2265 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and q t subscript \\ud835\\udc5e \\ud835\\udc61 q_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT weakly decreases in b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . We can now define the key notion of stable sampling, and state and prove our main result below. Definition 3.11 (Stable Sampling) . Let q i \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 q_{i}(b_{i}) italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) be an aggregation function obtained by fixing \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p , and let T + subscript \\ud835\\udc47 T_{+} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT be the sets of undersampled and oversampled tokens for agent i \\ud835\\udc56 i italic_i . Then we say that an implementation \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 is stable with respect to aggregation function q \\ud835\\udc5e q italic_q if for any r \\u2208 \\u211b \\ud835\\udc5f \\u211b r\\\\in\\\\mathcal{R} italic_r \\u2208 caligraphic_R there are two tokens u r \\u2208 T + subscript \\ud835\\udc62 \\ud835\\udc5f subscript \\ud835\\udc47 u_{r}\\\\in T_{+} italic_u start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and o r \\u2208 T \\u2212 subscript \\ud835\\udc5c \\ud835\\udc5f subscript \\ud835\\udc47 o_{r}\\\\in T_{-} italic_o start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT and a threshold \\u03b8 r \\u2208 \\u211a + \\u222a { \\u221e } subscript \\ud835\\udf03 \\ud835\\udc5f subscript \\u211a \\\\theta_{r}\\\\in\\\\mathbb{Q}_{+}\\\\cup\\\\{\\\\infty\\\\} italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u222a { \\u221e } such that: \\u03c3 \\u2062 ( b i , r ) = o r , if \\u2062 b i < \\u03b8 r ; and \\u2062 \\u03c3 \\u2062 ( b i , r ) = u r , if \\u2062 b i \\u2265 \\u03b8 r . formulae-sequence \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f subscript \\ud835\\udc5c \\ud835\\udc5f formulae-sequence if subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udf03 \\ud835\\udc5f formulae-sequence and \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f subscript \\ud835\\udc62 \\ud835\\udc5f if subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udf03 \\ud835\\udc5f \\\\sigma(b_{i},r)=o_{r},~{}\\\\text{if}~{}b_{i}<\\\\theta_{r};~{}\\\\text{and}~{}\\\\sigma(b% _{i},r)=u_{r},~{}\\\\text{if}~{}b_{i}\\\\geq\\\\theta_{r}. italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) = italic_o start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , if italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ; and italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) = italic_u start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , if italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT . Here is an illustrative example of stable sampling for a simple distribution supported on two tokens: one undersampled token u \\ud835\\udc62 u italic_u with probability q u \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc62 subscript \\ud835\\udc4f \\ud835\\udc56 q_{u}(b_{i}) italic_q start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and an overampled token o \\ud835\\udc5c o italic_o with probability q o \\u2062 ( b i ) = 1 \\u2212 q u \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc5c subscript \\ud835\\udc4f \\ud835\\udc56 1 subscript \\ud835\\udc5e \\ud835\\udc62 subscript \\ud835\\udc4f \\ud835\\udc56 q_{o}(b_{i})=1-q_{u}(b_{i}) italic_q start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = 1 - italic_q start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . Monotonicity of q \\ud835\\udc5e q italic_q implies q u \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc62 subscript \\ud835\\udc4f \\ud835\\udc56 q_{u}(b_{i}) italic_q start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) weakly increases in b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and q o \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc5c subscript \\ud835\\udc4f \\ud835\\udc56 q_{o}(b_{i}) italic_q start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) weakly decreases. Sample r \\ud835\\udc5f r italic_r uniformly from [ 0 , 1 ] 0 1 [0,1] [ 0 , 1 ] . For any b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , if q o \\u2062 ( b i ) > r subscript \\ud835\\udc5e \\ud835\\udc5c subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f q_{o}(b_{i})>r italic_q start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) > italic_r assign o \\ud835\\udc5c o italic_o ; assign u \\ud835\\udc62 u italic_u otherwise. Note that this implementation is: (i) deterministic for fixed r \\ud835\\udc5f r italic_r ; (ii) transits from token o \\ud835\\udc5c o italic_o to u \\ud835\\udc62 u italic_u as b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT increases (hence q o \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc5c subscript \\ud835\\udc4f \\ud835\\udc56 q_{o}(b_{i}) italic_q start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) decreases) under any fixed r \\ud835\\udc5f r italic_r ; (iii) matches the probabilities of q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in expectation for any b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . The following theorem generalizes this to any number of tokens (proof in Appendix B ). Theorem 3.12 . Given a monotone distribution aggregation function q \\ud835\\udc5e q italic_q then for any agent i \\ud835\\udc56 i italic_i with robust preferences and fixed \\ud835\\udc1b \\u2212 i subscript \\ud835\\udc1b \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc29 \\ud835\\udc29 \\\\boldsymbol{p} bold_italic_p there always exists a stable implementation \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 of q \\ud835\\udc5e q italic_q . 3.3.2 A Second Price Rule via Stable Sampling A stable implementation of a monotone aggregation rule naturally leads to a second-price payment rule: for any given randomness r \\ud835\\udc5f r italic_r , if the oversampled token o r subscript \\ud835\\udc5c \\ud835\\udc5f o_{r} italic_o start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is sampled, the agent pays zero as it is the same token that would have been sampled under randomness r \\ud835\\udc5f r italic_r if their bid was zero. If the agent\\u2019s bid was high enough to move from the oversampled o r subscript \\ud835\\udc5c \\ud835\\udc5f o_{r} italic_o start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT to the undersampled token u r subscript \\ud835\\udc62 \\ud835\\udc5f u_{r} italic_u start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , then the agent pays the critical bid \\u03b8 r subscript \\ud835\\udf03 \\ud835\\udc5f \\\\theta_{r} italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT . Perhaps surprisingly, the expected payment induced by the second price rule described above does not depend on the actual implementation of the sampling algorithm so long as it is stable in the sense of Definition 3.11 . The expected payment is proportional to the extent to which the sampling shifts the distribution q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) towards the desired distribution p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT increases and, interestingly, admits an expression simillar to the standard Myersonian payment as a function of allocations (Myerson, 1981 ) in which the allocation probability is replaced by the total variation distance between the agent\\u2019s preferred distribution p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and the implemented distribution q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . Proposition 3.13 . Consider an arbitrary stable sampling implementation of q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and the induced second price rule using the critical bid \\u03b8 r subscript \\ud835\\udf03 \\ud835\\udc5f \\\\theta_{r} italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT as described above. Then the expected payment satisfies z i \\u2062 ( b i ) = 1 2 \\u2062 \\u222b 0 b i [ \\u2016 q \\u2062 ( b i ) \\u2212 p i \\u2016 1 \\u2212 \\u2016 q \\u2062 ( b \\u2032 ) \\u2212 p i \\u2016 1 ] \\u2062 d b \\u2032 , \\u2200 b i \\u2208 \\u211a + . formulae-sequence subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 1 2 superscript subscript 0 subscript \\ud835\\udc4f \\ud835\\udc56 delimited-[] subscript norm \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 1 subscript norm \\ud835\\udc5e superscript \\ud835\\udc4f \\u2032 subscript \\ud835\\udc5d \\ud835\\udc56 1 differential-d superscript \\ud835\\udc4f \\u2032 for-all subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a z_{i}(b_{i})=\\\\frac{1}{2}\\\\int_{0}^{b_{i}}\\\\big{[}\\\\|q(b_{i})-p_{i}\\\\|_{1}-\\\\|q(b^{% \\\\prime})-p_{i}\\\\|_{1}\\\\big{]}\\\\mathrm{d}b^{\\\\prime},\\\\qquad\\\\forall b_{i}\\\\in\\\\mathbb{% Q}_{+}. italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT [ \\u2225 italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - \\u2225 italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] roman_d italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , \\u2200 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT . Proof. We again omit the terms \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p since they are fixed in each context. If a token t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT is sampled, the payment is naturally \\u03b6 i \\u2062 ( b i , t ) = 0 subscript \\ud835\\udf01 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc61 0 \\\\zeta_{i}(b_{i},t)=0 italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) = 0 . For a token t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT we have: \\u03b6 i \\u2062 ( b i , t ) \\u2062 q t \\u2062 ( b i ) = \\ud835\\udd3c r \\u2061 [ \\u03b8 r \\u22c5 \\ud835\\udfcf \\u2062 { \\u03c3 \\u2062 ( b i , r ) = t } ] subscript \\ud835\\udf01 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udd3c \\ud835\\udc5f \\u22c5 subscript \\ud835\\udf03 \\ud835\\udc5f 1 \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f \\ud835\\udc61 \\\\displaystyle\\\\zeta_{i}(b_{i},t)q_{t}(b_{i})=\\\\textstyle\\\\operatorname{\\\\mathbb{E}% }_{r}[\\\\theta_{r}\\\\cdot\\\\mathbf{1}\\\\{\\\\sigma(b_{i},r)=t\\\\}] italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = blackboard_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT [ italic_\\u03b8 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 bold_1 { italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) = italic_t } ] = \\\\displaystyle= = \\ud835\\udd3c r \\u2062 \\u222b 0 b i [ \\ud835\\udfcf \\u2062 { \\u03c3 \\u2062 ( b i , r ) = t } \\u2212 \\ud835\\udfcf \\u2062 { \\u03c3 \\u2062 ( b \\u2032 , r ) = t } ] \\u2062 d b \\u2032 subscript \\ud835\\udd3c \\ud835\\udc5f superscript subscript 0 subscript \\ud835\\udc4f \\ud835\\udc56 delimited-[] 1 \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f \\ud835\\udc61 1 \\ud835\\udf0e superscript \\ud835\\udc4f \\u2032 \\ud835\\udc5f \\ud835\\udc61 differential-d superscript \\ud835\\udc4f \\u2032 \\\\displaystyle\\\\textstyle\\\\operatorname{\\\\mathbb{E}}_{r}\\\\int_{0}^{b_{i}}\\\\big{[}% \\\\mathbf{1}\\\\{\\\\sigma(b_{i},r)=t\\\\}-\\\\mathbf{1}\\\\{\\\\sigma(b^{\\\\prime},r)=t\\\\}\\\\big{]}% \\\\mathrm{d}b^{\\\\prime} blackboard_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT [ bold_1 { italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) = italic_t } - bold_1 { italic_\\u03c3 ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , italic_r ) = italic_t } ] roman_d italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT = \\\\displaystyle= = \\u222b 0 b i [ q t \\u2062 ( b i ) \\u2212 q t \\u2062 ( b \\u2032 ) ] \\u2062 d b \\u2032 . superscript subscript 0 subscript \\ud835\\udc4f \\ud835\\udc56 delimited-[] subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5e \\ud835\\udc61 superscript \\ud835\\udc4f \\u2032 differential-d superscript \\ud835\\udc4f \\u2032 \\\\displaystyle\\\\textstyle\\\\int_{0}^{b_{i}}[q_{t}(b_{i})-q_{t}(b^{\\\\prime})]\\\\mathrm% {d}b^{\\\\prime}. \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT [ italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] roman_d italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT . Hence: z i \\u2062 ( b i ) subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\displaystyle z_{i}(b_{i}) italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2211 t \\u03b6 i \\u2062 ( b i , t ) \\u2062 q t \\u2062 ( b i ) = \\u222b 0 b i [ \\u2211 t \\u2208 T + q t \\u2062 ( b i ) \\u2212 \\u2211 t \\u2208 T + q t \\u2062 ( b \\u2032 ) ] \\u2062 d b \\u2032 absent subscript \\ud835\\udc61 subscript \\ud835\\udf01 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 superscript subscript 0 subscript \\ud835\\udc4f \\ud835\\udc56 delimited-[] subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 superscript \\ud835\\udc4f \\u2032 differential-d superscript \\ud835\\udc4f \\u2032 \\\\displaystyle\\\\textstyle=\\\\sum_{t}\\\\zeta_{i}(b_{i},t)q_{t}(b_{i})\\\\textstyle=\\\\int_% {0}^{b_{i}}\\\\bigg{[}\\\\sum_{t\\\\in T_{+}}q_{t}(b_{i})-\\\\sum_{t\\\\in T_{+}}q_{t}(b^{% \\\\prime})\\\\bigg{]}\\\\mathrm{d}b^{\\\\prime} = \\u2211 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_\\u03b6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] roman_d italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT = 1 2 \\u2062 \\u222b 0 b i [ \\u2016 q \\u2062 ( b i ) \\u2212 p i \\u2016 1 \\u2212 \\u2016 q \\u2062 ( b \\u2032 ) \\u2212 p i \\u2016 1 ] \\u2062 d b \\u2032 , absent 1 2 superscript subscript 0 subscript \\ud835\\udc4f \\ud835\\udc56 delimited-[] subscript norm \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 1 subscript norm \\ud835\\udc5e superscript \\ud835\\udc4f \\u2032 subscript \\ud835\\udc5d \\ud835\\udc56 1 differential-d superscript \\ud835\\udc4f \\u2032 \\\\displaystyle\\\\textstyle=\\\\frac{1}{2}\\\\int_{0}^{b_{i}}\\\\big{[}\\\\|q(b_{i})-p_{i}\\\\|_{% 1}-\\\\|q(b^{\\\\prime})-p_{i}\\\\|_{1}\\\\big{]}\\\\mathrm{d}b^{\\\\prime}, = divide start_ARG 1 end_ARG start_ARG 2 end_ARG \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT [ \\u2225 italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - \\u2225 italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] roman_d italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , as claimed. \\u220e Counterfactuals. The practical advantage of a stable sampling implementation coupled with a second price rule is to offer advertisers a description where it is clear that they only pay if they can improve the outcome. Moreover, with a fixed r \\ud835\\udc5f r italic_r , advertisers can easily evaluate counterfactuals, as each token can only have one of two possible outcomes, simplifying the comparison. Universally Stable Sampling. We chose to define stable sampling as a single-agent algorithm with fixed \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT . One may define a universal stable implementation as \\u03c3 \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf : \\u211a n \\u00d7 \\u211b \\u2192 T : superscript \\ud835\\udf0e \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\u2192 superscript \\u211a \\ud835\\udc5b \\u211b \\ud835\\udc47 \\\\sigma^{\\\\mathsf{univ}}:\\\\mathbb{Q}^{n}\\\\times\\\\mathcal{R}\\\\rightarrow T italic_\\u03c3 start_POSTSUPERSCRIPT sansserif_univ end_POSTSUPERSCRIPT : blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \\u00d7 caligraphic_R \\u2192 italic_T such that \\u2200 \\ud835\\udc83 \\u2208 \\u211a + n , t \\u2208 T , Pr r \\u223c R \\u2061 [ \\u03c3 \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\u2062 ( \\ud835\\udc83 , r ) = t ] = q t , formulae-sequence for-all \\ud835\\udc83 subscript superscript \\u211a \\ud835\\udc5b formulae-sequence \\ud835\\udc61 \\ud835\\udc47 subscript Pr similar-to \\ud835\\udc5f \\ud835\\udc45 superscript \\ud835\\udf0e \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\ud835\\udc83 \\ud835\\udc5f \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 \\\\displaystyle\\\\textstyle\\\\forall\\\\boldsymbol{b}\\\\in\\\\mathbb{Q}^{n}_{+},t\\\\in T,~{}% \\\\Pr_{r\\\\sim R}[\\\\sigma^{\\\\mathsf{univ}}(\\\\boldsymbol{b},r)=t]=q_{t}, \\u2200 bold_italic_b \\u2208 blackboard_Q start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , italic_t \\u2208 italic_T , roman_Pr start_POSTSUBSCRIPT italic_r \\u223c italic_R end_POSTSUBSCRIPT [ italic_\\u03c3 start_POSTSUPERSCRIPT sansserif_univ end_POSTSUPERSCRIPT ( bold_italic_b , italic_r ) = italic_t ] = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , and for any i \\ud835\\udc56 i italic_i and \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , \\u03c3 \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\u2062 ( \\u22c5 , \\ud835\\udc83 \\u2212 i , r ) superscript \\ud835\\udf0e \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\u22c5 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc5f \\\\sigma^{\\\\mathsf{univ}}(\\\\cdot,\\\\boldsymbol{b}_{-i},r) italic_\\u03c3 start_POSTSUPERSCRIPT sansserif_univ end_POSTSUPERSCRIPT ( \\u22c5 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , italic_r ) is stable. In Appendix C , we provide counter-examples where such \\u03c3 \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf superscript \\ud835\\udf0e \\ud835\\uddce\\ud835\\uddc7\\ud835\\uddc2\\ud835\\uddcf \\\\sigma^{\\\\mathsf{univ}} italic_\\u03c3 start_POSTSUPERSCRIPT sansserif_univ end_POSTSUPERSCRIPT do not always exist. 4 Design of Aggregation Functions In the previous section, we discussed payment schemes and incentive properties assuming we have an aggregation function. Here we investigate the design of aggregation functions. We adopt two guiding principles: (1) We first define an aggregated loss function to model the overall satisfaction of the agents with the final distribution q \\ud835\\udc5e q italic_q , weighted by their bids b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . The aggregated loss function has the form: Loss \\u2062 ( \\ud835\\udc91 , \\ud835\\udc83 , q ) = \\u2211 i b i \\u2062 \\u03c1 \\u2062 ( p i , q ) , Loss \\ud835\\udc91 \\ud835\\udc83 \\ud835\\udc5e subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udf0c subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc5e \\\\textstyle\\\\textsc{Loss}(\\\\boldsymbol{p},\\\\boldsymbol{b},q)=\\\\sum_{i}b_{i}\\\\rho(p_{% i},q), Loss ( bold_italic_p , bold_italic_b , italic_q ) = \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\\u03c1 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q ) , where \\u03c1 : \\u0394 \\u2062 ( T ) \\u00d7 \\u0394 \\u2062 ( T ) \\u2192 \\u211d : \\ud835\\udf0c \\u2192 \\u0394 \\ud835\\udc47 \\u0394 \\ud835\\udc47 \\u211d \\\\rho:\\\\Delta(T)\\\\times\\\\Delta(T)\\\\rightarrow\\\\mathbb{R} italic_\\u03c1 : roman_\\u0394 ( italic_T ) \\u00d7 roman_\\u0394 ( italic_T ) \\u2192 blackboard_R indicates how different the distribution q \\ud835\\udc5e q italic_q is from the preferred p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . (2) The second is to define the function \\u03c1 \\ud835\\udf0c \\\\rho italic_\\u03c1 based on the typical loss functions in LLM training. 4.1 Review of LLM Training So far we have assumed that an LLM f : T \\u2217 \\u2192 \\u0394 \\u2062 ( T ) : \\ud835\\udc53 \\u2192 superscript \\ud835\\udc47 \\u0394 \\ud835\\udc47 f:T^{*}\\\\rightarrow\\\\Delta(T) italic_f : italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) is already trained. In order to discuss the training process, it is useful to recall that an LLM is a neural network parameterized by a vector of weights W \\u2208 \\u211d N \\ud835\\udc4a superscript \\u211d \\ud835\\udc41 W\\\\in\\\\mathbb{R}^{N} italic_W \\u2208 blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT in a very high dimensional space. To discuss training, it is useful to think of f \\ud835\\udc53 f italic_f as a function of both input and weights: f : T \\u2217 \\u00d7 \\u211d N \\u2192 \\u0394 \\u2062 ( T ) . : \\ud835\\udc53 \\u2192 superscript \\ud835\\udc47 superscript \\u211d \\ud835\\udc41 \\u0394 \\ud835\\udc47 f:T^{*}\\\\times\\\\mathbb{R}^{N}\\\\rightarrow\\\\Delta(T). italic_f : italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u00d7 blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) . We represent the second argument by a superscript W \\ud835\\udc4a W italic_W . Training is to optimize W \\ud835\\udc4a W italic_W such that f W \\u2062 ( \\u22c5 ) superscript \\ud835\\udc53 \\ud835\\udc4a \\u22c5 f^{W}(\\\\cdot) italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ( \\u22c5 ) minimizes a certain loss function over a dataset. A dataset is a sequence of pairs ( x i , y i ) subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc66 \\ud835\\udc56 (x_{i},y_{i}) ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) with x i \\u2208 T \\u2217 subscript \\ud835\\udc65 \\ud835\\udc56 superscript \\ud835\\udc47 x_{i}\\\\in T^{*} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT (input sequence) and y i \\u2208 T subscript \\ud835\\udc66 \\ud835\\udc56 \\ud835\\udc47 y_{i}\\\\in T italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 italic_T (label), and a loss function is a function \\u2113 : T \\u00d7 \\u0394 \\u2062 ( T ) \\u2192 \\u211d : \\u2113 \\u2192 \\ud835\\udc47 \\u0394 \\ud835\\udc47 \\u211d \\\\ell:T\\\\times\\\\Delta(T)\\\\rightarrow\\\\mathbb{R} roman_\\u2113 : italic_T \\u00d7 roman_\\u0394 ( italic_T ) \\u2192 blackboard_R . A network typically seeks to minimize: min W \\u2062 \\u2211 i \\u2113 \\u2062 ( y i , f W \\u2062 ( x i ) ) . subscript \\ud835\\udc4a subscript \\ud835\\udc56 \\u2113 subscript \\ud835\\udc66 \\ud835\\udc56 superscript \\ud835\\udc53 \\ud835\\udc4a subscript \\ud835\\udc65 \\ud835\\udc56 \\\\textstyle\\\\min_{W}\\\\sum_{i}\\\\ell(y_{i},f^{W}(x_{i})). roman_min start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_\\u2113 ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) . A widely used loss function in the first stage is the KL-divergence: \\u2113 \\ud835\\uddaa\\ud835\\uddab \\u2062 ( y , x ) = \\u2212 ln \\u2061 [ f W \\u2062 ( y | x ) ] , subscript \\u2113 \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc66 \\ud835\\udc65 superscript \\ud835\\udc53 \\ud835\\udc4a conditional \\ud835\\udc66 \\ud835\\udc65 \\\\ell_{\\\\mathsf{KL}}(y,x)=-\\\\ln[f^{W}(y|x)], roman_\\u2113 start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_y , italic_x ) = - roman_ln [ italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ( italic_y | italic_x ) ] , where we use the notation f \\u2062 ( y | x ) \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 f(y|x) italic_f ( italic_y | italic_x ) to represent the probability that a token y \\u2208 T \\ud835\\udc66 \\ud835\\udc47 y\\\\in T italic_y \\u2208 italic_T is sampled from f \\u2062 ( x ) \\u2208 \\u0394 \\u2062 ( T ) . \\ud835\\udc53 \\ud835\\udc65 \\u0394 \\ud835\\udc47 f(x)\\\\in\\\\Delta(T). italic_f ( italic_x ) \\u2208 roman_\\u0394 ( italic_T ) . It is useful to think of this problem in the limit where the size of the dataset grows to infinity and it can be effectively thought of as a full-support distribution over T \\u2217 \\u00d7 T superscript \\ud835\\udc47 \\ud835\\udc47 T^{*}\\\\times T italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u00d7 italic_T . In that setting, we can represent the dataset as a distribution \\u03bc \\u2208 \\u0394 \\u2062 ( T \\u2217 \\u00d7 T ) \\ud835\\udf07 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc47 \\\\mu\\\\in\\\\Delta(T^{*}\\\\times T) italic_\\u03bc \\u2208 roman_\\u0394 ( italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u00d7 italic_T ) over input-label pairs ( x , y ) \\u2208 T \\u2217 \\u00d7 T \\ud835\\udc65 \\ud835\\udc66 superscript \\ud835\\udc47 \\ud835\\udc47 (x,y)\\\\in T^{*}\\\\times T ( italic_x , italic_y ) \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u00d7 italic_T . We will write \\u03bc \\u2062 ( x ) = \\u2211 y \\u03bc \\u2062 ( x , y ) \\ud835\\udf07 \\ud835\\udc65 subscript \\ud835\\udc66 \\ud835\\udf07 \\ud835\\udc65 \\ud835\\udc66 \\\\mu(x)=\\\\sum_{y}\\\\mu(x,y) italic_\\u03bc ( italic_x ) = \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_\\u03bc ( italic_x , italic_y ) to denote the marginal distribution on x \\ud835\\udc65 x italic_x and \\u03bc ( \\u22c5 | x ) \\\\mu(\\\\cdot|x) italic_\\u03bc ( \\u22c5 | italic_x ) to denote the conditional distribution of labels given an input x \\ud835\\udc65 x italic_x . Then min W \\u2112 KL \\u03bc ( f W ) , \\u2112 KL \\u03bc ( f ) := \\u2211 x \\u2208 T \\u2217 \\u03bc ( x ) \\u22c5 D \\ud835\\uddaa\\ud835\\uddab ( \\u03bc ( \\u22c5 | x ) \\u2225 f ( x ) ) , \\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\!\\\\displaystyle{\\\\min_{W}}\\\\textstyle\\\\mathcal{L}_{\\\\textsf{% KL}}^{\\\\mu}(f^{W}),~{}~{}~{}\\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\mu}(f):={\\\\sum_{x\\\\in T^{% *}}}\\\\mu(x)\\\\cdot D_{\\\\mathsf{KL}}(\\\\mu(\\\\cdot|x)\\\\|f(x)), roman_min start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT ( italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ) , caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT ( italic_f ) := \\u2211 start_POSTSUBSCRIPT italic_x \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03bc ( italic_x ) \\u22c5 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_\\u03bc ( \\u22c5 | italic_x ) \\u2225 italic_f ( italic_x ) ) , (KL) where D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( p \\u2225 q ) = \\u2211 t p \\u2062 ( t ) \\u2062 ln \\u2061 p \\u2062 ( t ) q \\u2062 ( t ) subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\ud835\\udc5d \\ud835\\udc5e subscript \\ud835\\udc61 \\ud835\\udc5d \\ud835\\udc61 \\ud835\\udc5d \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc61 D_{\\\\mathsf{KL}}(p\\\\|q)=\\\\sum_{t}p(t)\\\\ln\\\\frac{p(t)}{q(t)} italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_p \\u2225 italic_q ) = \\u2211 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p ( italic_t ) roman_ln divide start_ARG italic_p ( italic_t ) end_ARG start_ARG italic_q ( italic_t ) end_ARG is the KL-divergence. LLMs are typically trained through successive refinement of weights: W \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe \\u2192 W \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2192 W \\ud835\\uddb1\\ud835\\uddab \\u2192 superscript \\ud835\\udc4a \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe superscript \\ud835\\udc4a \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2192 superscript \\ud835\\udc4a \\ud835\\uddb1\\ud835\\uddab W^{\\\\mathsf{pre}}\\\\rightarrow W^{\\\\mathsf{SFT}}\\\\rightarrow W^{\\\\mathsf{RL}} italic_W start_POSTSUPERSCRIPT sansserif_pre end_POSTSUPERSCRIPT \\u2192 italic_W start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT \\u2192 italic_W start_POSTSUPERSCRIPT sansserif_RL end_POSTSUPERSCRIPT . In pre-training we compute W \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe superscript \\ud835\\udc4a \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe W^{\\\\mathsf{pre}} italic_W start_POSTSUPERSCRIPT sansserif_pre end_POSTSUPERSCRIPT by solving problem ( KL ) on a generic dataset \\u03bc \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe superscript \\ud835\\udf07 \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe \\\\mu^{\\\\mathsf{pre}} italic_\\u03bc start_POSTSUPERSCRIPT sansserif_pre end_POSTSUPERSCRIPT via stochastic gradient descent. In the second stage, we initialize the weights as W = W \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe \\ud835\\udc4a superscript \\ud835\\udc4a \\ud835\\uddc9\\ud835\\uddcb\\ud835\\uddbe W=W^{\\\\mathsf{pre}} italic_W = italic_W start_POSTSUPERSCRIPT sansserif_pre end_POSTSUPERSCRIPT and run stochastic gradient descent to solve the same problem ( KL ) on a more specialized dataset \\u03bc \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 superscript \\ud835\\udf07 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\\\mu^{\\\\mathsf{SFT}} italic_\\u03bc start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT . In other words, we solve the same problem on two different datasets. The problem in the RLHF stage is different. The dataset only contains x \\ud835\\udc65 x italic_x (still represented by \\u03bc \\ud835\\udf07 \\\\mu italic_\\u03bc ) and for any y \\ud835\\udc66 y italic_y , we have a function r \\u2062 ( x , y ) \\ud835\\udc5f \\ud835\\udc65 \\ud835\\udc66 r(x,y) italic_r ( italic_x , italic_y ) giving the reward of mapping x \\ud835\\udc65 x italic_x to y \\ud835\\udc66 y italic_y . Then W \\ud835\\uddb1\\ud835\\uddab superscript \\ud835\\udc4a \\ud835\\uddb1\\ud835\\uddab W^{\\\\mathsf{RL}} italic_W start_POSTSUPERSCRIPT sansserif_RL end_POSTSUPERSCRIPT is obtained by maximizing reward while minimizing the distance to the function f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 f^{\\\\mathsf{SFT}} italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT from previous stages (the PPO algorithm (Schulman et al . , 2017 ; Ouyang et al . , 2022 ) ): max W \\u2061 \\u2112 RL \\u03bc , r \\u2062 ( f W ) , subscript \\ud835\\udc4a superscript subscript \\u2112 RL \\ud835\\udf07 \\ud835\\udc5f superscript \\ud835\\udc53 \\ud835\\udc4a \\\\displaystyle\\\\max_{W}\\\\mathcal{L}_{\\\\textsf{RL}}^{\\\\mu,r}(f^{W}), roman_max start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT RL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc , italic_r end_POSTSUPERSCRIPT ( italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ) , (RL) \\u2112 RL \\u03bc , r \\u2062 ( f ) := \\u2211 x \\u2208 T \\u2217 \\u03bc \\u2062 ( x ) \\u2062 [ \\u2211 y r \\u2062 ( x , y ) \\u2062 f \\u2062 ( y | x ) \\u2212 \\u03b2 \\u2062 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f \\u2062 ( x ) \\u2225 f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( x ) ) ] . assign superscript subscript \\u2112 RL \\ud835\\udf07 \\ud835\\udc5f \\ud835\\udc53 subscript \\ud835\\udc65 superscript \\ud835\\udc47 \\ud835\\udf07 \\ud835\\udc65 delimited-[] subscript \\ud835\\udc66 \\ud835\\udc5f \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\ud835\\udefd subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\ud835\\udc53 \\ud835\\udc65 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\ud835\\udc65 \\\\displaystyle\\\\mathcal{L}_{\\\\textsf{RL}}^{\\\\mu,r}(f):=\\\\sum_{x\\\\in T^{*}}\\\\mu(x)% \\\\Bigl{[}\\\\sum_{y}r(x,y)f(y|x)-\\\\beta D_{\\\\mathsf{KL}}(f(x)\\\\|f^{\\\\mathsf{SFT}}(x))% \\\\Bigr{]}. caligraphic_L start_POSTSUBSCRIPT RL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc , italic_r end_POSTSUPERSCRIPT ( italic_f ) := \\u2211 start_POSTSUBSCRIPT italic_x \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03bc ( italic_x ) [ \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_r ( italic_x , italic_y ) italic_f ( italic_y | italic_x ) - italic_\\u03b2 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f ( italic_x ) \\u2225 italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_x ) ) ] . KL-divergence and Entropy. For the next propositions it is useful to recall that the entropy of a distribution p \\u2208 \\u0394 \\u2062 ( T ) \\ud835\\udc5d \\u0394 \\ud835\\udc47 p\\\\in\\\\Delta(T) italic_p \\u2208 roman_\\u0394 ( italic_T ) is H \\u2062 ( p ) = \\u2212 \\u2211 t \\u2208 T p \\u2062 ( t ) \\u2062 ln \\u2061 p \\u2062 ( t ) \\ud835\\udc3b \\ud835\\udc5d subscript \\ud835\\udc61 \\ud835\\udc47 \\ud835\\udc5d \\ud835\\udc61 \\ud835\\udc5d \\ud835\\udc61 H(p)=-\\\\sum_{t\\\\in T}p(t)\\\\ln p(t) italic_H ( italic_p ) = - \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T end_POSTSUBSCRIPT italic_p ( italic_t ) roman_ln italic_p ( italic_t ) . Given two distributions p , q \\u2208 \\u0394 \\u2062 ( T ) \\ud835\\udc5d \\ud835\\udc5e \\u0394 \\ud835\\udc47 p,q\\\\in\\\\Delta(T) italic_p , italic_q \\u2208 roman_\\u0394 ( italic_T ) , the cross entropy of q \\ud835\\udc5e q italic_q relative to p \\ud835\\udc5d p italic_p is H \\u2062 ( p , q ) = \\u2212 \\u2211 t \\u2208 T p \\u2062 ( t ) \\u2062 ln \\u2061 q \\u2062 ( t ) \\ud835\\udc3b \\ud835\\udc5d \\ud835\\udc5e subscript \\ud835\\udc61 \\ud835\\udc47 \\ud835\\udc5d \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc61 H(p,q)=-\\\\sum_{t\\\\in T}p(t)\\\\ln q(t) italic_H ( italic_p , italic_q ) = - \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T end_POSTSUBSCRIPT italic_p ( italic_t ) roman_ln italic_q ( italic_t ) . Hence we can write D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( p \\u2225 q ) = H \\u2062 ( p , q ) \\u2212 H \\u2062 ( p ) subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\ud835\\udc5d \\ud835\\udc5e \\ud835\\udc3b \\ud835\\udc5d \\ud835\\udc5e \\ud835\\udc3b \\ud835\\udc5d D_{\\\\mathsf{KL}}(p\\\\|q)=H(p,q)-H(p) italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_p \\u2225 italic_q ) = italic_H ( italic_p , italic_q ) - italic_H ( italic_p ) . We will also use Gibbs\\u2019 inequality H \\u2062 ( p ) \\u2264 H \\u2062 ( p , q ) , \\u2200 p , q \\u2208 \\u0394 \\u2062 ( T ) formulae-sequence \\ud835\\udc3b \\ud835\\udc5d \\ud835\\udc3b \\ud835\\udc5d \\ud835\\udc5e for-all \\ud835\\udc5d \\ud835\\udc5e \\u0394 \\ud835\\udc47 H(p)\\\\leq H(p,q),\\\\forall p,q\\\\in\\\\Delta(T) italic_H ( italic_p ) \\u2264 italic_H ( italic_p , italic_q ) , \\u2200 italic_p , italic_q \\u2208 roman_\\u0394 ( italic_T ) . 4.2 KL-inspired Aggregation The first aggregation method is based on the ( KL ) program. When trying to aggregate LLMs f i subscript \\ud835\\udc53 \\ud835\\udc56 f_{i} italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT according to bids b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we will design a function q \\ud835\\udc5e q italic_q that mimics the outcome of the following thought experiment. We will imagine that each LLM was obtained by solving the ( KL ) on a dataset represented by \\u03bc i subscript \\ud835\\udf07 \\ud835\\udc56 \\\\mu_{i} italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where the marginal over inputs are the same \\u03bc i \\u2062 ( x ) = \\u03bc \\u2062 ( x ) , \\u2200 i subscript \\ud835\\udf07 \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udf07 \\ud835\\udc65 for-all \\ud835\\udc56 \\\\mu_{i}(x)=\\\\mu(x),\\\\forall i italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) = italic_\\u03bc ( italic_x ) , \\u2200 italic_i but potentially differ on the marginals on the labels \\u03bc i \\u2062 ( y | x ) subscript \\ud835\\udf07 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 \\\\mu_{i}(y|x) italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) . In this thought experiment, we will combine their LLMs by re-training an LLM on the combined labels weighted by the bids. In other words, we will solve the problem: min W \\u2061 \\u2062 \\u2112 KL \\u03bc \\u00af \\u2062 ( f W ) , where \\u2062 \\u03bc \\u00af = \\u2211 i b i \\u2062 \\u03bc i \\u2211 i b i . subscript \\ud835\\udc4a superscript subscript \\u2112 KL \\u00af \\ud835\\udf07 superscript \\ud835\\udc53 \\ud835\\udc4a where \\u00af \\ud835\\udf07 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udf07 \\ud835\\udc56 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle\\\\min_{W}\\\\text{ }\\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\bar{\\\\mu}}(f^{W}),\\\\quad% \\\\quad\\\\text{where}~{}\\\\bar{\\\\mu}=\\\\frac{\\\\sum_{i}b_{i}\\\\mu_{i}}{\\\\sum_{i}b_{i}}. roman_min start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\\u00af start_ARG italic_\\u03bc end_ARG end_POSTSUPERSCRIPT ( italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ) , where over\\u00af start_ARG italic_\\u03bc end_ARG = divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG . (3) The next proposition morally says that we can obtain a solution to the ( KL ) problem on the aggregated dataset ( 3 ) by combining its solutions on individual datasets. The proof appears in Appendix D . Proposition 4.1 . Consider datasets \\u03bc i subscript \\ud835\\udf07 \\ud835\\udc56 \\\\mu_{i} italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT such that \\u03bc i \\u2062 ( x ) = \\u03bc \\u2062 ( x ) , \\u2200 i , x subscript \\ud835\\udf07 \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udf07 \\ud835\\udc65 for-all \\ud835\\udc56 \\ud835\\udc65 \\\\mu_{i}(x)=\\\\mu(x),\\\\forall i,x italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) = italic_\\u03bc ( italic_x ) , \\u2200 italic_i , italic_x and let \\u03bc \\u00af \\u00af \\ud835\\udf07 \\\\bar{\\\\mu} over\\u00af start_ARG italic_\\u03bc end_ARG be their weighted average. Let f i subscript \\ud835\\udc53 \\ud835\\udc56 f_{i} italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the minimizer of \\u2112 KL \\u03bc i superscript subscript \\u2112 KL subscript \\ud835\\udf07 \\ud835\\udc56 \\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\mu_{i}} caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and f \\u2217 superscript \\ud835\\udc53 f^{*} italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT be the minimizer of \\u2112 KL \\u03bc \\u00af superscript subscript \\u2112 KL \\u00af \\ud835\\udf07 \\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\bar{\\\\mu}} caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\\u00af start_ARG italic_\\u03bc end_ARG end_POSTSUPERSCRIPT , the loss on the aggregated dataset. Then f \\u2217 superscript \\ud835\\udc53 f^{*} italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT is the solution to: min f \\u2062 \\u2211 x \\u03bc \\u2062 ( x ) \\u2062 \\u2211 i b i \\u2062 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f i \\u2062 ( x ) \\u2225 f \\u2062 ( x ) ) . subscript \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udf07 \\ud835\\udc65 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udc53 \\ud835\\udc65 \\\\textstyle\\\\min_{f}\\\\sum_{x}\\\\mu(x)\\\\sum_{i}b_{i}D_{\\\\mathsf{KL}}(f_{i}(x)\\\\|f(x)). roman_min start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT \\u2211 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_\\u03bc ( italic_x ) \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) \\u2225 italic_f ( italic_x ) ) . (4) Proposition 4.1 motivates the following aggregated loss function: Loss \\ud835\\uddaa\\ud835\\uddab = \\u2211 i \\u2208 [ n ] b i \\u22c5 \\u03c1 \\ud835\\uddaa\\ud835\\uddab \\u2062 ( p i , q ) = \\u2211 i \\u2208 [ n ] \\u2211 t \\u2208 T b i \\u22c5 p i \\u2062 ( t ) \\u22c5 ln \\u2061 p i \\u2062 ( t ) q \\u2062 ( t ) . subscript Loss \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udf0c \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b subscript \\ud835\\udc61 \\ud835\\udc47 \\u22c5 \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc61 \\\\textstyle\\\\textsc{Loss}_{\\\\mathsf{KL}}=\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot\\\\rho_{\\\\mathsf{KL% }}(p_{i},q)=\\\\sum_{i\\\\in[n]}\\\\sum_{t\\\\in T}b_{i}\\\\cdot p_{i}(t)\\\\cdot\\\\ln\\\\frac{p_{i}(% t)}{q(t)}. Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_\\u03c1 start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q ) = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) \\u22c5 roman_ln divide start_ARG italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_q ( italic_t ) end_ARG . Now, we characterize the aggregation function that minimizes Loss \\ud835\\uddaa\\ud835\\uddab subscript Loss \\ud835\\uddaa\\ud835\\uddab \\\\textsc{Loss}_{\\\\mathsf{KL}} Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT . The proof in Appendix D uses Gibb\\u2019s inequality. Lemma 4.2 . The aggregation function that minimizes Loss \\ud835\\uddaa\\ud835\\uddab subscript Loss \\ud835\\uddaa\\ud835\\uddab \\\\textsc{Loss}_{\\\\mathsf{KL}} Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT is the linear combination of p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : \\u2200 t \\u2208 T , q \\ud835\\uddaa\\ud835\\uddab \\u2062 ( t ) = \\u2211 i b i \\u22c5 p i \\u2062 ( t ) \\u2211 i b i . formulae-sequence for-all \\ud835\\udc61 \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc61 subscript \\ud835\\udc56 \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle\\\\forall t\\\\in T,~{}q_{\\\\mathsf{KL}}(t)=\\\\frac{\\\\sum_{i}b_{i}\\\\cdot p_{i}(% t)}{\\\\sum_{i}b_{i}}. \\u2200 italic_t \\u2208 italic_T , italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_t ) = divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG . Besides being monotone and aligned with how LLMs are trained, this aggregation function has the advantage that we only need to call a single LLM to sample each token. We can choose an index i \\ud835\\udc56 i italic_i proportionally to the bids and then sample a token from the i \\ud835\\udc56 i italic_i -th LLM. To compute second price payments, however, we still need to query the LLMs for all agents. 4.3 RL-inspired Aggregation Now, consider a different thought experiment where all agents use the same pre-trained and fine-tuned model of weights W \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 superscript \\ud835\\udc4a \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 W^{\\\\mathsf{SFT}} italic_W start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT , but employs a different reward function r i \\u2062 ( x , y ) subscript \\ud835\\udc5f \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udc66 r_{i}(x,y) italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x , italic_y ) for RLHF. We combine their LLMs by solving the ( RL ) problem on the combined reward functions weighted by the bids. We will solve the problem: max W \\u2061 \\u2112 RL \\u03bc , r \\u00af \\u2062 ( f W ) , r \\u00af = \\u2211 i b i \\u2062 r i \\u2211 i b i . subscript \\ud835\\udc4a superscript subscript \\u2112 RL \\ud835\\udf07 \\u00af \\ud835\\udc5f superscript \\ud835\\udc53 \\ud835\\udc4a \\u00af \\ud835\\udc5f subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5f \\ud835\\udc56 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle\\\\max_{W}\\\\mathcal{L}_{\\\\textsf{RL}}^{\\\\mu,\\\\bar{r}}(f^{W}),\\\\quad\\\\bar{r}=% \\\\frac{\\\\sum_{i}b_{i}r_{i}}{\\\\sum_{i}b_{i}}. roman_max start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT RL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc , over\\u00af start_ARG italic_r end_ARG end_POSTSUPERSCRIPT ( italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ) , over\\u00af start_ARG italic_r end_ARG = divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG . Analogously to Proposition 4.1 , we show that we can obtain the solution to the aggregated problem by combining the solutions on each dataset. We defer the proof of Proposition 4.3 to Appendix D . Proposition 4.3 . Consider datasets \\u03bc , r i \\ud835\\udf07 subscript \\ud835\\udc5f \\ud835\\udc56 \\\\mu,r_{i} italic_\\u03bc , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and let f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 f^{\\\\mathsf{SFT}} italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT be the solution of program ( KL ) with data \\u03bc \\ud835\\udf07 \\\\mu italic_\\u03bc . If f i subscript \\ud835\\udc53 \\ud835\\udc56 f_{i} italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the maximizer of \\u2112 RL \\u03bc , r i superscript subscript \\u2112 RL \\ud835\\udf07 subscript \\ud835\\udc5f \\ud835\\udc56 \\\\mathcal{L}_{\\\\textsf{RL}}^{\\\\mu,r_{i}} caligraphic_L start_POSTSUBSCRIPT RL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , let f \\u2217 superscript \\ud835\\udc53 f^{*} italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT be the maximizer of \\u2112 RL \\u03bc , r \\u00af superscript subscript \\u2112 RL \\ud835\\udf07 \\u00af \\ud835\\udc5f \\\\mathcal{L}_{\\\\textsf{RL}}^{\\\\mu,\\\\bar{r}} caligraphic_L start_POSTSUBSCRIPT RL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc , over\\u00af start_ARG italic_r end_ARG end_POSTSUPERSCRIPT where r \\u00af \\u00af \\ud835\\udc5f \\\\bar{r} over\\u00af start_ARG italic_r end_ARG is the weighted average of the reward functions, then f \\u2217 superscript \\ud835\\udc53 f^{*} italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT is the function minimizing: min f \\u2062 \\u2211 x \\u03bc \\u2062 ( x ) \\u2062 \\u2211 i b i \\u2062 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f \\u2062 ( x ) \\u2225 f i \\u2062 ( x ) ) . subscript \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udf07 \\ud835\\udc65 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\ud835\\udc53 \\ud835\\udc65 subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc65 \\\\textstyle\\\\min_{f}\\\\sum_{x}\\\\mu(x)\\\\sum_{i}b_{i}D_{\\\\mathsf{KL}}(f(x)\\\\|f_{i}(x)). roman_min start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT \\u2211 start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_\\u03bc ( italic_x ) \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f ( italic_x ) \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ) . (5) Similar to what we did in the previous subsection, we can also define an aggregated loss function inspired by Proposition 4.3 . Namely: Loss \\u00af \\ud835\\uddaa\\ud835\\uddab = \\u2211 i \\u2208 [ n ] b i \\u22c5 \\u03c1 \\ud835\\uddaa\\ud835\\uddab \\u2062 ( q , p i ) = \\u2211 i \\u2208 [ n ] \\u2211 t \\u2208 T b i \\u22c5 q \\u2062 ( t ) \\u22c5 ln \\u2061 q \\u2062 ( t ) p i \\u2062 ( t ) . subscript \\u00af Loss \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udf0c \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc5e subscript \\ud835\\udc5d \\ud835\\udc56 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b subscript \\ud835\\udc61 \\ud835\\udc47 \\u22c5 \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\\\textstyle\\\\overline{\\\\textsc{Loss}}_{\\\\mathsf{KL}}=\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot\\\\rho_% {\\\\mathsf{KL}}(q,p_{i})=\\\\sum_{i\\\\in[n]}\\\\sum_{t\\\\in T}b_{i}\\\\cdot q(t)\\\\cdot\\\\ln\\\\frac% {q(t)}{p_{i}(t)}. over\\u00af start_ARG Loss end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_\\u03c1 start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_q , italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_q ( italic_t ) \\u22c5 roman_ln divide start_ARG italic_q ( italic_t ) end_ARG start_ARG italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_ARG . Lemma 4.4 . The aggregation function that minimizes Loss \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af Loss \\ud835\\uddaa\\ud835\\uddab \\\\overline{\\\\textsc{Loss}}_{\\\\mathsf{KL}} over\\u00af start_ARG Loss end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT is the log-linear combination of p i subscript \\ud835\\udc5d \\ud835\\udc56 p_{i} italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : \\u2200 t \\u2208 T , ln \\u2061 q \\u00af \\ud835\\uddaa\\ud835\\uddab \\u2062 ( t ) = C + \\u2211 i b i \\u2062 ln \\u22c5 p i \\u2062 ( t ) \\u2211 i b i , formulae-sequence for-all \\ud835\\udc61 \\ud835\\udc47 subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc61 \\ud835\\udc36 subscript \\ud835\\udc56 \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle\\\\forall t\\\\in T,~{}\\\\ln\\\\bar{q}_{\\\\mathsf{KL}}(t)=C+\\\\frac{\\\\sum_{i}b_{i}% \\\\ln\\\\cdot p_{i}(t)}{\\\\sum_{i}b_{i}}, \\u2200 italic_t \\u2208 italic_T , roman_ln over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_t ) = italic_C + divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_ln \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG , where C \\ud835\\udc36 C italic_C is a normalization constant such that \\u2211 t q \\u00af \\ud835\\uddaa\\ud835\\uddab \\u2062 ( t ) = 1 subscript \\ud835\\udc61 subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc61 1 \\\\sum_{t}\\\\bar{q}_{\\\\mathsf{KL}}(t)=1 \\u2211 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_t ) = 1 . The proof follows directly from the proof of Proposition 4.3 . While not monotone (Example 3.9 ), the log-linear aggregation function is a reasonable choice assuming that the agents\\u2019 preferences are aligned with the KL-divergence loss for the RL-stage training. 5 Demonstration We implement the aggregation functions proposed in Section 4 and discuss the examples they produce. Off-the-shelf LLMs generate full text passages. In our case, we need to peek at the internal states of LLMs (the probability distributions over tokens) at each token generation stage. Therefore, we use a custom version of the Google Bard model with a modified inference method that allows access to the token distributions. Starting from the same base model, we customize it for different agents by prompt-tuning. We start with a base model f : T \\u2217 \\u2192 \\u0394 \\u2062 ( T ) : \\ud835\\udc53 \\u2192 superscript \\ud835\\udc47 \\u0394 \\ud835\\udc47 f:T^{*}\\\\rightarrow\\\\Delta(T) italic_f : italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) and for each agent i \\ud835\\udc56 i italic_i we come up with a \\u201cprompt\\u201d s 0 i \\u2208 T \\u2217 superscript subscript \\ud835\\udc60 0 \\ud835\\udc56 superscript \\ud835\\udc47 s_{0}^{i}\\\\in T^{*} italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \\u2208 italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT and now we define for each agent i \\ud835\\udc56 i italic_i the LLM f i : T \\u2217 \\u2192 \\u0394 \\u2062 ( T ) : subscript \\ud835\\udc53 \\ud835\\udc56 \\u2192 superscript \\ud835\\udc47 \\u0394 \\ud835\\udc47 f_{i}:T^{*}\\\\rightarrow\\\\Delta(T) italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_T start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2192 roman_\\u0394 ( italic_T ) as: f i \\u2062 ( s ) = f \\u2062 ( s 0 i \\u2295 s ) subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc60 \\ud835\\udc53 direct-sum superscript subscript \\ud835\\udc60 0 \\ud835\\udc56 \\ud835\\udc60 f_{i}(s)=f(s_{0}^{i}\\\\oplus s) italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_s ) = italic_f ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \\u2295 italic_s ) Therefore if \\u03c4 1 , \\u2026 , \\u03c4 k \\u2212 1 subscript \\ud835\\udf0f 1 \\u2026 subscript \\ud835\\udf0f \\ud835\\udc58 1 \\\\tau_{1},\\\\ldots,\\\\tau_{k-1} italic_\\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \\u2026 , italic_\\u03c4 start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT are the first k \\u2212 1 \\ud835\\udc58 1 k-1 italic_k - 1 tokens generated, then the preferred distribution of agent i \\ud835\\udc56 i italic_i over the k \\ud835\\udc58 k italic_k -th token is given by: p i = f \\u2062 ( s 0 i \\u2295 s \\u2295 \\u03c4 1 \\u2295 \\u22ef \\u2295 \\u03c4 k \\u2212 1 ) , subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc53 direct-sum superscript subscript \\ud835\\udc60 0 \\ud835\\udc56 \\ud835\\udc60 subscript \\ud835\\udf0f 1 \\u22ef subscript \\ud835\\udf0f \\ud835\\udc58 1 p_{i}=f(s_{0}^{i}\\\\oplus s\\\\oplus\\\\tau_{1}\\\\oplus\\\\cdots\\\\oplus\\\\tau_{k-1}), italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_f ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT \\u2295 italic_s \\u2295 italic_\\u03c4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \\u2295 \\u22ef \\u2295 italic_\\u03c4 start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT ) , A key advantage of simulating LLM agents with different prompts is the ability to use a single LLM, making multiple queries with different prompts instead of serving multiple LLMs concurrently. Because of their large sizes, serving multiple LLMs can be very costly and practically challenging. As one of the key strengths of LLMs, the flexibility to accomplish various tasks with properly designed prompts sheds light to the possibility of training one universal LLM that can, for example, generate different ads according to agent-specific prompts. That is, the universal advertising LLM, plus an advertiser-specific prompt, behaves like an advertiser-specific LLM through the online in-context few-shot learning. 5.1 Setups We illustrate our method with a co-marketing example as well as a competing brands example. In the setup of co-marketing, the two agents would like to advertise for their brands, \\u201cAlpha Airlines\\u201d and \\u201cBeta Resort\\u201d respectively, regarding a shared topic \\u201cHawaii.\\u201d We intentionally choose fictitious brands in order to avoid the model directly retrieving any existing ads. We use the brand names \\u201cAlpha\\u201d and \\u201cBeta\\u201d that do not have strong meanings on their own to minimize any potential hallucination, as we are using a common purposed LLM that is not optimized for our task. Each agent is given the following prompt: \\u201cYou are an expert of writing texts that naturally combines two ads together. Your choice of words and sentences is full of artistic flair. Write a one-sentence ad for .\\u201d Agent A \\ud835\\udc34 A italic_A uses \\u201ca flight to Hawaii using [ Alpha Airlines ]\\u201d to fill the blank, while agent B \\ud835\\udc35 B italic_B uses \\u201ca vacation in Hawaii at the [ Beta Resort ]\\u201d . The first two sentences in the prompt aim to improve the quality of the ad generation through assigning roles (see, for example, (Wu et al . , 2023 ) ). A natural question is whether the proposed method can adjust the combining strategy according to the context. Since in both the linear aggregation rule q \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab q_{\\\\mathsf{KL}} italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT and the log-linear aggregation rule q \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\\\bar{q}_{\\\\mathsf{KL}} over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT , there is only one degree of freedom, we parameterize the response by \\u03bb = b 1 / ( b 1 + b 2 ) \\ud835\\udf06 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 \\\\lambda=\\\\nicefrac{{b_{1}}}{{(b_{1}+b_{2})}} italic_\\u03bb = / start_ARG italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG . The demonstration for competing brands uses the same setup, except that the two brands are \\u201cBeta Resort\\u201d and \\u201cGamma Hotel\\u201d. We seek to understand whether competition will lead LLMs to avoid advertising for both advertisers in the same creative. \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb Linear aggregation function q \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab q_{\\\\mathsf{KL}} italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT Log-linear aggregation function q \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\\\bar{q}_{\\\\mathsf{KL}} over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT 1 1 1 1 Alpha Airlines : Your ticket to paradise. 0.75 0.75 0.75 0.75 Alpha Airlines : Fly to Hawaii and experience the beauty of the islands with aloha. Beta Resorts : Stay at our resorts and enjoy the best of Hawaii. Feel the magic of Hawaii with a flight on Alpha Airlines , now offering 20% off all flights when you book with us today! 0.6 0.6 0.6 0.6 Alpha Airlines flies you to Hawaii, where you can enjoy a week-long stay at the Beta resort for just $1000. Experience the magic of Hawaii with a flight on Alpha Airlines , now offering 20% off all flights when you book with us today! 0.55 0.55 0.55 0.55 Alpha Airlines flies you to Hawaii, where you can enjoy a week-long stay at the Beta resort . Escape to the tropical paradise of Hawaii with [ Alpha Airlines ]! 0.5 0.5 0.5 0.5 Alpha Airlines flies you to Hawaii, where you can enjoy a beautiful sunset on the beach. Stay 3 nights and get the 4th free at the Beta Resort . Experience the magic of Hawaii with a stay at the luxurious [ Beta Resort ] and a refreshing flight on [ Alpha Airlines ]. 0.45 0.45 0.45 0.45 Fly Alpha Airlines to sunny Hawaii and enjoy the secluded beaches and private lagoons of the Royal Hawaiian Beta Resort . Experience the magic of Hawaii with a stay at the luxurious [ Beta Resort ] and a special flight offer from [ Alpha Airlines ]. 0.4 0.4 0.4 0.4 Fly Alpha Airlines to sunny Hawaii and enjoy the first-class treatment that awaits you at Beta Resort , all for one low price. Experience the magic of Hawaii at the [ Beta Resort ], where you\\u2019ll feel like you\\u2019re in a tropical paradise. 0.25 0.25 0.25 0.25 Experience the magic of Hawaii at the Beta Resort , where the sun shines brighter and the waves crash louder \\u2014 book your stay today with our exclusive 20% off discount! Experience the magic of Hawaii at the Beta Resort , where you\\u2019ll be pampered like royalty and surrounded by breathtaking beauty. 0 0 Hawaii\\u2019s Beta Resort : a paradise where the sun shines brighter, the waves sing sweeter, and the sand feels softer. Table 2: Text generation from two aggregation functions with different \\u03bb = b 1 / ( b 1 + b 2 ) \\ud835\\udf06 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 \\\\lambda=b_{1}/(b_{1}+b_{2}) italic_\\u03bb = italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) . \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb Linear aggregation function q \\ud835\\uddaa\\ud835\\uddab subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab q_{\\\\mathsf{KL}} italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT Log-linear aggregation function q \\u00af \\ud835\\uddaa\\ud835\\uddab subscript \\u00af \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\\\bar{q}_{\\\\mathsf{KL}} over\\u00af start_ARG italic_q end_ARG start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT 1 1 1 1 For those who want a relaxing vacation in Hawaii, the Gamma Hotel is the perfect place to stay. 0.75 0.75 0.75 0.75 Experience the magic of Hawaii at the Gamma Hotel , where the sun shines brighter, the waves crash louder, and the nights are filled with endless possibilities. Experience the magic of Hawaii at the [ Gamma Hotel ], where you\\u2019ll be pampered by our luxurious amenities and stunning views of the Pacific Ocean. 0.6 0.6 0.6 0.6 For those who want a truly unforgettable vacation, come to Hawaii and stay at the [ Gamma Hotel ]. Plan your dream vacation in Hawaii with our special rates at the luxurious [ Gamma Hotel ]. 0.55 0.55 0.55 0.55 For those who want a truly unforgettable vacation, come to Hawaii and stay at the [ Gamma Hotel ]. Plan your dream vacation in Hawaii with our special rates at the luxurious [ Gamma Hotel ]! 0.5 0.5 0.5 0.5 For those who want a relaxing vacation in Hawaii, the Gamma Resort is the perfect place to stay. Gamma Hotel : a touch of heaven in the heart of Hawaii. 0.45 0.45 0.45 0.45 Hawaii is a beautiful place to vacation, and the Beta Hotel is the perfect place to stay. Plan your dream vacation in Hawaii with our special rates at the luxurious [ Beta Resort ]. 0.4 0.4 0.4 0.4 Escape to the beautiful beaches of Hawaii and stay at the luxurious Gamma Hotel , where you\\u2019ll be treated like royalty. Escape to the tropical paradise of Hawaii and stay at the luxurious [ Beta Resort ], where you\\u2019ll enjoy stunning views of the Pacific Ocean and easy access to all the island has to offer. 0.25 0.25 0.25 0.25 Escape to the tropical paradise of Hawaii and stay at the luxurious Beta Resort , where you\\u2019ll be surrounded by lush greenery and stunning ocean views. Escape to the tropical paradise of Hawaii and stay at the luxurious Beta Resort , where you\\u2019ll be pampered from the moment you arrive. 0 0 Escape to the tropical paradise of Hawaii and stay at the luxurious Beta Resort , where you\\u2019ll be pampered from the moment you arrive. Table 3: Text generation from two aggregation functions with different \\u03bb = b 1 / ( b 1 + b 2 ) \\ud835\\udf06 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 \\\\lambda=b_{1}/(b_{1}+b_{2}) italic_\\u03bb = italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) in the competing setup. 5.2 Results The results for the co-marketing example are listed in Table 2 , where from top to bottom, the value of \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb decreases from 1 1 1 1 to 0 0 . As we can see for both aggregation functions, the generated texts roughly follow the pattern of \\u201conly Alpha Airlines\\u201d \\u2192 \\u2192 \\\\rightarrow \\u2192 \\u201cboth Alpha Airlines and Beta Resort\\u201d \\u2192 \\u2192 \\\\rightarrow \\u2192 \\u201conly Beta Resort\\u201d when \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb goes from 1 1 1 1 to 0 0 . This is expected, as \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb going from 1 1 1 1 to 0 0 corresponds to b 2 subscript \\ud835\\udc4f 2 b_{2} italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT increasing from 0 0 to \\u221e \\\\infty \\u221e with b 1 subscript \\ud835\\udc4f 1 b_{1} italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT fixed (or b 1 subscript \\ud835\\udc4f 1 b_{1} italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT decreasing from \\u221e \\\\infty \\u221e to 0 0 with b 2 subscript \\ud835\\udc4f 2 b_{2} italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT fixed). The thresholds of pattern changes are 0.75 0.75 0.75 0.75 and 0.4 0.4 0.4 0.4 for the linear aggregation, and 0.5 0.5 0.5 0.5 and 0.45 0.45 0.45 0.45 for the log-linear aggregation. We emphasize that the example is generated with a general purposed LLM, and it is reasonable to believe that the performance can be improved with proper fine-tuning for the specific task at hand. The results for the example with competing brands is listed in Table 3 . As we can see for both aggregation functions, the generated texts roughly follow the pattern of \\u201conly Gamma Hotel\\u201d \\u2192 \\u2192 \\\\rightarrow \\u2192 \\u201conly Beta Resort\\u201d as \\u03bb \\ud835\\udf06 \\\\lambda italic_\\u03bb goes from 1 1 1 1 to 0 0 . The thresholds of pattern changes are 0.5 \\u223c 0.45 similar-to 0.5 0.45 0.5\\\\sim 0.45 0.5 \\u223c 0.45 for both the linear aggregation and the log-linear aggregation. We note that for \\u03bb = 0.45 \\ud835\\udf06 0.45 \\\\lambda=0.45 italic_\\u03bb = 0.45 and \\u03bb = 0.5 \\ud835\\udf06 0.5 \\\\lambda=0.5 italic_\\u03bb = 0.5 , the generated results from the linear aggregation seem to get confused on the brands of \\u201cGamma Hotel\\u201d and \\u201cBeta Resort\\u201d to generate non-existing \\u201cGamma Resort\\u201d and \\u201cBeta Hotel\\u201d. We expect such phenomenons can be addressed by additional task specific training to enforce the extra requirement on using the exact terms on brands. 6 Conclusion In this work, we put forward a mechanism-design approach to the problem of aggregating the output of several LLMs into one. We have proposed an auction format, the token auction model , which operates on a token-by-token basis and allows the LLM agents to influence the output through single-dimensional bids. We explored mechanism design with such LLMs through a robust lens, which makes minimal assumptions about the agents\\u2019 preferences. Working under this paradigm, we have shown that natural requirements on the incentive properties of the auction mechanism, imply that it should feature a monotone aggregation function. We then showed that under robust preferences, any monotone aggregation function enables second-price style payments (akin to those in the Vickrey auction or the Generalized-Second Price auction). We also explored the design of aggregation functions inspired by common loss functions used in LLM training, such as KL-divergence or PPO (in RLHF). As a \\u201cproof of concept\\u201d for our designed mechanism, we demonstrated promising outcomes of our aggregation methods by implementing these aggregation functions in a real-world state-of-the-art LLM using prompt tuning. References (1) Bai et al . (2022) Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom B. Brown, Jack Clark, Sam McCandlish, Chris Olah, Benjamin Mann, and Jared Kaplan. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. CoRR abs/2204.05862 (2022). https://doi.org/10.48550/arXiv.2204.05862 Bakker et al . (2022) Michiel A. Bakker, Martin J. Chadwick, Hannah Sheahan, Michael Henry Tessler, Lucy Campbell-Gillingham, Jan Balaguer, Nat McAleese, Amelia Glaese, John Aslanides, Matt M. Botvinick, and Christopher Summerfield. 2022. Fine-tuning language models to find agreement among humans with diverse preferences. In NeurIPS 2022 . 38176\\u201338189. Bergemann and Morris (2005) Dirk Bergemann and Stephen Morris. 2005. Robust mechanism design. Econometrica (2005), 1771\\u20131813. Bergemann and Morris (2012) Dirk Bergemann and Stephen Morris. 2012. Robust mechanism design: The role of private information and higher order beliefs . Vol. 2. World Scientific. Brown et al . (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. NeurIPS 2020 , 1877\\u20131901. Bulow and Roberts (1989) Jeremy Bulow and John Roberts. 1989. The simple economics of optimal auctions. Journal of Political Economy 97, 5 (1989), 1060\\u20131090. Carroll (2015) Gabriel Carroll. 2015. Robustness and linear contracts. American Economic Review 105, 2 (2015), 536\\u2013563. Dubey et al . (2024) Kumar Avinava Dubey, Zhe Feng, Rahul Kidambi, Aranyak Mehta, and Di Wang. 2024. Auctions with LLM Summaries. CoRR abs/2404.08126 (2024). arXiv:2404.08126 https://doi.org/10.48550/arXiv.2404.08126 Dughmi (2011) Shaddin Dughmi. 2011. A truthful randomized mechanism for combinatorial public projects via convex optimization. In EC 2011 . 263\\u2013272. D\\u00fctting et al . (2019) Paul D\\u00fctting, Tim Roughgarden, and Inbal Talgam-Cohen. 2019. Simple versus Optimal Contracts. In Proceedings of the 2019 ACM Conference on Economics and Computation . 369\\u2013387. Edelman et al . (2007) Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet Advertising and the Generalized Second-Price Auction: Selling Billions of Dollars Worth of Keywords. American Economic Review 97(1) (2007), 242\\u2013259. Freeman et al . (2019) Rupert Freeman, David M Pennock, Dominik Peters, and Jennifer Wortman Vaughan. 2019. Truthful aggregation of budget proposals. In Proceedings of the 2019 ACM Conference on Economics and Computation . 751\\u2013752. Goel et al . (2019) Ashish Goel, Anilesh K Krishnaswamy, Sukolsak Sakshuwong, and Tanja Aitamurto. 2019. Knapsack Voting for Participatory Budgeting. ACM Transactions on Economics and Computation 7, 2 (2019). Google et al . (2023) Google, Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Cl\\u00e9ment Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D\\u00edaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. 2023. PaLM 2 Technical Report. arXiv:2305.10403 [cs.CL] Holtzman et al . (2019) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The Curious Case of Neural Text Degeneration. In International Conference on Learning Representations . Mordo et al . (2024) Tommy Mordo, Moshe Tennenholtz, and Oren Kurland. 2024. Sponsored Question Answering. In Proceedings of the ACM SIGIR International Conference on the Theory of Information Retrieval . https://openreview.net/forum?id=JVh7rytFjh Myerson (1981) Roger B Myerson. 1981. Optimal auction design. Mathematics of Operations Research 6, 1 (1981), 58\\u201373. Ouyang et al . (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In NeurIPS 2022 . 27730\\u201327744. Papadimitriou et al . (2008) Christos Papadimitriou, Michael Schapira, and Yaron Singer. 2008. On the hardness of being truthful. In FOCS 2008 . 250\\u2013259. Ramesh et al . (2021) Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot text-to-image generation. In ICML 2021 . 8821\\u20138831. Roughgarden and Talgam-Cohen (2016) Tim Roughgarden and Inbal Talgam-Cohen. 2016. Optimal and robust mechanism design with interdependent values. ACM Transactions on Economics and Computation 4 (3) (2016), 1\\u201334. Schulman et al . (2017) John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal Policy Optimization Algorithms. CoRR abs/1707.06347 (2017). http://arxiv.org/abs/1707.06347 Sen (2018) Amartya Sen. 2018. Collective choice and social welfare . Harvard University Press. Soumalias et al . (2024) Ermis Soumalias, Michael J. Curry, and Sven Seuken. 2024. Truthful Aggregation of LLMs with an Application to Online Advertising. CoRR abs/2405.05905 (2024). https://doi.org/10.48550/ARXIV.2405.05905 arXiv:2405.05905 Sun et al . (2019) Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid. 2019. Videobert: A joint model for video and language representation learning. In ICCV 2019 . 7464\\u20137473. Thoppilan et al . (2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Ag\\u00fcera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications. CoRR abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239 Varian (2007) Hal R. Varian. 2007. Position auctions. International Journal of Industrial Organization 25 (6) (2007), 1163\\u20131178. Vickrey (1961) William Vickrey. 1961. Counterspeculation, auctions, and competitive sealed tenders. The Journal of Finance 16, 1 (1961), 8\\u201337. Wei et al . (2021) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned Language Models are Zero-Shot Learners. In International Conference on Learning Representations . Wei et al . (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In NeurIPS 2022 . 24824\\u201324837. Wei et al . (2023) Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, and Tengyu Ma. 2023. Larger language models do in-context learning differently. CoRR abs/2303.03846 (2023). https://doi.org/10.48550/arXiv.2303.03846 Wu et al . (2023) Ning Wu, Ming Gong, Linjun Shou, Shining Liang, and Daxin Jiang. 2023. Large language models are diverse role-players for summarization evaluation. arXiv preprint arXiv:2303.15078 (2023). Yu et al . (2022) Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and Yonghui Wu. 2022. Scaling Autoregressive Models for Content-Rich Text-to-Image Generation. Transactions on Machine Learning Research (2022). Appendix A Omitted Proofs from Section 3.2 Our proofs make use of the following technical lemma, which shows that any complete preference relation on a countable set can be expressed via a function that maps elements of the countable set into the non-negative rationals. Lemma A.1 . Let X \\ud835\\udc4b X italic_X be a countable set, and let \\u2ab0 succeeds-or-equals \\\\succeq \\u2ab0 be a complete preference relation on X \\ud835\\udc4b X italic_X . Then there is a function f : X \\u2192 \\u211a + : \\ud835\\udc53 \\u2192 \\ud835\\udc4b subscript \\u211a f:X\\\\rightarrow\\\\mathbb{Q}_{+} italic_f : italic_X \\u2192 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT such that x \\u2aaf y precedes-or-equals \\ud835\\udc65 \\ud835\\udc66 x\\\\preceq y italic_x \\u2aaf italic_y if and only if f \\u2062 ( x ) \\u2264 f \\u2062 ( y ) \\ud835\\udc53 \\ud835\\udc65 \\ud835\\udc53 \\ud835\\udc66 f(x)\\\\leq f(y) italic_f ( italic_x ) \\u2264 italic_f ( italic_y ) . Proof. Since X \\ud835\\udc4b X italic_X is countable, we can arrange it in a sequence { x 1 , x 2 , \\u2026 } subscript \\ud835\\udc65 1 subscript \\ud835\\udc65 2 \\u2026 \\\\{x_{1},x_{2},\\\\ldots\\\\} { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \\u2026 } . We describe a procedure to define f \\u2062 ( x i ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc56 f(x_{i}) italic_f ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) for each x i subscript \\ud835\\udc65 \\ud835\\udc56 x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in turn. Let f \\u2062 ( x 1 ) = 1 \\ud835\\udc53 subscript \\ud835\\udc65 1 1 f(x_{1})=1 italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 1 . Suppose we have defined f \\u2062 ( x 1 ) \\ud835\\udc53 subscript \\ud835\\udc65 1 f(x_{1}) italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , f \\u2062 ( x 2 ) \\ud835\\udc53 subscript \\ud835\\udc65 2 f(x_{2}) italic_f ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , \\u2026 \\u2026 \\\\ldots \\u2026 , f \\u2062 ( x n ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc5b f(x_{n}) italic_f ( italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) in such a way that all order relations are preserved. That is, for all i , j \\u2264 n \\ud835\\udc56 \\ud835\\udc57 \\ud835\\udc5b i,j\\\\leq n italic_i , italic_j \\u2264 italic_n , we have x i \\u2aaf x j precedes-or-equals subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc65 \\ud835\\udc57 x_{i}\\\\preceq x_{j} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2aaf italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT if and only if f \\u2062 ( x i ) \\u2264 f \\u2062 ( x j ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc56 \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc57 f(x_{i})\\\\leq f(x_{j}) italic_f ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u2264 italic_f ( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) . We want to define f \\u2062 ( x n + 1 ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc5b 1 f(x_{n+1}) italic_f ( italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ) . If x n + 1 \\u2ab0 x i succeeds-or-equals subscript \\ud835\\udc65 \\ud835\\udc5b 1 subscript \\ud835\\udc65 \\ud835\\udc56 x_{n+1}\\\\succeq x_{i} italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT \\u2ab0 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and x n + 1 \\u2aaf x i precedes-or-equals subscript \\ud835\\udc65 \\ud835\\udc5b 1 subscript \\ud835\\udc65 \\ud835\\udc56 x_{n+1}\\\\preceq x_{i} italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT \\u2aaf italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (i.e., x n + 1 \\u223c x i similar-to subscript \\ud835\\udc65 \\ud835\\udc5b 1 subscript \\ud835\\udc65 \\ud835\\udc56 x_{n+1}\\\\sim x_{i} italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT \\u223c italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) for some i \\u2264 n \\ud835\\udc56 \\ud835\\udc5b i\\\\leq n italic_i \\u2264 italic_n , then we can let f \\u2062 ( x n + 1 ) = f \\u2062 ( x i ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc5b 1 \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc56 f(x_{n+1})=f(x_{i}) italic_f ( italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ) = italic_f ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and we have extended the function to one more element in a way that preserves all order relations until (including) x n + 1 subscript \\ud835\\udc65 \\ud835\\udc5b 1 x_{n+1} italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT . Otherwise, we can partition the set { x 1 , \\u2026 , x n } subscript \\ud835\\udc65 1 \\u2026 subscript \\ud835\\udc65 \\ud835\\udc5b \\\\{x_{1},\\\\ldots,x_{n}\\\\} { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \\u2026 , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } into two sets L = { x i : i \\u2264 n , x i \\u227a x n + 1 } and H = { x i : i \\u2264 n , x i \\u227b x n + 1 } . formulae-sequence \\ud835\\udc3f conditional-set subscript \\ud835\\udc65 \\ud835\\udc56 formulae-sequence \\ud835\\udc56 \\ud835\\udc5b precedes subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc65 \\ud835\\udc5b 1 and \\ud835\\udc3b conditional-set subscript \\ud835\\udc65 \\ud835\\udc56 formulae-sequence \\ud835\\udc56 \\ud835\\udc5b succeeds subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc65 \\ud835\\udc5b 1 L=\\\\{x_{i}:\\\\;i\\\\leq n,\\\\;x_{i}\\\\prec x_{n+1}\\\\}\\\\quad\\\\text{and}\\\\quad H=\\\\{x_{i}:\\\\;i% \\\\leq n,\\\\;x_{i}\\\\succ x_{n+1}\\\\}. italic_L = { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_i \\u2264 italic_n , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227a italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT } and italic_H = { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_i \\u2264 italic_n , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227b italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT } . In the set \\u211a + subscript \\u211a \\\\mathbb{Q}_{+} blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT of all positive rational numbers, every element in f \\u2062 ( L ) = { f \\u2062 ( x i ) } x i \\u2208 L \\ud835\\udc53 \\ud835\\udc3f subscript \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc65 \\ud835\\udc56 \\ud835\\udc3f f(L)=\\\\{f(x_{i})\\\\}_{x_{i}\\\\in L} italic_f ( italic_L ) = { italic_f ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 italic_L end_POSTSUBSCRIPT is strictly smaller than every element in f \\u2062 ( H ) \\ud835\\udc53 \\ud835\\udc3b f(H) italic_f ( italic_H ) . Choose q \\u2208 \\u211a + \\ud835\\udc5e subscript \\u211a q\\\\in\\\\mathbb{Q}_{+} italic_q \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT strictly larger than all the elements of f \\u2062 ( L ) \\ud835\\udc53 \\ud835\\udc3f f(L) italic_f ( italic_L ) and strictly smaller than all the elements of f \\u2062 ( H ) \\ud835\\udc53 \\ud835\\udc3b f(H) italic_f ( italic_H ) . For each x i subscript \\ud835\\udc65 \\ud835\\udc56 x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with i \\u2264 n \\ud835\\udc56 \\ud835\\udc5b i\\\\leq n italic_i \\u2264 italic_n the relationship between x i subscript \\ud835\\udc65 \\ud835\\udc56 x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and x n + 1 subscript \\ud835\\udc65 \\ud835\\udc5b 1 x_{n+1} italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT is the same as the relationship between f \\u2062 ( x i ) \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc56 f(x_{i}) italic_f ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and q \\ud835\\udc5e q italic_q . Therefore, letting f \\u2062 ( x n + 1 ) = q \\ud835\\udc53 subscript \\ud835\\udc65 \\ud835\\udc5b 1 \\ud835\\udc5e f(x_{n+1})=q italic_f ( italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ) = italic_q extends the function to one more element, preserving all order relations, as required. The resulting function defined on all of X \\ud835\\udc4b X italic_X is thus an isomorphism from X \\ud835\\udc4b X italic_X to the image of f \\ud835\\udc53 f italic_f . \\u220e We remark that the assumption of X \\ud835\\udc4b X italic_X being countable in Lemma A.1 is crucial as the lemma does not hold for uncountable set X \\ud835\\udc4b X italic_X . A canonical counter example is X = \\u211d 2 \\ud835\\udc4b superscript \\u211d 2 X=\\\\mathbb{R}^{2} italic_X = blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT with the lexicographic ordering: x \\u227b x \\u2032 succeeds \\ud835\\udc65 superscript \\ud835\\udc65 \\u2032 x\\\\succ x^{\\\\prime} italic_x \\u227b italic_x start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT if and only if either x 1 > x 1 \\u2032 subscript \\ud835\\udc65 1 subscript superscript \\ud835\\udc65 \\u2032 1 x_{1}>x^{\\\\prime}_{1} italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_x start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or x 1 = x 1 \\u2032 \\u2227 x 2 \\u2265 x 2 \\u2032 subscript \\ud835\\udc65 1 subscript superscript \\ud835\\udc65 \\u2032 1 subscript \\ud835\\udc65 2 subscript superscript \\ud835\\udc65 \\u2032 2 x_{1}=x^{\\\\prime}_{1}\\\\wedge x_{2}\\\\geq x^{\\\\prime}_{2} italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_x start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \\u2227 italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \\u2265 italic_x start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . It is well-known that there is no utility function (continuous or non-continuous) that can induce this complete order (Sen, 2018 ) . This is also why we restrict bids to be non-negative rational numbers, which is certainly practical but also has underlying technical reasons. Proof of Lemma 3.6 Proof. We first prove the \\u201conly if\\u201d (\\u201c \\u27f9 \\u27f9 \\\\Longrightarrow \\u27f9 \\u201d) direction. That is, suppose \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 is payment-monotone, then it must imply a total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = { q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) : b i \\u2208 \\u211a + } \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } for any fixed \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p . Fix any \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p . For any q , q \\u2032 \\u2208 Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = { q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) : b i \\u2208 \\u211a + } \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a q,q^{\\\\prime}\\\\in Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}% _{-i},\\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_q , italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u2208 italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } such that q = q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q=q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q = italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , q \\u2032 = q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) superscript \\ud835\\udc5e \\u2032 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q^{\\\\prime}=q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . Let z i = z i \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 z_{i}=z_{i}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) and z i \\u2032 = z i \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript superscript \\ud835\\udc67 \\u2032 \\ud835\\udc56 subscript \\ud835\\udc67 \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 z^{\\\\prime}_{i}=z_{i}(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_z start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) be the corresponding payment given by \\u2133 \\u2133 \\\\mathcal{M} caligraphic_M . Without loss of generality, suppose that z i \\u2265 z i \\u2032 subscript \\ud835\\udc67 \\ud835\\udc56 subscript superscript \\ud835\\udc67 \\u2032 \\ud835\\udc56 z_{i}\\\\geq z^{\\\\prime}_{i} italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 italic_z start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Then by payment-monotonicity of the mechanism \\u2133 \\u2133 \\\\mathcal{M} caligraphic_M , we have q \\u2ab0 i q \\u2032 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 q\\\\succeq_{i}q^{\\\\prime} italic_q \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT . In other words, \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT establishes a total order over Q \\ud835\\udc44 Q italic_Q . Next we show the \\u201cif\\u201d (\\u201c \\u27f8 \\u27f8 \\\\Longleftarrow \\u27f8 \\u201d) direction. That is, given a total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = { q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) : b i \\u2208 \\u211a + } \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 conditional-set \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\u211a Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\{q(b_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}):b_{i}\\\\in\\\\mathbb{Q}_{+}\\\\} italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = { italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) : italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT } for any fixed \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p , we can construct a payment rule z \\ud835\\udc67 z italic_z such that \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 is payment-monotone. Fix any \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p . Since \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT establishes a total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) and Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) is countable, by Lemma A.1 there exists a function f i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 : Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2192 \\u211a + : subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\u2192 \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\u211a f_{i,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}}:Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})% \\\\rightarrow\\\\mathbb{Q}_{+} italic_f start_POSTSUBSCRIPT italic_i , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p end_POSTSUBSCRIPT : italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2192 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT such that \\u2200 q , q \\u2032 \\u2208 Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) for-all \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\forall q,q^{\\\\prime}\\\\in Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) \\u2200 italic_q , italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u2208 italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , q \\u2ab0 i q \\u2032 \\u21d4 f i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 \\u2062 ( q ) \\u2265 f i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 \\u2062 ( q \\u2032 ) . iff subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc5e \\u2032 subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 superscript \\ud835\\udc5e \\u2032 q\\\\succeq_{i}q^{\\\\prime}\\\\iff f_{i,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}}(q)\\\\geq f_{% i,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}}(q^{\\\\prime}). italic_q \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u21d4 italic_f start_POSTSUBSCRIPT italic_i , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p end_POSTSUBSCRIPT ( italic_q ) \\u2265 italic_f start_POSTSUBSCRIPT italic_i , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) . Letting z i \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) = f i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 \\u2062 ( q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) ) subscript \\ud835\\udc67 \\ud835\\udc56 \\ud835\\udc83 \\ud835\\udc91 subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 z_{i}(\\\\boldsymbol{b},\\\\boldsymbol{p})=f_{i,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}}(% q(\\\\boldsymbol{b},\\\\boldsymbol{p})) italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p ) = italic_f start_POSTSUBSCRIPT italic_i , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p end_POSTSUBSCRIPT ( italic_q ( bold_italic_b , bold_italic_p ) ) , we obtain a payment-monotone mechanism \\u27e8 q , z \\u27e9 \\ud835\\udc5e \\ud835\\udc67 \\\\langle q,z\\\\rangle \\u27e8 italic_q , italic_z \\u27e9 . \\u220e Proof of Lemma 3.7 Proof. Given the consistency of the distribution aggregation function q \\ud835\\udc5e q italic_q , we can define a preference relation \\u2ab0 i , \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc91 \\\\succeq_{i,\\\\boldsymbol{p}} \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT on \\u211a + subscript \\u211a \\\\mathbb{Q}_{+} blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT according to the total orders over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) for all possible \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT (assumed by the lemma) such that, \\u2200 b i , b i \\u2032 \\u2208 \\u211a + for-all subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\u211a \\\\forall b_{i},b^{\\\\prime}_{i}\\\\in\\\\mathbb{Q}_{+} \\u2200 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT : \\u2022 If there exists \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT such that q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u227b i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript succeeds \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succ_{i}q(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , then b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is preferred to b i \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b^{\\\\prime}_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , i.e., b i \\u227b i , \\ud835\\udc91 b i \\u2032 subscript succeeds \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\succ_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227b start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ; \\u2022 If \\u2200 \\ud835\\udc83 \\u2212 i for-all subscript \\ud835\\udc83 \\ud835\\udc56 \\\\forall\\\\boldsymbol{b}_{-i} \\u2200 bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-% i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , then b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and b i \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b^{\\\\prime}_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are indifferent, i.e., b i \\u223c i , \\ud835\\udc91 b i \\u2032 subscript similar-to \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\sim_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u223c start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Note that the validity of this construction is guaranteed by the definition of consistency (Definition 3.2 ): \\u2022 For any b i , b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i},b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT assigned b i \\u227b i , \\ud835\\udc91 b i \\u2032 subscript succeeds \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\succ_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227b start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , there exists some \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT such that q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u227b i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript succeeds \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succ_{i}q(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . By the definition of consistency, \\u2200 \\ud835\\udc83 \\u2212 i \\u2032 for-all subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\\\forall\\\\boldsymbol{b}^{\\\\prime}_{-i} \\u2200 bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i \\u2032 , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i \\u2032 , \\ud835\\udc91 ) subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript superscript \\ud835\\udc83 \\u2032 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}^{\\\\prime}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b^{\\\\prime}_{i% },\\\\boldsymbol{b}^{\\\\prime}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . So we never assign the contradicting order ( b i \\u2032 \\u227b i , \\ud835\\udc91 b i subscript succeeds \\ud835\\udc56 \\ud835\\udc91 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 b^{\\\\prime}_{i}\\\\succ_{i,\\\\boldsymbol{p}}b_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227b start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). \\u2022 Meanwhile, for any b i , b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i},b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT assigned b i \\u223c i , \\ud835\\udc91 b i \\u2032 subscript similar-to \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\sim_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u223c start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we have that \\u2200 \\ud835\\udc83 \\u2212 i for-all subscript \\ud835\\udc83 \\ud835\\udc56 \\\\forall\\\\boldsymbol{b}_{-i} \\u2200 bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-% i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , which implies that for all \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2281 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript not-succeeds \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\not\\\\succ_{i}q(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2281 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . Therefore, we never assign b i \\u227b i , \\ud835\\udc91 b i \\u2032 subscript succeeds \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i}\\\\succ_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u227b start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . By the assumption of the lemma, \\u2ab0 i subscript succeeds-or-equals \\ud835\\udc56 \\\\succeq_{i} \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT establishes a total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . We argue that this implies that \\u2ab0 i , \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc91 \\\\succeq_{i,\\\\boldsymbol{p}} \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT is a complete preference relation on \\u211a + subscript \\u211a \\\\mathbb{Q}_{+} blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT . Concretely, for every pair b i , b i \\u2032 \\u2208 \\u211a + subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\u211a b_{i},b^{\\\\prime}_{i}\\\\in\\\\mathbb{Q}_{+} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT we have q \\u2062 ( b i ) , q \\u2062 ( b i \\u2032 ) \\u2208 Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i}),q(b^{\\\\prime}_{i})\\\\in Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u2208 italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . So either for some \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i ) \\u227b i q \\u2062 ( b i \\u2032 ) subscript succeeds \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 q(b_{i})\\\\succ_{i}q(b^{\\\\prime}_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) (or q \\u2062 ( b i \\u2032 ) \\u227b i q \\u2062 ( b i ) subscript succeeds \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b^{\\\\prime}_{i})\\\\succ_{i}q(b_{i}) italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u227b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ), or for all \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , q \\u2062 ( b i ) = q \\u2062 ( b i \\u2032 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 q(b_{i})=q(b^{\\\\prime}_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , due to the lemma\\u2019s assumption of total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . Hence every pair b i , b i \\u2032 \\u2208 \\u211a + subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\u211a b_{i},b^{\\\\prime}_{i}\\\\in\\\\mathbb{Q}_{+} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT has an order under \\u2ab0 i , \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc91 \\\\succeq_{i,\\\\boldsymbol{p}} \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT (i.e., \\u227b i , \\ud835\\udc91 subscript succeeds \\ud835\\udc56 \\ud835\\udc91 \\\\succ_{i,\\\\boldsymbol{p}} \\u227b start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT or \\u223c i , \\ud835\\udc91 subscript similar-to \\ud835\\udc56 \\ud835\\udc91 \\\\sim_{i,\\\\boldsymbol{p}} \\u223c start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ), so the preference relation \\u2ab0 i , \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc91 \\\\succeq_{i,\\\\boldsymbol{p}} \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT is complete. By Lemma A.1 , since \\u211a + subscript \\u211a \\\\mathbb{Q}_{+} blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT is countable, there exists a function f i , \\ud835\\udc91 : \\u211a + \\u2192 \\u211a + : subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 \\u2192 subscript \\u211a subscript \\u211a f_{i,\\\\boldsymbol{p}}:\\\\mathbb{Q}_{+}\\\\rightarrow\\\\mathbb{Q}_{+} italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT : blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u2192 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT that represents the preference relation \\u2ab0 i , \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc91 \\\\succeq_{i,\\\\boldsymbol{p}} \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT , i.e., \\u2200 b i , b i \\u2032 \\u2208 \\u211a + , b i \\u2ab0 i , \\ud835\\udc91 b i \\u2032 \\u21d4 f i , \\ud835\\udc91 ( b i ) \\u2265 f i , \\ud835\\udc91 ( b i \\u2032 ) . \\\\displaystyle\\\\forall b_{i},b^{\\\\prime}_{i}\\\\in\\\\mathbb{Q}_{+},~{}b_{i}\\\\succeq_{i,% \\\\boldsymbol{p}}b^{\\\\prime}_{i}\\\\iff f_{i,\\\\boldsymbol{p}}(b_{i})\\\\geq f_{i,% \\\\boldsymbol{p}}(b^{\\\\prime}_{i}). \\u2200 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2ab0 start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u21d4 italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) \\u2265 italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . Hence we can construct q ~ ~ \\ud835\\udc5e \\\\tilde{q} over~ start_ARG italic_q end_ARG as: q ~ \\u2062 ( f i , \\ud835\\udc91 \\u2062 ( b i ) , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) . ~ \\ud835\\udc5e subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\displaystyle\\\\tilde{q}(f_{i,\\\\boldsymbol{p}}(b_{i}),\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p})=q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}). over~ start_ARG italic_q end_ARG ( italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . Note that for any b i , b i \\u2032 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b_{i},b^{\\\\prime}_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT such that f i , \\ud835\\udc91 \\u2062 ( b i ) = f i , \\ud835\\udc91 \\u2062 ( b i \\u2032 ) subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 f_{i,\\\\boldsymbol{p}}(b_{i})=f_{i,\\\\boldsymbol{p}}(b^{\\\\prime}_{i}) italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , we have b i \\u223c i , \\ud835\\udc91 b i \\u2032 \\u27f9 q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript similar-to \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc4f \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 \\u27f9 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 b_{i}\\\\sim_{i,\\\\boldsymbol{p}}b^{\\\\prime}_{i}\\\\Longrightarrow q(b_{i},\\\\boldsymbol{% b}_{-i},\\\\boldsymbol{p})=q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u223c start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u27f9 italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) for every \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p . Hence, the construction of q ~ ~ \\ud835\\udc5e \\\\tilde{q} over~ start_ARG italic_q end_ARG never assigns different values to the same input. To complete the construction of q ~ \\u2062 ( \\u22c5 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) ~ \\ud835\\udc5e \\u22c5 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\tilde{q}(\\\\cdot,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) over~ start_ARG italic_q end_ARG ( \\u22c5 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , we expand its definition from the image set of f i , \\ud835\\udc91 subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 f_{i,\\\\boldsymbol{p}} italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT to the entire bid space while preserving monotonicity. The existence of the expansion is guaranteed by the monotonicity of q ~ \\u2062 ( \\u22c5 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) ~ \\ud835\\udc5e \\u22c5 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\\\tilde{q}(\\\\cdot,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) over~ start_ARG italic_q end_ARG ( \\u22c5 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) on the image set of f i , \\ud835\\udc91 subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 f_{i,\\\\boldsymbol{p}} italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT and the fact that the space of aggregations is compact. Letting \\u03c0 i \\u2062 ( b ) = f i , \\ud835\\udc91 \\u2062 ( b ) subscript \\ud835\\udf0b \\ud835\\udc56 \\ud835\\udc4f subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc4f \\\\pi_{i}(b)=f_{i,\\\\boldsymbol{p}}(b) italic_\\u03c0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b ) = italic_f start_POSTSUBSCRIPT italic_i , bold_italic_p end_POSTSUBSCRIPT ( italic_b ) , we have q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) = q ~ \\u2062 ( \\u03c0 i \\u2062 ( b i ) , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 ~ \\ud835\\udc5e subscript \\ud835\\udf0b \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})=\\\\tilde{q}(\\\\pi_{i}(b_{i}),% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) = over~ start_ARG italic_q end_ARG ( italic_\\u03c0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) and q ~ ~ \\ud835\\udc5e \\\\tilde{q} over~ start_ARG italic_q end_ARG is a monotone distribution aggregation function for agent i \\ud835\\udc56 i italic_i . Applying the same argument and the relabeling procedure for every i \\ud835\\udc56 i italic_i from 1 1 1 1 to n \\ud835\\udc5b n italic_n , completes the proof. \\u220e Proof of Theorem 3.5 Proof. Applying Lemma 3.6 , we know that the payment monotonicity of \\u2133 \\u2133 \\\\mathcal{M} caligraphic_M implies a total order over Q \\u2062 ( \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\ud835\\udc44 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 Q(\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_Q ( bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) for any fixed \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT and \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p . Then applying Lemma 3.7 , we know that for any \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p there exist strategy mappings \\u03c0 i : \\u211a + \\u2192 \\u211a + : subscript \\ud835\\udf0b \\ud835\\udc56 \\u2192 subscript \\u211a subscript \\u211a \\\\pi_{i}:\\\\mathbb{Q}_{+}\\\\rightarrow\\\\mathbb{Q}_{+} italic_\\u03c0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \\u2192 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT for each i \\ud835\\udc56 i italic_i such that q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) = q ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 ~ \\ud835\\udc5e \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 q(\\\\boldsymbol{b},\\\\boldsymbol{p})=\\\\tilde{q}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p}) italic_q ( bold_italic_b , bold_italic_p ) = over~ start_ARG italic_q end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) and q ~ \\u2062 ( \\u22c5 , \\ud835\\udc91 ) ~ \\ud835\\udc5e \\u22c5 \\ud835\\udc91 \\\\tilde{q}(\\\\cdot,\\\\boldsymbol{p}) over~ start_ARG italic_q end_ARG ( \\u22c5 , bold_italic_p ) is a monotone aggregation function. Now, following the same argument in the proof of Lemma 3.7 , let us further define z ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) = z \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) ~ \\ud835\\udc67 \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 \\ud835\\udc67 \\ud835\\udc83 \\ud835\\udc91 \\\\tilde{z}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p})=z(\\\\boldsymbol{b},\\\\boldsymbol{p}) over~ start_ARG italic_z end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) = italic_z ( bold_italic_b , bold_italic_p ) for each \\ud835\\udc83 \\u2208 \\u211a + n \\ud835\\udc83 superscript subscript \\u211a \\ud835\\udc5b \\\\boldsymbol{b}\\\\in\\\\mathbb{Q}_{+}^{n} bold_italic_b \\u2208 blackboard_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and \\ud835\\udc91 \\u2208 \\u0394 \\u2062 ( T ) n \\ud835\\udc91 \\u0394 superscript \\ud835\\udc47 \\ud835\\udc5b \\\\boldsymbol{p}\\\\in\\\\Delta(T)^{n} bold_italic_p \\u2208 roman_\\u0394 ( italic_T ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT . So \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 is strategically equivalent to \\u2133 ~ = \\u27e8 q ~ , z ~ \\u27e9 ~ \\u2133 ~ \\ud835\\udc5e ~ \\ud835\\udc67 \\\\tilde{\\\\mathcal{M}}=\\\\langle\\\\tilde{q},\\\\tilde{z}\\\\rangle over~ start_ARG caligraphic_M end_ARG = \\u27e8 over~ start_ARG italic_q end_ARG , over~ start_ARG italic_z end_ARG \\u27e9 by definition. It remains to show that the mechanism \\u2133 ~ = \\u27e8 q ~ , z ~ \\u27e9 ~ \\u2133 ~ \\ud835\\udc5e ~ \\ud835\\udc67 \\\\tilde{\\\\mathcal{M}}=\\\\langle\\\\tilde{q},\\\\tilde{z}\\\\rangle over~ start_ARG caligraphic_M end_ARG = \\u27e8 over~ start_ARG italic_q end_ARG , over~ start_ARG italic_z end_ARG \\u27e9 is payment-monotone. We know that the original mechanism \\u2133 = \\u27e8 q , z \\u27e9 \\u2133 \\ud835\\udc5e \\ud835\\udc67 \\\\mathcal{M}=\\\\langle q,z\\\\rangle caligraphic_M = \\u27e8 italic_q , italic_z \\u27e9 satisfies payment monotonicity, meaning that for each \\ud835\\udc91 \\ud835\\udc91 \\\\boldsymbol{p} bold_italic_p , \\ud835\\udc83 \\u2212 i subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}_{-i} bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , b i \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 b^{\\\\prime}_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , z i \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2265 z i \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u27fa q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) . \\u27fa subscript \\ud835\\udc67 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc67 \\ud835\\udc56 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 z_{i}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\geq z_{i}(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\Longleftrightarrow q(b_{i},\\\\boldsymbol{b}_% {-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}). italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2265 italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u27fa italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . But then, with \\ud835\\udc83 = ( b i , \\ud835\\udc83 \\u2212 i ) \\ud835\\udc83 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}=(b_{i},\\\\boldsymbol{b}_{-i}) bold_italic_b = ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) and \\ud835\\udc83 \\u2032 = ( b i \\u2032 , \\ud835\\udc83 \\u2212 i ) superscript \\ud835\\udc83 \\u2032 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\\\boldsymbol{b}^{\\\\prime}=(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i}) bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT = ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT ) , we also have z ~ i \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) = z i \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\u2265 z i \\u2062 ( \\ud835\\udc83 \\u2032 , \\ud835\\udc91 ) = z ~ i \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 \\u2032 ) , \\ud835\\udc91 ) subscript ~ \\ud835\\udc67 \\ud835\\udc56 \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 subscript \\ud835\\udc67 \\ud835\\udc56 \\ud835\\udc83 \\ud835\\udc91 subscript \\ud835\\udc67 \\ud835\\udc56 superscript \\ud835\\udc83 \\u2032 \\ud835\\udc91 subscript ~ \\ud835\\udc67 \\ud835\\udc56 \\ud835\\udf0b superscript \\ud835\\udc83 \\u2032 \\ud835\\udc91 \\\\displaystyle\\\\tilde{z}_{i}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p})=z_{i}(% \\\\boldsymbol{b},\\\\boldsymbol{p})\\\\geq z_{i}(\\\\boldsymbol{b}^{\\\\prime},\\\\boldsymbol{p% })=\\\\tilde{z}_{i}(\\\\pi(\\\\boldsymbol{b}^{\\\\prime}),\\\\boldsymbol{p}) over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) = italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b , bold_italic_p ) \\u2265 italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , bold_italic_p ) = over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c0 ( bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , bold_italic_p ) \\u27fa \\u27fa \\\\displaystyle\\\\Longleftrightarrow\\\\quad \\u27fa q ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 ) , \\ud835\\udc91 ) = q \\u2062 ( \\ud835\\udc83 , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( \\ud835\\udc83 \\u2032 , \\ud835\\udc91 ) = q ~ \\u2062 ( \\u03c0 \\u2062 ( \\ud835\\udc83 \\u2032 ) , \\ud835\\udc91 ) , ~ \\ud835\\udc5e \\ud835\\udf0b \\ud835\\udc83 \\ud835\\udc91 \\ud835\\udc5e \\ud835\\udc83 \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e superscript \\ud835\\udc83 \\u2032 \\ud835\\udc91 ~ \\ud835\\udc5e \\ud835\\udf0b superscript \\ud835\\udc83 \\u2032 \\ud835\\udc91 \\\\displaystyle\\\\tilde{q}(\\\\pi(\\\\boldsymbol{b}),\\\\boldsymbol{p})=q(\\\\boldsymbol{b},% \\\\boldsymbol{p})\\\\succeq_{i}q(\\\\boldsymbol{b}^{\\\\prime},\\\\boldsymbol{p})=\\\\tilde{q}(% \\\\pi(\\\\boldsymbol{b}^{\\\\prime}),\\\\boldsymbol{p}), over~ start_ARG italic_q end_ARG ( italic_\\u03c0 ( bold_italic_b ) , bold_italic_p ) = italic_q ( bold_italic_b , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , bold_italic_p ) = over~ start_ARG italic_q end_ARG ( italic_\\u03c0 ( bold_italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , bold_italic_p ) , so the pair q ~ ~ \\ud835\\udc5e \\\\tilde{q} over~ start_ARG italic_q end_ARG , z ~ ~ \\ud835\\udc67 \\\\tilde{z} over~ start_ARG italic_z end_ARG satisfies payment monotonicity as needed. \\u220e Appendix B Omitted Proofs from Section 3.3 Proof of Lemma 3.10 Proof. We first prove the \\u201conly if\\u201d (\\u201c \\u27f9 \\u27f9 \\\\Longrightarrow \\u27f9 \\u201d) direction. Suppose q \\ud835\\udc5e q italic_q is a monotone distribution aggregation function. By Definition 3.3 , for any agent i \\ud835\\udc56 i italic_i and b i \\u2032 \\u2265 b i \\u2265 0 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 0 b^{\\\\prime}_{i}\\\\geq b_{i}\\\\geq 0 italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 0 , we have q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( 0 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) . subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e 0 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(0,\\\\boldsymbol{b}_{-i},% \\\\boldsymbol{p}). italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( 0 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) . For any undersampled token t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , because q t \\u2062 ( 0 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2264 ( p i ) t subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(0,\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\leq(p_{i})_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2264 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , then by Definition 2.1 , we have q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) , q t \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2208 [ q t \\u2062 ( 0 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) , ( p i ) t ] . subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc5e \\ud835\\udc61 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}),q_{t}(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\in[q_{t}(0,\\\\boldsymbol{b}_{-i},\\\\boldsymbol% {p}),(p_{i})_{t}]. italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2208 [ italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ] . Hence by q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , we have q t \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2265 q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) , subscript \\ud835\\udc5e \\ud835\\udc61 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q_{t}(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\geq q_{t}(b_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}), italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2265 italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , namely, q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) weakly increases with b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and never goes above ( p i ) t subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 (p_{i})_{t} ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Similarly, we can prove that for any oversampled token t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT , q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) weakly decreases with b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and never goes below ( p i ) t subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 (p_{i})_{t} ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Then we prove the \\u201cif\\u201d (\\u201c \\u27f8 \\u27f8 \\\\Longleftarrow \\u27f8 \\u201d) direction. Consider any b i \\u2032 \\u2265 b i subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 b^{\\\\prime}_{i}\\\\geq b_{i} italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2265 italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . For any undersampled token t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , as q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2264 ( p i ) t subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\leq(p_{i})_{t} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2264 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT weakly increases with b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , we have q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2264 q t \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2264 ( p i ) t . subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc5e \\ud835\\udc61 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\leq q_{t}(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\leq(p_{i})_{t}. italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2264 italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2264 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Similarly, we have for any oversampled token t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT , q t \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2265 q t \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2265 ( p i ) t . subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript \\ud835\\udc5e \\ud835\\udc61 subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 subscript subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 q_{t}(b_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\geq q_{t}(b^{\\\\prime}_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\geq(p_{i})_{t}. italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2265 italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2265 ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Then by Definition 2.1 , q \\u2062 ( b i \\u2032 , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) \\u2ab0 i q \\u2062 ( b i , \\ud835\\udc83 \\u2212 i , \\ud835\\udc91 ) , subscript succeeds-or-equals \\ud835\\udc56 \\ud835\\udc5e subscript superscript \\ud835\\udc4f \\u2032 \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc83 \\ud835\\udc56 \\ud835\\udc91 q(b^{\\\\prime}_{i},\\\\boldsymbol{b}_{-i},\\\\boldsymbol{p})\\\\succeq_{i}q(b_{i},% \\\\boldsymbol{b}_{-i},\\\\boldsymbol{p}), italic_q ( italic_b start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) \\u2ab0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_b start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT , bold_italic_p ) , which then implies the monotonicity of q \\ud835\\udc5e q italic_q . \\u220e Proof of Theorem 3.12 Proof. Given an aggregation q \\u2062 ( b i ) \\ud835\\udc5e subscript \\ud835\\udc4f \\ud835\\udc56 q(b_{i}) italic_q ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) we construct a stable sampling procedure \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 . Let Q + \\u2062 ( b i ) subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 Q_{+}(b_{i}) italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and Q \\u2212 \\u2062 ( b i ) subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 Q_{-}(b_{i}) italic_Q start_POSTSUBSCRIPT - end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) be the probability of sampling tokens from T + subscript \\ud835\\udc47 T_{+} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT : Q + \\u2062 ( b i ) = \\u2211 t \\u2208 T + q t \\u2062 ( b i ) , Q \\u2212 \\u2062 ( b i ) = \\u2211 t \\u2208 T \\u2212 q t \\u2062 ( b i ) . formulae-sequence subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 \\\\textstyle Q_{+}(b_{i})=\\\\sum_{t\\\\in T_{+}}q_{t}(b_{i}),\\\\qquad Q_{-}(b_{i})=\\\\sum% _{t\\\\in T_{-}}q_{t}(b_{i}). italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_Q start_POSTSUBSCRIPT - end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . Both are monotone as q \\ud835\\udc5e q italic_q is monotone (by Lemma 3.10 ). Reparameterize functions q t \\u2062 ( b i ) subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc4f \\ud835\\udc56 q_{t}(b_{i}) italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in the range I = [ Q + \\u2062 ( 0 ) , Q + \\u2062 ( \\u221e ) ] \\ud835\\udc3c subscript \\ud835\\udc44 0 subscript \\ud835\\udc44 I=[Q_{+}(0),Q_{+}(\\\\infty)] italic_I = [ italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) , italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) ] by defining: 6 6 6 Here Q + \\u2212 1 \\u2062 ( x ) superscript subscript \\ud835\\udc44 1 \\ud835\\udc65 Q_{+}^{-1}(x) italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_x ) refers to a generalized inverse (or the quantile function (Bulow and Roberts, 1989 ) ) so that it is properly defined even when Q + \\u2062 ( x ) subscript \\ud835\\udc44 \\ud835\\udc65 Q_{+}(x) italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_x ) is discontinuous. q ^ t \\u2062 ( x ) = q t \\u2062 ( Q + \\u2212 1 \\u2062 ( x ) ) , \\u2200 t \\u2208 T , x \\u2208 I . formulae-sequence subscript ^ \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc65 subscript \\ud835\\udc5e \\ud835\\udc61 superscript subscript \\ud835\\udc44 1 \\ud835\\udc65 formulae-sequence for-all \\ud835\\udc61 \\ud835\\udc47 \\ud835\\udc65 \\ud835\\udc3c \\\\hat{q}_{t}(x)=q_{t}(Q_{+}^{-1}(x)),\\\\forall t\\\\in T,x\\\\in I. over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_x ) ) , \\u2200 italic_t \\u2208 italic_T , italic_x \\u2208 italic_I . Since q ^ t \\u2062 ( x ) subscript ^ \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc65 \\\\hat{q}_{t}(x) over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) is monotone, by Lebesgue\\u2019s Differentiation Theorem, it is differentiable almost everywhere on I \\ud835\\udc3c I italic_I . We observe that: \\u2211 t \\u2208 T + q ^ t \\u2062 ( x ) = Q + \\u2062 ( Q + \\u2212 1 \\u2062 ( x ) ) = x , \\u2211 t \\u2208 T \\u2212 q ^ t \\u2062 ( x ) = Q \\u2212 \\u2062 ( Q + \\u2212 1 \\u2062 ( x ) ) = 1 \\u2212 x . formulae-sequence subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript ^ \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc65 subscript \\ud835\\udc44 superscript subscript \\ud835\\udc44 1 \\ud835\\udc65 \\ud835\\udc65 subscript \\ud835\\udc61 subscript \\ud835\\udc47 subscript ^ \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc65 subscript \\ud835\\udc44 superscript subscript \\ud835\\udc44 1 \\ud835\\udc65 1 \\ud835\\udc65 \\\\textstyle\\\\sum_{t\\\\in T_{+}}\\\\hat{q}_{t}(x)=Q_{+}(Q_{+}^{-1}(x))=x,~{}~{}\\\\sum_{t% \\\\in T_{-}}\\\\hat{q}_{t}(x)=Q_{-}(Q_{+}^{-1}(x))=1-x. \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_x ) ) = italic_x , \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = italic_Q start_POSTSUBSCRIPT - end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_x ) ) = 1 - italic_x . Then q ^ t \\u2032 \\u2062 ( x ) subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 \\ud835\\udc65 \\\\hat{q}^{\\\\prime}_{t}(x) over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) for t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT forms a probability distribution over T + subscript \\ud835\\udc47 T_{+} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT . Similarly \\u2212 q ^ t \\u2032 \\u2062 ( x ) subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 \\ud835\\udc65 -\\\\hat{q}^{\\\\prime}_{t}(x) - over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) for t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT forms a probability distribution over T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT . Define \\u03ba + \\u2062 ( x ) , \\u03ba \\u2212 \\u2062 ( x ) \\u2208 \\u0394 \\u2062 ( T ) superscript \\ud835\\udf05 \\ud835\\udc65 superscript \\ud835\\udf05 \\ud835\\udc65 \\u0394 \\ud835\\udc47 \\\\kappa^{+}(x),\\\\kappa^{-}(x)\\\\in\\\\Delta(T) italic_\\u03ba start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ( italic_x ) , italic_\\u03ba start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( italic_x ) \\u2208 roman_\\u0394 ( italic_T ) as \\u03ba t + \\u2062 ( x ) = q ^ t \\u2032 \\u2062 ( x ) subscript superscript \\ud835\\udf05 \\ud835\\udc61 \\ud835\\udc65 subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 \\ud835\\udc65 \\\\kappa^{+}_{t}(x)=\\\\hat{q}^{\\\\prime}_{t}(x) italic_\\u03ba start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) for t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , and zero otherwise and \\u03ba t \\u2212 \\u2062 ( x ) = \\u2212 q ^ t \\u2032 \\u2062 ( x ) subscript superscript \\ud835\\udf05 \\ud835\\udc61 \\ud835\\udc65 subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 \\ud835\\udc65 \\\\kappa^{-}_{t}(x)=-\\\\hat{q}^{\\\\prime}_{t}(x) italic_\\u03ba start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) = - over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) for t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT and zero otherwise. We also define the vector q + , q \\u2212 \\u2208 \\u0394 \\u2062 ( T ) superscript \\ud835\\udc5e superscript \\ud835\\udc5e \\u0394 \\ud835\\udc47 q^{+},q^{-}\\\\in\\\\Delta(T) italic_q start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT , italic_q start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT \\u2208 roman_\\u0394 ( italic_T ) such that q t + = q t \\u2062 ( 0 ) / Q + \\u2062 ( 0 ) subscript superscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript \\ud835\\udc44 0 q^{+}_{t}=q_{t}(0)/Q_{+}(0) italic_q start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) / italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) for t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT and zero for t \\u2208 T \\u2212 \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{-} italic_t \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT . Similarly: q t \\u2212 = q t \\u2062 ( \\u221e ) / Q + \\u2062 ( \\u221e ) subscript superscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc44 q^{-}_{t}=q_{t}(\\\\infty)/Q_{+}(\\\\infty) italic_q start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( \\u221e ) / italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) for t \\u2208 T \\u2212 \\ud835\\udc61 superscript \\ud835\\udc47 t\\\\in T^{-} italic_t \\u2208 italic_T start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT and zero otherwise. Finally, we define a deterministic function Sampler : \\u0394 \\u2062 ( T ) \\u00d7 [ 0 , 1 ] \\u2192 T : Sampler \\u2192 \\u0394 \\ud835\\udc47 0 1 \\ud835\\udc47 \\\\textsf{Sampler}:\\\\Delta(T)\\\\times[0,1]\\\\rightarrow T Sampler : roman_\\u0394 ( italic_T ) \\u00d7 [ 0 , 1 ] \\u2192 italic_T that takes a probability vector p \\u2208 \\u0394 \\u2062 ( T ) \\ud835\\udc5d \\u0394 \\ud835\\udc47 p\\\\in\\\\Delta(T) italic_p \\u2208 roman_\\u0394 ( italic_T ) and r \\u2208 [ 0 , 1 ] \\ud835\\udc5f 0 1 r\\\\in[0,1] italic_r \\u2208 [ 0 , 1 ] and outputs an index t \\u2208 T \\ud835\\udc61 \\ud835\\udc47 t\\\\in T italic_t \\u2208 italic_T such that \\u2211 j < t p j < r \\u2264 \\u2211 j \\u2264 t p j subscript \\ud835\\udc57 \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc57 \\ud835\\udc5f subscript \\ud835\\udc57 \\ud835\\udc61 subscript \\ud835\\udc5d \\ud835\\udc57 \\\\sum_{j<t}p_{j}<r\\\\leq\\\\sum_{j\\\\leq t}p_{j} \\u2211 start_POSTSUBSCRIPT italic_j < italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT < italic_r \\u2264 \\u2211 start_POSTSUBSCRIPT italic_j \\u2264 italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT . Now, we are ready to define the stable sampling procedure. Let \\u211b \\u211b \\\\mathcal{R} caligraphic_R be the uniform distribution on [ 0 , 1 ] 2 superscript 0 1 2 [0,1]^{2} [ 0 , 1 ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT . Given r = ( r A , r B ) \\u223c \\u211b \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5f \\ud835\\udc35 similar-to \\u211b r=(r_{A},r_{B})\\\\sim\\\\mathcal{R} italic_r = ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) \\u223c caligraphic_R we define the output t = \\u03c3 \\u2062 ( b i , r ) \\ud835\\udc61 \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f t=\\\\sigma(b_{i},r) italic_t = italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) as follows: 1. if r A \\u2264 Q + \\u2062 ( 0 ) subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc44 0 r_{A}\\\\leq Q_{+}(0) italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT \\u2264 italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) , t = Sampler \\u2062 ( q + , r B ) \\u2208 T + \\ud835\\udc61 Sampler superscript \\ud835\\udc5e subscript \\ud835\\udc5f \\ud835\\udc35 subscript \\ud835\\udc47 t=\\\\textsf{Sampler}(q^{+},r_{B})\\\\in T_{+} italic_t = Sampler ( italic_q start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ; 2. if Q + \\u2062 ( 0 ) < r A \\u2264 Q + \\u2062 ( b i ) subscript \\ud835\\udc44 0 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 Q_{+}(0)<r_{A}\\\\leq Q_{+}(b_{i}) italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) < italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT \\u2264 italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , t = Sampler \\u2062 ( \\u03ba + \\u2062 ( r A ) , r B ) \\u2208 T + \\ud835\\udc61 Sampler superscript \\ud835\\udf05 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5f \\ud835\\udc35 subscript \\ud835\\udc47 t=\\\\textsf{Sampler}(\\\\kappa^{+}(r_{A}),r_{B})\\\\in T_{+} italic_t = Sampler ( italic_\\u03ba start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ; 3. if Q + \\u2062 ( b i ) < r A \\u2264 Q + \\u2062 ( \\u221e ) subscript \\ud835\\udc44 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc44 Q_{+}(b_{i})<r_{A}\\\\leq Q_{+}(\\\\infty) italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) < italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT \\u2264 italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) , t = Sampler \\u2062 ( \\u03ba \\u2212 \\u2062 ( r A ) , r B ) \\u2208 T \\u2212 \\ud835\\udc61 Sampler superscript \\ud835\\udf05 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5f \\ud835\\udc35 subscript \\ud835\\udc47 t=\\\\textsf{Sampler}(\\\\kappa^{-}(r_{A}),r_{B})\\\\in T_{-} italic_t = Sampler ( italic_\\u03ba start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT ; 4. if Q + \\u2062 ( \\u221e ) < r A subscript \\ud835\\udc44 subscript \\ud835\\udc5f \\ud835\\udc34 Q_{+}(\\\\infty)<r_{A} italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) < italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , t = Sampler \\u2062 ( q \\u2212 , r B ) \\u2208 T \\u2212 \\ud835\\udc61 Sampler superscript \\ud835\\udc5e subscript \\ud835\\udc5f \\ud835\\udc35 subscript \\ud835\\udc47 t=\\\\textsf{Sampler}(q^{-},r_{B})\\\\in T_{-} italic_t = Sampler ( italic_q start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) \\u2208 italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT . Since \\u03c3 \\u2062 ( b i , r ) \\ud835\\udf0e subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc5f \\\\sigma(b_{i},r) italic_\\u03c3 ( italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r ) is deterministic, for any fixed r \\ud835\\udc5f r italic_r , either the output can not be influenced by the bid ( r A < Q + \\u2062 ( 0 ) subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc44 0 r_{A}<Q_{+}(0) italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT < italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) or r A > Q + \\u2062 ( \\u221e ) subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc44 r_{A}>Q_{+}(\\\\infty) italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT > italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) ) or it can only cause the output to shift from an oversampled token Sampler \\u2062 ( \\u03ba \\u2212 \\u2062 ( r A ) , r B ) Sampler superscript \\ud835\\udf05 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5f \\ud835\\udc35 \\\\textsf{Sampler}(\\\\kappa^{-}(r_{A}),r_{B}) Sampler ( italic_\\u03ba start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) to an undersampled token Sampler \\u2062 ( \\u03ba + \\u2062 ( r A ) , r B ) Sampler superscript \\ud835\\udf05 subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5f \\ud835\\udc35 \\\\textsf{Sampler}(\\\\kappa^{+}(r_{A}),r_{B}) Sampler ( italic_\\u03ba start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) , italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) . We now argue that the tokens are sampled with the correct probabilities. For t \\u2208 T + \\ud835\\udc61 subscript \\ud835\\udc47 t\\\\in T_{+} italic_t \\u2208 italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT , the total probability of getting sampled is: \\u222b 0 Q + \\u2062 ( 0 ) q t + \\u2062 d r A + \\u222b Q + \\u2062 ( 0 ) Q + \\u2062 ( b ) q ^ t \\u2032 \\u2062 ( r A ) \\u2062 d r A = q t \\u2062 ( 0 ) + q ^ t \\u2062 ( Q + \\u2062 ( b ) ) \\u2212 q ^ t \\u2062 ( Q + \\u2062 ( 0 ) ) superscript subscript 0 subscript \\ud835\\udc44 0 subscript superscript \\ud835\\udc5e \\ud835\\udc61 differential-d subscript \\ud835\\udc5f \\ud835\\udc34 superscript subscript subscript \\ud835\\udc44 0 subscript \\ud835\\udc44 \\ud835\\udc4f subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 subscript \\ud835\\udc5f \\ud835\\udc34 differential-d subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript ^ \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc44 \\ud835\\udc4f subscript ^ \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc44 0 \\\\displaystyle\\\\textstyle\\\\int_{0}^{Q_{+}(0)}q^{+}_{t}\\\\mathrm{d}r_{A}+\\\\int_{Q_{+}% (0)}^{Q_{+}(b)}\\\\hat{q}^{\\\\prime}_{t}(r_{A})\\\\mathrm{d}r_{A}=q_{t}(0)+\\\\hat{q}_{t}% (Q_{+}(b))-\\\\hat{q}_{t}(Q_{+}(0)) \\u222b start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT roman_d italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT + \\u222b start_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b ) end_POSTSUPERSCRIPT over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) roman_d italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) + over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b ) ) - over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( 0 ) ) = q t \\u2062 ( 0 ) + q t \\u2062 ( b ) \\u2212 q t \\u2062 ( 0 ) = q t \\u2062 ( b ) . absent subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc4f subscript \\ud835\\udc5e \\ud835\\udc61 0 subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc4f \\\\displaystyle=q_{t}(0)+q_{t}(b)-q_{t}(0)=q_{t}(b). = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) + italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b ) - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( 0 ) = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b ) . Similarly for tokens in T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT , the probability of being sampled is: \\u222b Q + \\u2062 ( b ) Q + \\u2062 ( \\u221e ) \\u2212 q ^ t \\u2032 \\u2062 ( r A ) \\u2062 d \\u2062 r A + \\u222b Q + \\u2062 ( \\u221e ) 1 q t \\u2212 \\u2062 d r A superscript subscript subscript \\ud835\\udc44 \\ud835\\udc4f subscript \\ud835\\udc44 subscript superscript ^ \\ud835\\udc5e \\u2032 \\ud835\\udc61 subscript \\ud835\\udc5f \\ud835\\udc34 d subscript \\ud835\\udc5f \\ud835\\udc34 superscript subscript subscript \\ud835\\udc44 1 subscript superscript \\ud835\\udc5e \\ud835\\udc61 differential-d subscript \\ud835\\udc5f \\ud835\\udc34 \\\\displaystyle\\\\textstyle\\\\int_{Q_{+}(b)}^{Q_{+}(\\\\infty)}-\\\\hat{q}^{\\\\prime}_{t}(r_% {A})\\\\mathrm{d}r_{A}+\\\\int_{Q_{+}(\\\\infty)}^{1}q^{-}_{t}\\\\mathrm{d}r_{A} \\u222b start_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) end_POSTSUPERSCRIPT - over^ start_ARG italic_q end_ARG start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) roman_d italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT + \\u222b start_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT roman_d italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT = q ^ t \\u2062 ( Q + \\u2062 ( b ) ) \\u2212 q ^ t \\u2062 ( Q + \\u2062 ( \\u221e ) ) + q t \\u2062 ( \\u221e ) = q t \\u2062 ( b ) \\u2212 q t \\u2062 ( \\u221e ) + q t \\u2062 ( \\u221e ) = q t \\u2062 ( b ) . absent subscript ^ \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc44 \\ud835\\udc4f subscript ^ \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc44 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc4f subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc4f \\\\displaystyle=\\\\hat{q}_{t}(Q_{+}(b))-\\\\hat{q}_{t}(Q_{+}(\\\\infty))+q_{t}(\\\\infty)=q% _{t}(b)-q_{t}(\\\\infty)+q_{t}(\\\\infty)=q_{t}(b). = over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( italic_b ) ) - over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Q start_POSTSUBSCRIPT + end_POSTSUBSCRIPT ( \\u221e ) ) + italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( \\u221e ) = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b ) - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( \\u221e ) + italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( \\u221e ) = italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_b ) . This completes the proof. \\u220e Appendix C Universally Stable Sampling Example C.1 (Counterexample 4 4 4 4 -token) . Consider two agents { 1 , 2 } 1 2 \\\\{1,2\\\\} { 1 , 2 } and 4 4 4 4 tokens { t 1 , t 2 , t 3 , t 4 } subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 2 subscript \\ud835\\udc61 3 subscript \\ud835\\udc61 4 \\\\{t_{1},t_{2},t_{3},t_{4}\\\\} { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT } . Assume that both agents have the same preferred distribution p 1 = p 2 = ( 0 , 0 , .5 , .5 ) subscript \\ud835\\udc5d 1 subscript \\ud835\\udc5d 2 0 0 .5 .5 p_{1}=p_{2}=(0,0,.5,.5) italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( 0 , 0 , .5 , .5 ) and the allocation function is such that if both agents bid zero the allocation is ( .5 , .5 , 0 , 0 ) .5 .5 0 0 (.5,.5,0,0) ( .5 , .5 , 0 , 0 ) . Hence both both agents have the same set of favored tokens T + = { t 3 , t 4 } subscript \\ud835\\udc47 subscript \\ud835\\udc61 3 subscript \\ud835\\udc61 4 T_{+}=\\\\{t_{3},t_{4}\\\\} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT = { italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT } and less favored tokens T \\u2212 = { t 1 , t 2 } subscript \\ud835\\udc47 subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 2 T_{-}=\\\\{t_{1},t_{2}\\\\} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT = { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } . The aggregation function q \\u2062 ( b 1 , b 2 , p 1 , p 2 ) \\ud835\\udc5e subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 subscript \\ud835\\udc5d 1 subscript \\ud835\\udc5d 2 q(b_{1},b_{2},p_{1},p_{2}) italic_q ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) is given by the following table: b 1 = 0 subscript \\ud835\\udc4f 1 0 b_{1}=0 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 b 1 = 1 subscript \\ud835\\udc4f 1 1 b_{1}=1 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 b 2 = 0 subscript \\ud835\\udc4f 2 0 b_{2}=0 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 q 00 = ( .5 , .5 , 0 , 0 ) subscript \\ud835\\udc5e 00 .5 .5 0 0 q_{00}=(.5,.5,0,0) italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT = ( .5 , .5 , 0 , 0 ) q 10 = ( 0 , .5 , .5 , 0 ) subscript \\ud835\\udc5e 10 0 .5 .5 0 q_{10}=(0,.5,.5,0) italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT = ( 0 , .5 , .5 , 0 ) b 2 = 1 subscript \\ud835\\udc4f 2 1 b_{2}=1 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 q 01 = ( .5 , 0 , .5 , 0 ) subscript \\ud835\\udc5e 01 .5 0 .5 0 q_{01}=(.5,0,.5,0) italic_q start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT = ( .5 , 0 , .5 , 0 ) q 11 = ( 0 , 0 , .5 , .5 ) subscript \\ud835\\udc5e 11 0 0 .5 .5 q_{11}=(0,0,.5,.5) italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = ( 0 , 0 , .5 , .5 ) One can verify that the aggregation function is monotone: When either of the agents increase the bid from 0 0 to 1 1 1 1 , exactly 1 / 2 1 2 1/2 1 / 2 of the probability mass moves from T \\u2212 = { t 1 , t 2 } subscript \\ud835\\udc47 subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 2 T_{-}=\\\\{t_{1},t_{2}\\\\} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT = { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } to T + = { t 3 , t 4 } subscript \\ud835\\udc47 subscript \\ud835\\udc61 3 subscript \\ud835\\udc61 4 T_{+}=\\\\{t_{3},t_{4}\\\\} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT = { italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT } . Now we show that there does not exist a universally stable sampling algorithm that implements this aggregation function. Suppose there exist one, \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 , let r A = { r | \\u03c3 \\u2062 ( q 00 , r ) = t 1 } subscript \\ud835\\udc5f \\ud835\\udc34 conditional-set \\ud835\\udc5f \\ud835\\udf0e subscript \\ud835\\udc5e 00 \\ud835\\udc5f subscript \\ud835\\udc61 1 r_{A}=\\\\{r|\\\\sigma(q_{00},r)=t_{1}\\\\} italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT = { italic_r | italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT , italic_r ) = italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } and r B = { r | \\u03c3 \\u2062 ( q 00 , r ) = t 2 } subscript \\ud835\\udc5f \\ud835\\udc35 conditional-set \\ud835\\udc5f \\ud835\\udf0e subscript \\ud835\\udc5e 00 \\ud835\\udc5f subscript \\ud835\\udc61 2 r_{B}=\\\\{r|\\\\sigma(q_{00},r)=t_{2}\\\\} italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT = { italic_r | italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT , italic_r ) = italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } . Because \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 is stable for bidder 1 1 1 1 , when bidder 1 1 1 1 increases bid, the probability mass only transfers from T \\u2212 subscript \\ud835\\udc47 T_{-} italic_T start_POSTSUBSCRIPT - end_POSTSUBSCRIPT to T + subscript \\ud835\\udc47 T_{+} italic_T start_POSTSUBSCRIPT + end_POSTSUBSCRIPT . In this case, when the bid profile ( b 1 , b 2 ) subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 (b_{1},b_{2}) ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) moves from ( 0 , 0 ) 0 0 (0,0) ( 0 , 0 ) to ( 1 , 0 ) 1 0 (1,0) ( 1 , 0 ) , we must have \\u03c3 \\u2062 ( q 10 , r ) = { t 3 , r \\u2208 r A t 2 , r \\u2208 r B . \\ud835\\udf0e subscript \\ud835\\udc5e 10 \\ud835\\udc5f cases subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 2 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\\\sigma(q_{10},r)=\\\\left\\\\{\\\\begin{array}[]{ll}t_{3},&r\\\\in r_{A}\\\\\\\\ t_{2},&r\\\\in r_{B}\\\\end{array}\\\\right.. italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY . Further apply the same argument when ( b 1 , b 2 ) subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 (b_{1},b_{2}) ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) moves from ( 1 , 0 ) 1 0 (1,0) ( 1 , 0 ) to ( 1 , 1 ) 1 1 (1,1) ( 1 , 1 ) , we have \\u03c3 \\u2062 ( q 11 , r ) = { t 3 , r \\u2208 r A t 4 , r \\u2208 r B . \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f cases subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 4 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\\\sigma(q_{11},r)=\\\\left\\\\{\\\\begin{array}[]{ll}t_{3},&r\\\\in r_{A}\\\\\\\\ t_{4},&r\\\\in r_{B}\\\\end{array}\\\\right.. italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY . However, if we consider ( b 1 , b 2 ) subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 (b_{1},b_{2}) ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) moves along the path ( 0 , 0 ) \\u2192 ( 0 , 1 ) \\u2192 ( 1 , 1 ) \\u2192 0 0 0 1 \\u2192 1 1 (0,0)\\\\rightarrow(0,1)\\\\rightarrow(1,1) ( 0 , 0 ) \\u2192 ( 0 , 1 ) \\u2192 ( 1 , 1 ) , we should have \\u03c3 \\u2062 ( q 01 , r ) = { t 1 , r \\u2208 r A t 3 , r \\u2208 r B , \\u03c3 \\u2062 ( q 11 , r ) = { t 4 , r \\u2208 r A t 3 , r \\u2208 r B . formulae-sequence \\ud835\\udf0e subscript \\ud835\\udc5e 01 \\ud835\\udc5f cases subscript \\ud835\\udc61 1 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f cases subscript \\ud835\\udc61 4 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\\\sigma(q_{01},r)=\\\\left\\\\{\\\\begin{array}[]{ll}t_{1},&r\\\\in r_{A}\\\\\\\\ t_{3},&r\\\\in r_{B}\\\\end{array}\\\\right.,\\\\qquad\\\\sigma(q_{11},r)=\\\\left\\\\{\\\\begin{array% }[]{ll}t_{4},&r\\\\in r_{A}\\\\\\\\ t_{3},&r\\\\in r_{B}\\\\end{array}\\\\right.. italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY , italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY . We end up with a contradiction on the value of \\u03c3 \\u2062 ( q 11 , r ) \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f \\\\sigma(q_{11},r) italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) while moving from ( 0 , 0 ) 0 0 (0,0) ( 0 , 0 ) to ( 1 , 1 ) 1 1 (1,1) ( 1 , 1 ) along two different paths. Example C.2 (Counterexample 3 3 3 3 -token) . Consider two agents { 1 , 2 } 1 2 \\\\{1,2\\\\} { 1 , 2 } and 3 3 3 3 tokens { t 1 , t 2 , t 3 } subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 2 subscript \\ud835\\udc61 3 \\\\{t_{1},t_{2},t_{3}\\\\} { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT } , where the agents have different sets of favored (less favored) tokens. In particular, T 1 + = { t 1 , t 3 } , T 1 \\u2212 = { t 2 } formulae-sequence superscript subscript \\ud835\\udc47 1 subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 3 superscript subscript \\ud835\\udc47 1 subscript \\ud835\\udc61 2 T_{1}^{+}=\\\\{t_{1},t_{3}\\\\},T_{1}^{-}=\\\\{t_{2}\\\\} italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT = { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT } , italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT = { italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } and T 2 + = { t 3 } , T 2 \\u2212 = { t 1 , t 2 } formulae-sequence superscript subscript \\ud835\\udc47 2 subscript \\ud835\\udc61 3 superscript subscript \\ud835\\udc47 2 subscript \\ud835\\udc61 1 subscript \\ud835\\udc61 2 T_{2}^{+}=\\\\{t_{3}\\\\},T_{2}^{-}=\\\\{t_{1},t_{2}\\\\} italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT = { italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT } , italic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT = { italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } . The aggregation function is given by the following table: b 1 = 0 subscript \\ud835\\udc4f 1 0 b_{1}=0 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 b 1 = 1 subscript \\ud835\\udc4f 1 1 b_{1}=1 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 b 2 = 0 subscript \\ud835\\udc4f 2 0 b_{2}=0 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 q 00 = ( .5 , .5 , 0 ) subscript \\ud835\\udc5e 00 .5 .5 0 q_{00}=(.5,.5,0) italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT = ( .5 , .5 , 0 ) q 10 = ( .5 , 0 , .5 ) subscript \\ud835\\udc5e 10 .5 0 .5 q_{10}=(.5,0,.5) italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT = ( .5 , 0 , .5 ) b 2 = 1 subscript \\ud835\\udc4f 2 1 b_{2}=1 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 q 01 = ( 0 , .5 , .5 ) subscript \\ud835\\udc5e 01 0 .5 .5 q_{01}=(0,.5,.5) italic_q start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT = ( 0 , .5 , .5 ) q 11 = ( .5 , 0 , .5 ) subscript \\ud835\\udc5e 11 .5 0 .5 q_{11}=(.5,0,.5) italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = ( .5 , 0 , .5 ) One can verify that the aggregation function is monotone: When b 1 subscript \\ud835\\udc4f 1 b_{1} italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT increases from 0 0 to 1 1 1 1 , exactly 1 / 2 1 2 1/2 1 / 2 of the probability mass moves from t 2 subscript \\ud835\\udc61 2 t_{2} italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT to t 3 subscript \\ud835\\udc61 3 t_{3} italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT (when b 2 = 0 subscript \\ud835\\udc4f 2 0 b_{2}=0 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 ) or t 1 subscript \\ud835\\udc61 1 t_{1} italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (when b 2 = 1 subscript \\ud835\\udc4f 2 1 b_{2}=1 italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 ). When b 2 subscript \\ud835\\udc4f 2 b_{2} italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT increases from 0 0 to 1 1 1 1 , either 1 / 2 1 2 1/2 1 / 2 of the probability mass moves from t 1 subscript \\ud835\\udc61 1 t_{1} italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to t 3 subscript \\ud835\\udc61 3 t_{3} italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT (when b 1 = 0 subscript \\ud835\\udc4f 1 0 b_{1}=0 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 ) or no move (when b 1 = 1 subscript \\ud835\\udc4f 1 1 b_{1}=1 italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 ). Similarly, suppose that there exists a universally stable sampling algorithm \\u03c3 \\ud835\\udf0e \\\\sigma italic_\\u03c3 that implements q \\ud835\\udc5e q italic_q . Let r A = { r | \\u03c3 \\u2062 ( q 00 , r ) = t 1 } subscript \\ud835\\udc5f \\ud835\\udc34 conditional-set \\ud835\\udc5f \\ud835\\udf0e subscript \\ud835\\udc5e 00 \\ud835\\udc5f subscript \\ud835\\udc61 1 r_{A}=\\\\{r|\\\\sigma(q_{00},r)=t_{1}\\\\} italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT = { italic_r | italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT , italic_r ) = italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } and r B = { r | \\u03c3 \\u2062 ( q 00 , r ) = t 2 } subscript \\ud835\\udc5f \\ud835\\udc35 conditional-set \\ud835\\udc5f \\ud835\\udf0e subscript \\ud835\\udc5e 00 \\ud835\\udc5f subscript \\ud835\\udc61 2 r_{B}=\\\\{r|\\\\sigma(q_{00},r)=t_{2}\\\\} italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT = { italic_r | italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT , italic_r ) = italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT } . Following the same argument in Example C.1 , consider the bid profile ( b 1 , b 2 ) subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 (b_{1},b_{2}) ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) moves along the path ( 0 , 0 ) \\u2192 ( 1 , 0 ) \\u2192 ( 1 , 1 ) \\u2192 0 0 1 0 \\u2192 1 1 (0,0)\\\\rightarrow(1,0)\\\\rightarrow(1,1) ( 0 , 0 ) \\u2192 ( 1 , 0 ) \\u2192 ( 1 , 1 ) , we must have \\u03c3 \\u2062 ( q 10 , r ) = \\u03c3 \\u2062 ( q 11 , r ) = { t 1 , r \\u2208 r A t 3 , r \\u2208 r B . \\ud835\\udf0e subscript \\ud835\\udc5e 10 \\ud835\\udc5f \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f cases subscript \\ud835\\udc61 1 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\\\sigma(q_{10},r)=\\\\sigma(q_{11},r)=\\\\left\\\\{\\\\begin{array}[]{ll}t_{1},&r\\\\in r_{A}% \\\\\\\\ t_{3},&r\\\\in r_{B}\\\\end{array}\\\\right.. italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT , italic_r ) = italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY . However, consider the bid profile ( b 1 , b 2 ) subscript \\ud835\\udc4f 1 subscript \\ud835\\udc4f 2 (b_{1},b_{2}) ( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) moves along the path ( 0 , 0 ) \\u2192 ( 1 , 0 ) \\u2192 ( 1 , 1 ) \\u2192 0 0 1 0 \\u2192 1 1 (0,0)\\\\rightarrow(1,0)\\\\rightarrow(1,1) ( 0 , 0 ) \\u2192 ( 1 , 0 ) \\u2192 ( 1 , 1 ) , we must have \\u03c3 \\u2062 ( q 01 , r ) = { t 3 , r \\u2208 r A t 2 , r \\u2208 r B , \\u03c3 \\u2062 ( q 11 , r ) = { t 3 , r \\u2208 r A t 1 , r \\u2208 r B . formulae-sequence \\ud835\\udf0e subscript \\ud835\\udc5e 01 \\ud835\\udc5f cases subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 2 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f cases subscript \\ud835\\udc61 3 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc34 subscript \\ud835\\udc61 1 \\ud835\\udc5f subscript \\ud835\\udc5f \\ud835\\udc35 \\\\sigma(q_{01},r)=\\\\left\\\\{\\\\begin{array}[]{ll}t_{3},&r\\\\in r_{A}\\\\\\\\ t_{2},&r\\\\in r_{B}\\\\end{array}\\\\right.,\\\\qquad\\\\sigma(q_{11},r)=\\\\left\\\\{\\\\begin{array% }[]{ll}t_{3},&r\\\\in r_{A}\\\\\\\\ t_{1},&r\\\\in r_{B}\\\\end{array}\\\\right.. italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY , italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) = { start_ARRAY start_ROW start_CELL italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , end_CELL start_CELL italic_r \\u2208 italic_r start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_CELL end_ROW end_ARRAY . We end up with a contradiction on the value of \\u03c3 \\u2062 ( q 11 , r ) \\ud835\\udf0e subscript \\ud835\\udc5e 11 \\ud835\\udc5f \\\\sigma(q_{11},r) italic_\\u03c3 ( italic_q start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_r ) . Appendix D Omitted Proofs from Section 4 Proof of Proposition 4.1 Proof of Proposition 4.1 . We prove the theorem by showing that the loss \\u2112 KL \\u03bc \\u00af superscript subscript \\u2112 KL \\u00af \\ud835\\udf07 \\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\bar{\\\\mu}} caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\\u00af start_ARG italic_\\u03bc end_ARG end_POSTSUPERSCRIPT and the loss in equation ( 4 ) differ by a constant and hence have the same minimizer. For B = \\u2211 i b i \\ud835\\udc35 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 B=\\\\sum_{i}b_{i} italic_B = \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and a fixed x \\ud835\\udc65 x italic_x we will show that: B \\u22c5 D \\ud835\\uddaa\\ud835\\uddab ( \\u2211 i b i B \\u03bc i ( \\u22c5 | x ) \\u2225 f W ( x ) ) \\u2212 \\u2211 i b i D \\ud835\\uddaa\\ud835\\uddab ( f i ( x ) \\u2225 f W ( x ) ) = \\ud835\\uddbc\\ud835\\uddc8\\ud835\\uddc7\\ud835\\uddcc\\ud835\\uddcd . B\\\\cdot D_{\\\\mathsf{KL}}(\\\\textstyle\\\\sum_{i}\\\\frac{b_{i}}{B}\\\\mu_{i}(\\\\cdot|x)\\\\|f^{W% }(x))-\\\\sum_{i}b_{i}D_{\\\\mathsf{KL}}(f_{i}(x)\\\\|f^{W}(x))=\\\\mathsf{const}. italic_B \\u22c5 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT divide start_ARG italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG italic_B end_ARG italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( \\u22c5 | italic_x ) \\u2225 italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ( italic_x ) ) - \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) \\u2225 italic_f start_POSTSUPERSCRIPT italic_W end_POSTSUPERSCRIPT ( italic_x ) ) = sansserif_const . For notation simplicity, we omit the parameters x \\ud835\\udc65 x italic_x and W \\ud835\\udc4a W italic_W when it is clear from the context and write \\u2211 i b i \\u2062 f i \\u2062 ( x ) / B = f \\u00af \\u2062 ( x ) subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udc35 \\u00af \\ud835\\udc53 \\ud835\\udc65 \\\\sum_{i}b_{i}f_{i}(x)/B=\\\\bar{f}(x) \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) / italic_B = over\\u00af start_ARG italic_f end_ARG ( italic_x ) . Below we treat any term that doesn\\u2019t depend on f \\ud835\\udc53 f italic_f as a constant: \\u2211 i b i \\u2062 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f i \\u2225 f ) subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc53 \\\\displaystyle\\\\sum_{i}b_{i}D_{\\\\mathsf{KL}}(f_{i}\\\\|f) \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2225 italic_f ) = \\u2211 i b i \\u2062 H \\u2062 ( f i ) \\u2212 \\u2211 y b i \\u2062 f i \\u2062 ( y | x ) \\u2062 ln \\u2061 f \\u2062 ( y | x ) absent subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc53 \\ud835\\udc56 subscript \\ud835\\udc66 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\\\displaystyle=\\\\sum_{i}b_{i}H(f_{i})-\\\\sum_{y}b_{i}f_{i}(y|x)\\\\ln f(y|x) = \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) roman_ln italic_f ( italic_y | italic_x ) = \\u2212 B \\u2062 \\u2211 y \\u2211 i b i \\u2062 f i \\u2062 ( y | x ) B \\u22c5 ln \\u2061 f \\u2062 ( y | x ) + \\u2211 i b i \\u2062 H \\u2062 ( f i ) absent \\ud835\\udc35 subscript \\ud835\\udc66 \\u22c5 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 \\ud835\\udc35 \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc53 \\ud835\\udc56 \\\\displaystyle=-B\\\\sum_{y}\\\\frac{\\\\sum_{i}b_{i}f_{i}(y|x)}{B}\\\\cdot\\\\ln f(y|x)+\\\\sum_% {i}b_{i}H(f_{i}) = - italic_B \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) end_ARG start_ARG italic_B end_ARG \\u22c5 roman_ln italic_f ( italic_y | italic_x ) + \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2212 B \\u22c5 H \\u2062 ( f \\u00af , f ) + \\u2211 i b i \\u2062 H \\u2062 ( f i ) absent \\u22c5 \\ud835\\udc35 \\ud835\\udc3b \\u00af \\ud835\\udc53 \\ud835\\udc53 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc53 \\ud835\\udc56 \\\\displaystyle=-B\\\\cdot H(\\\\bar{f},f)+\\\\sum_{i}b_{i}H(f_{i}) = - italic_B \\u22c5 italic_H ( over\\u00af start_ARG italic_f end_ARG , italic_f ) + \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = B \\u22c5 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f \\u00af \\u2225 f ) \\u2212 B \\u22c5 H \\u2062 ( f \\u00af ) + \\u2211 i b i \\u2062 H \\u2062 ( f i ) absent \\u22c5 \\ud835\\udc35 subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\u00af \\ud835\\udc53 \\ud835\\udc53 \\u22c5 \\ud835\\udc35 \\ud835\\udc3b \\u00af \\ud835\\udc53 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc53 \\ud835\\udc56 \\\\displaystyle=B\\\\cdot D_{\\\\mathsf{KL}}(\\\\bar{f}\\\\|f)-B\\\\cdot H(\\\\bar{f})+\\\\sum_{i}b_{% i}H(f_{i}) = italic_B \\u22c5 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( over\\u00af start_ARG italic_f end_ARG \\u2225 italic_f ) - italic_B \\u22c5 italic_H ( over\\u00af start_ARG italic_f end_ARG ) + \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H ( italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = B \\u22c5 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f \\u00af \\u2225 f ) \\u2212 \\ud835\\uddbc\\ud835\\uddc8\\ud835\\uddc7\\ud835\\uddcc\\ud835\\uddcd . absent \\u22c5 \\ud835\\udc35 subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\u00af \\ud835\\udc53 \\ud835\\udc53 \\ud835\\uddbc\\ud835\\uddc8\\ud835\\uddc7\\ud835\\uddcc\\ud835\\uddcd \\\\displaystyle=B\\\\cdot D_{\\\\mathsf{KL}}(\\\\bar{f}\\\\|f)-\\\\mathsf{const}. = italic_B \\u22c5 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( over\\u00af start_ARG italic_f end_ARG \\u2225 italic_f ) - sansserif_const . To complete the proof, observe that if f i subscript \\ud835\\udc53 \\ud835\\udc56 f_{i} italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the unconstrained minimizer of \\u2112 KL \\u03bc i \\u2062 ( f ) superscript subscript \\u2112 KL subscript \\ud835\\udf07 \\ud835\\udc56 \\ud835\\udc53 \\\\mathcal{L}_{\\\\textsf{KL}}^{\\\\mu_{i}}(f) caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_f ) we must have f i \\u2062 ( y | x ) = \\u03bc i \\u2062 ( y | x ) subscript \\ud835\\udc53 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 subscript \\ud835\\udf07 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 f_{i}(y|x)=\\\\mu_{i}(y|x) italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) = italic_\\u03bc start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) . \\u220e Proof of Lemma 4.2 Proof of Lemma 4.2 . Let B = \\u2211 i b i \\ud835\\udc35 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 B=\\\\sum_{i}b_{i} italic_B = \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and consider Loss \\ud835\\uddaa\\ud835\\uddab subscript Loss \\ud835\\uddaa\\ud835\\uddab \\\\textsc{Loss}_{\\\\mathsf{KL}} Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT : Loss \\ud835\\uddaa\\ud835\\uddab subscript Loss \\ud835\\uddaa\\ud835\\uddab \\\\displaystyle\\\\textsc{Loss}_{\\\\mathsf{KL}} Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT = \\u2211 i \\u2208 [ n ] b i \\u22c5 ( H \\u2062 ( p i , q ) \\u2212 H \\u2062 ( p i ) ) absent subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc5e \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\\\displaystyle=\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot(H(p_{i},q)-H(p_{i})) = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 ( italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q ) - italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) = \\u2212 \\u2211 i \\u2208 [ n ] b i \\u22c5 \\u2211 t \\u2208 [ T ] p i \\u2062 ( t ) \\u2062 ln \\u2061 q \\u2062 ( t ) \\u2212 \\u2211 i \\u2208 [ n ] b i \\u22c5 H \\u2062 ( p i ) absent subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc61 delimited-[] \\ud835\\udc47 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\\\displaystyle=-\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot\\\\sum_{t\\\\in[T]}p_{i}(t)\\\\ln q(t)-\\\\sum_{i% \\\\in[n]}b_{i}\\\\cdot H(p_{i}) = - \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 [ italic_T ] end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) roman_ln italic_q ( italic_t ) - \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2212 \\u2211 t \\u2208 [ T ] ln \\u2061 q \\u2062 ( t ) \\u2062 \\u2211 i \\u2208 [ n ] b i \\u22c5 p i \\u2062 ( t ) \\u2212 \\u2211 i \\u2208 [ n ] b i \\u22c5 H \\u2062 ( p i ) absent subscript \\ud835\\udc61 delimited-[] \\ud835\\udc47 \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\\\displaystyle=-\\\\sum_{t\\\\in[T]}\\\\ln q(t)\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot p_{i}(t)-\\\\sum_{i% \\\\in[n]}b_{i}\\\\cdot H(p_{i}) = - \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 [ italic_T ] end_POSTSUBSCRIPT roman_ln italic_q ( italic_t ) \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) - \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2212 B \\u22c5 \\u2211 t \\u2208 [ T ] \\u2211 i \\u2208 [ n ] b i \\u22c5 p i \\u2062 ( t ) B \\u2062 ln \\u2061 q \\u2062 ( t ) \\u2212 \\u2211 i \\u2208 [ n ] b i \\u22c5 H \\u2062 ( p i ) absent \\u22c5 \\ud835\\udc35 subscript \\ud835\\udc61 delimited-[] \\ud835\\udc47 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5d \\ud835\\udc56 \\ud835\\udc61 \\ud835\\udc35 \\ud835\\udc5e \\ud835\\udc61 subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\\\displaystyle=-B\\\\cdot\\\\sum_{t\\\\in[T]}\\\\frac{\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot p_{i}(t)}{B}% \\\\ln q(t)-\\\\sum_{i\\\\in[n]}b_{i}\\\\cdot H(p_{i}) = - italic_B \\u22c5 \\u2211 start_POSTSUBSCRIPT italic_t \\u2208 [ italic_T ] end_POSTSUBSCRIPT divide start_ARG \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_B end_ARG roman_ln italic_q ( italic_t ) - \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = \\u2211 i \\u2208 [ n ] B \\u22c5 H \\u2062 ( q \\ud835\\uddaa\\ud835\\uddab , q ) \\u2212 b i \\u22c5 H \\u2062 ( p i ) . absent subscript \\ud835\\udc56 delimited-[] \\ud835\\udc5b \\u22c5 \\ud835\\udc35 \\ud835\\udc3b subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc5e \\u22c5 subscript \\ud835\\udc4f \\ud835\\udc56 \\ud835\\udc3b subscript \\ud835\\udc5d \\ud835\\udc56 \\\\displaystyle=\\\\sum_{i\\\\in[n]}B\\\\cdot H(q_{\\\\mathsf{KL}},q)-b_{i}\\\\cdot H(p_{i}). = \\u2211 start_POSTSUBSCRIPT italic_i \\u2208 [ italic_n ] end_POSTSUBSCRIPT italic_B \\u22c5 italic_H ( italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT , italic_q ) - italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u22c5 italic_H ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . By Gibbs\\u2019 inequality, the cross entropy H \\u2062 ( q \\ud835\\uddaa\\ud835\\uddab , q ) \\ud835\\udc3b subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc5e H(q_{\\\\mathsf{KL}},q) italic_H ( italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT , italic_q ) is minimized if and only if q = q \\ud835\\uddaa\\ud835\\uddab \\ud835\\udc5e subscript \\ud835\\udc5e \\ud835\\uddaa\\ud835\\uddab q=q_{\\\\mathsf{KL}} italic_q = italic_q start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT . Hence this is also the minimizer of Loss \\ud835\\uddaa\\ud835\\uddab subscript Loss \\ud835\\uddaa\\ud835\\uddab \\\\textsc{Loss}_{\\\\mathsf{KL}} Loss start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT . \\u220e Proof of Proposition 4.3 Proof. For a fixed x \\ud835\\udc65 x italic_x , f \\u2217 \\u2062 ( y | x ) superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 f^{*}(y|x) italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT ( italic_y | italic_x ) can be obtained by solving: max f ( \\u22c5 | x ) \\u2061 \\\\displaystyle\\\\max_{f(\\\\cdot|x)}\\\\text{ } roman_max start_POSTSUBSCRIPT italic_f ( \\u22c5 | italic_x ) end_POSTSUBSCRIPT \\u2211 y f \\u2062 ( y | x ) \\u2062 r \\u00af \\u2062 ( x , y ) \\u2212 \\u03b2 \\u2062 D \\ud835\\uddaa\\ud835\\uddab \\u2062 ( f \\u2062 ( x ) \\u2225 f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( x ) ) subscript \\ud835\\udc66 \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\u00af \\ud835\\udc5f \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udefd subscript \\ud835\\udc37 \\ud835\\uddaa\\ud835\\uddab conditional \\ud835\\udc53 \\ud835\\udc65 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\ud835\\udc65 \\\\displaystyle\\\\sum_{y}f(y|x)\\\\bar{r}(x,y)-\\\\beta D_{\\\\mathsf{KL}}(f(x)\\\\|f^{\\\\mathsf% {SFT}}(x)) \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_y | italic_x ) over\\u00af start_ARG italic_r end_ARG ( italic_x , italic_y ) - italic_\\u03b2 italic_D start_POSTSUBSCRIPT sansserif_KL end_POSTSUBSCRIPT ( italic_f ( italic_x ) \\u2225 italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_x ) ) s.t. \\u2211 y f \\u2062 ( y | x ) = 1 \\u2062 and \\u2062 f \\u2062 ( y | x ) \\u2265 0 . subscript \\ud835\\udc66 \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 1 and \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 0 \\\\displaystyle\\\\sum_{y}f(y|x)=1\\\\text{ and }f(y|x)\\\\geq 0. \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_y | italic_x ) = 1 and italic_f ( italic_y | italic_x ) \\u2265 0 . By the standard KKT conditions, the solution has the form: f \\u2217 \\u2062 ( y | x ) = f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( y | x ) \\u2062 e r \\u00af \\u2062 ( x , y ) / \\u03b2 \\u2062 C x . superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 conditional \\ud835\\udc66 \\ud835\\udc65 superscript \\ud835\\udc52 \\u00af \\ud835\\udc5f \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udefd subscript \\ud835\\udc36 \\ud835\\udc65 f^{*}(y|x)=f^{\\\\mathsf{SFT}}(y|x)e^{\\\\bar{r}(x,y)/\\\\beta}C_{x}. italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT ( italic_y | italic_x ) = italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_y | italic_x ) italic_e start_POSTSUPERSCRIPT over\\u00af start_ARG italic_r end_ARG ( italic_x , italic_y ) / italic_\\u03b2 end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT . where C x subscript \\ud835\\udc36 \\ud835\\udc65 C_{x} italic_C start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT is a normalization constant to ensure \\u2211 y f \\u2217 \\u2062 ( y | x ) = 1 subscript \\ud835\\udc66 superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 1 \\\\sum_{y}f^{*}(y|x)=1 \\u2211 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT ( italic_y | italic_x ) = 1 . For the same reason, we have that: f i \\u2062 ( y | x ) = f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( y | x ) \\u2062 e r i \\u2062 ( x , y ) / \\u03b2 \\u2062 C i , x . subscript \\ud835\\udc53 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 conditional \\ud835\\udc66 \\ud835\\udc65 superscript \\ud835\\udc52 subscript \\ud835\\udc5f \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udefd subscript \\ud835\\udc36 \\ud835\\udc56 \\ud835\\udc65 f_{i}(y|x)=f^{\\\\mathsf{SFT}}(y|x)e^{r_{i}(x,y)/\\\\beta}C_{i,x}. italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) = italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_y | italic_x ) italic_e start_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x , italic_y ) / italic_\\u03b2 end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_i , italic_x end_POSTSUBSCRIPT . If f \\u2218 superscript \\ud835\\udc53 f^{\\\\circ} italic_f start_POSTSUPERSCRIPT \\u2218 end_POSTSUPERSCRIPT is the function minimizing problem ( 5 ), then we can apply KKT conditions to obtain: f \\u2218 \\u2062 ( y | x ) = exp \\u2061 ( 1 B \\u2062 \\u2211 i b i \\u2062 ln \\u2061 f i \\u2062 ( y | x ) ) \\u22c5 C x \\u2032 superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\u22c5 1 \\ud835\\udc35 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udc56 conditional \\ud835\\udc66 \\ud835\\udc65 subscript superscript \\ud835\\udc36 \\u2032 \\ud835\\udc65 f^{\\\\circ}(y|x)=\\\\exp\\\\left(\\\\frac{1}{B}\\\\sum_{i}b_{i}\\\\ln f_{i}(y|x)\\\\right)\\\\cdot C^% {\\\\prime}_{x} italic_f start_POSTSUPERSCRIPT \\u2218 end_POSTSUPERSCRIPT ( italic_y | italic_x ) = roman_exp ( divide start_ARG 1 end_ARG start_ARG italic_B end_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_ln italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_y | italic_x ) ) \\u22c5 italic_C start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT for normalization constants C x \\u2032 subscript superscript \\ud835\\udc36 \\u2032 \\ud835\\udc65 C^{\\\\prime}_{x} italic_C start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT and B = \\u2211 i b i \\ud835\\udc35 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 B=\\\\sum_{i}b_{i} italic_B = \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Replacing the formula for f i \\u2062 ( x ) subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc65 f_{i}(x) italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) from the previous line, we obtain that: f \\u2218 \\u2062 ( y | x ) superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\\\displaystyle f^{\\\\circ}(y|x) italic_f start_POSTSUPERSCRIPT \\u2218 end_POSTSUPERSCRIPT ( italic_y | italic_x ) = exp \\u2061 ( 1 B \\u2062 \\u2211 i b i \\u2062 ( r i \\u2062 ( x , y ) / \\u03b2 + ln \\u2061 f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( y | x ) ) ) \\u22c5 C x \\u2032\\u2032 absent \\u22c5 1 \\ud835\\udc35 subscript \\ud835\\udc56 subscript \\ud835\\udc4f \\ud835\\udc56 subscript \\ud835\\udc5f \\ud835\\udc56 \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udefd superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 conditional \\ud835\\udc66 \\ud835\\udc65 subscript superscript \\ud835\\udc36 \\u2032\\u2032 \\ud835\\udc65 \\\\displaystyle=\\\\exp\\\\left(\\\\frac{1}{B}\\\\sum_{i}b_{i}\\\\left(r_{i}(x,y)/\\\\beta+\\\\ln f^{% \\\\mathsf{SFT}}(y|x)\\\\right)\\\\right)\\\\cdot C^{\\\\prime\\\\prime}_{x} = roman_exp ( divide start_ARG 1 end_ARG start_ARG italic_B end_ARG \\u2211 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x , italic_y ) / italic_\\u03b2 + roman_ln italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_y | italic_x ) ) ) \\u22c5 italic_C start_POSTSUPERSCRIPT \\u2032 \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = exp \\u2061 ( r \\u00af \\u2062 ( x , y ) / \\u03b2 + ln \\u2061 f \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 \\u2062 ( y | x ) ) \\u22c5 C x \\u2032\\u2032 = f \\u2217 \\u2062 ( y | x ) . absent \\u22c5 \\u00af \\ud835\\udc5f \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udefd superscript \\ud835\\udc53 \\ud835\\uddb2\\ud835\\udda5\\ud835\\uddb3 conditional \\ud835\\udc66 \\ud835\\udc65 subscript superscript \\ud835\\udc36 \\u2032\\u2032 \\ud835\\udc65 superscript \\ud835\\udc53 conditional \\ud835\\udc66 \\ud835\\udc65 \\\\displaystyle=\\\\exp\\\\left(\\\\bar{r}(x,y)/\\\\beta+\\\\ln f^{\\\\mathsf{SFT}}(y|x)\\\\right)% \\\\cdot C^{\\\\prime\\\\prime}_{x}=f^{*}(y|x). = roman_exp ( over\\u00af start_ARG italic_r end_ARG ( italic_x , italic_y ) / italic_\\u03b2 + roman_ln italic_f start_POSTSUPERSCRIPT sansserif_SFT end_POSTSUPERSCRIPT ( italic_y | italic_x ) ) \\u22c5 italic_C start_POSTSUPERSCRIPT \\u2032 \\u2032 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = italic_f start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT ( italic_y | italic_x ) . This completes the proof. \\u220e\",\n          \"Probabilistic Constrained Reinforcement Learning with Formal Interpretability Yanran Wang Qiuchen Qian David Boyle Abstract Reinforcement learning can provide effective reasoning for sequential decision-making problems with variable dynamics. Such reasoning in practical implementation, however, poses a persistent challenge in interpreting the reward function and the corresponding optimal policy. Consequently, representing sequential decision-making problems as probabilistic inference can have considerable value, as, in principle, the inference offers diverse and powerful mathematical tools to infer the stochastic dynamics whilst suggesting a probabilistic interpretation of policy optimization. In this study, we propose a novel Adaptive Wasserstein Variational Optimization, namely AWaVO, to tackle these interpretability challenges. Our approach uses formal methods to achieve the interpretability for convergence guarantee, training transparency, and intrinsic decision-interpretation. To demonstrate its practicality, we showcase guaranteed interpretability with a global convergence rate \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) in simulation and in practical quadrotor tasks. In comparison with state-of-the-art benchmarks, including TRPO-IPO, PCPO, and CRPO, we empirically verify that AWaVO offers a reasonable trade-off between high performance and sufficient interpretability. Machine Learning, ICML 1 Introduction Sequential decision-making problems can be represented using Reinforcement Learning (RL) or optimal control technologies to efficiently determine optimal policies or control strategies in the presence of uncertainties (Levine, 2018 ) . Nevertheless, such reasoning poses an ongoing challenge to create a convincing interpretation of sequential decision-making and its corresponding optimal policies (Devidze et al., 2021 ; Levine, 2022 ) . This challenge in comprehension poses a significant barrier to real-world RL\\u2019s implementation in safety-critical domains, such as advanced manufacturing (Napoleone et al., 2020 ) , autonomous navigation (Fernandez-Llorca & G\\u00f3mez, 2023 ) and financial trading (McNamara, 2016 ) . Key Challenges. The challenges surrounding interpretability in the context of RL can be conceptualized through three distinct phases: a. Guarantee of convergence ensures that an RL framework converges towards an optimal policy, e.g., in an asymptotic manner. b. Transparency in training convergence emphasizes the identification of the underlying processes that an RL algorithm employs to reach convergence during its training. An instance is the convergence rate, where, based on a given number of training iterations, the rate enables the prediction of the expected level of convergence with a certain degree of confidence. c. Interpretation of decisions seeks to explain why these specific sequential decisions were made within a given state and environment. Specifically, this interpretation involves clarifying the quantitative impact of latent factors on these sequential decisions. Moreover, due to legal mandates in industries, this facet of interpretation is of even greater significance, particularly in ensuring the trustworthiness of self-driving vehicles (Fern\\u00e1ndez Llorca & G\\u00f3mez, 2021 ; Fernandez-Llorca & G\\u00f3mez, 2023 ) , aerospace engineering (Brat, 2021 ; Torens et al., 2022 ) , and high-frequency trading (McNamara, 2016 ) . One widely adopted approach to achieving model interpretability involves the use of post-hoc explanation methods. These methods provide retrospective rationales for model predictions, often through the creation of saliency maps or exemplars, as discussed in previous research (Lipton, 2018 ; Kenny et al., 2021 ) . Despite their popularity, these approaches may produce incomplete or inaccurate explanations (Slack et al., 2020 ; Zhou et al., 2022 ) . In response to these limitations, recent studies have shifted their focus towards intrinsic interpretability (Rudin, 2019 ; Kenny et al., 2022 ) . These methods, however, face challenges in providing a transparent and comprehensive view in the decision-making process. While they present decision explanations that are user-friendly, as demonstrated in (Kenny et al., 2022 ) , corresponding to Key Challenge c , there is no guaranteed transparency, as highlighted in Key Challenges a and b . Establishing such transparency is crucial and serves as a prerequisite for underpinning user trust and predicting the system\\u2019s capabilities. To our best knowledge, we present the first intrinsically interpretable constrained RL framework through the lens of probabilistic inference. Specifically, we reframe constrained RL as Wasserstein variational optimization, leveraging an enhanced foundational inference framework known as augmented Probabilistic Graphical Models (PGMs). This is illustrated in Figure 1 . Our proposed A daptive Sliced Wa sserstein V ariational O ptimization (AWaVO), as elaborated in Figure 2 , consists of two primary steps: a. Optimality-Rectified Policy Optimization using Distributional Representation (ORPO-DR) : ORPO is conducted to dynamically adapt to uncertainties (Algorithm 1 , Section 4.2 ). More importantly, Distributional Representation (DR) provides an entire distribution of the action-value function, contributing to heightened transparency in the convergence process (as outlined in Theorem 5.4 and Theorem 5.5 ). Consequently, this efficiently tackles a significant portion of the deficiencies outlined in Key Challenges a and b ; b. Wasserstein Variational Inference (WVI) : as detailed in Section 4.1 , WVI is subsequently performed to achieve the probabilistic interpretation of decisions, thereby tackling Key Challenge c . Our contributions can be summarized as follows: \\u2022 Adaptive Generalized Sliced Wasserstein Distance , referred to as A-GSWD, incorporates the Sliced Wasserstein Distance (SWD) along with adaptive Radon transforms to handle dynamic uncertainties. Specifically, the proposed A-GSWD adaptively determines the hypersurfaces\\u2019 slicing directions to enhance the precision of distribution distance computation; \\u2022 Adaptive Sliced Wasserstein Variational Optimization , abbreviated as AWaVO, employs inference to reformulate the problem of sequential decision-making. To tackle all Key Challenges, AWaVO leverages ORPO-DR to enhance the transparency of convergence under dynamic uncertainties. Additionally, WVI is employed to provide probabilistic decision-interpretation; \\u2022 Formal methods for interpretation are employed to demonstrate theoretical comprehension on the metric judgment of A-GSWD, transparency of training convergence, and probabilistic interpretation of decisions. The practical hardware implementation and additional demonstrations are showcased in a video 1 1 1 https://github.com/Alex-yanranwang/AWaVO . 2 Related Work Reinforcement Learning as Inference. The relationship between sequential decision-making and probabilistic inference has been explored extensively in recent years (Levine, 2018 ; Okada & Taniguchi, 2020 ; Liu et al., 2022 ) . Despite variations in terminology, the core inference frameworks remain consistent, namely, PGMs (Koller & Friedman, 2009 ) . While substantial research exists on learning and inference techniques within PGMs (Levine, 2018 ) , the direct connection between RL (or control) and probabilistic inference is not immediately apparent. (Welch et al., 1995 ) establishes that control and inference are dual perspectives of the same problem. This connection offers novel insights and enhanced understanding within control problems by leveraging mathematical tools of inference (Toussaint & Storkey, 2006 ; Kappen et al., 2012 ) . Moreover, the study on \\u2018RL as inference\\u2019 represents another prominent trend. Specifically, (Levine, 2018 ) demonstrates that RL is equivalent to probabilistic inference under dynamics. (Chua et al., 2018 ; Okada & Taniguchi, 2020 ) approach dynamics modeling by employing Bayesian inference optimization. Furthermore, (O\\u2019Donoghue et al., 2020 ) revisits the formalization of \\u2018RL as inference\\u2019 and demonstrates that with a slight algorithmic modification, this approximation can perform well even in problems where it initially performs poorly. In this study, we formalize constrained RL as Wasserstein variational optimization to achieve decision-interpretations. Figure 1: A new graphical model for constrained RL: refer to Algorithm 2 for a comprehensive overview of (i) Parameter Identification , (ii) Policy Updating and (iii) Inference Execution . Optimal Transport Theory. Forming effective metrics between two probability measures is a fundamental challenge in machine learning and statistics communities. The optimal transport theory, particularly the Wasserstein distance, has garnered significant attention across various domains (Solomon et al., 2014 ; Kolouri et al., 2017 ; Schmitz et al., 2018 ; Wang & Boyle, 2023 ) due to its accuracy, robustness, and stable optimization. Nevertheless, due to its computational demand on high-dimensional data, recent advancements emphasize computational efficiency through differentiable optimization (Peyr\\u00e9 et al., 2017 ) . Among these methods, Sinkhorn distance (Cuturi, 2013 ; Altschuler et al., 2017 ) introduces entropy regularization to smoothen the convex regularization. Another notable approach involves slicing or linear projection (Ng, 2005 ) , i.e., Sliced Wasserstein Distance (SWD) (Bonneel et al., 2015 ) , which leverages the measures\\u2019 Radon transform for efficient dimensionality reduction. Then, variants of SWD, such as Generalized SWD (GSWD) (Kolouri et al., 2019 ) , improve projection efficiency. These advancements contribute to the efficiency in optimal-transport-based metrics. However, they suffer from reduced accuracy as SWD only slices distributions using linear hyperplanes, which may fail to capture the complex structures of data distributions. To overcome the accuracy limitation, Augmented SWD (ASWD) (Chen et al., 2021 ) projects onto flexible nonlinear hypersurfaces, enabling the capture of intricate data distribution structures. Building upon the ASWD framework, we introduce an adaptive variant called A-GSWD which leverages the projection onto nonlinear hypersurfaces and combines it with ORPO-DR to achieve adaptivity. This adaptive approach enhances the efficiency and accuracy of Wasserstein distance computation, improving upon the limitations of previous methods. 3 Problem Formulation and Preliminaries Sequential Decision-making as Probabilistic Inference. A sequential decision-making problem, formalized as a standard RL or control problem, can be seen as an inference problem (Levine, 2018 ) : p \\ud835\\udc5d \\\\displaystyle p italic_p ( \\u03c4 | \\ud835\\udcaa 0 : T \\u2212 1 = 1 ) \\u221d \\u222b \\u220f t = 0 T \\u2212 1 p \\u2062 ( \\ud835\\udcaa t = 1 | \\ud835\\udc94 t , \\ud835\\udc82 t ) \\u23df := p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u22c5 \\\\displaystyle(\\\\tau|\\\\mathcal{O}_{0:T-1}=1)\\\\propto\\\\int\\\\underbrace{\\\\prod_{t=0}^{T% -1}p(\\\\mathcal{O}_{t}=1|\\\\bm{s}_{t},\\\\bm{a}_{t})}_{:=p(\\\\mathcal{O}|\\\\tau)}\\\\cdot ( italic_\\u03c4 | caligraphic_O start_POSTSUBSCRIPT 0 : italic_T - 1 end_POSTSUBSCRIPT = 1 ) \\u221d \\u222b under\\u23df start_ARG \\u220f start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_POSTSUBSCRIPT := italic_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT \\u22c5 (1) p \\u2062 ( \\ud835\\udc94 0 ) \\u2062 { \\u220f t = 0 T \\u2212 1 p \\u2062 ( \\ud835\\udc82 t | \\ud835\\udc94 t , \\u03b8 ) \\u2062 p \\u2062 ( \\ud835\\udc94 t + 1 | \\ud835\\udc94 t , \\ud835\\udc82 t ) } \\u23df := Markov property p \\u2062 ( \\u03c4 | \\u03b8 ) \\u22c5 p \\u2062 ( \\u03b8 | D ) \\u23df := p D \\u2062 ( \\u03b8 ) \\u2062 d \\u2062 \\u03b8 \\u22c5 subscript \\u23df \\ud835\\udc5d subscript \\ud835\\udc94 0 superscript subscript product \\ud835\\udc61 0 \\ud835\\udc47 1 \\ud835\\udc5d conditional subscript \\ud835\\udc82 \\ud835\\udc61 subscript \\ud835\\udc94 \\ud835\\udc61 \\ud835\\udf03 \\ud835\\udc5d conditional subscript \\ud835\\udc94 \\ud835\\udc61 1 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 superscript assign Markov property absent \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udf03 subscript \\u23df \\ud835\\udc5d conditional \\ud835\\udf03 \\ud835\\udc37 assign absent subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 d \\ud835\\udf03 \\\\displaystyle\\\\underbrace{p(\\\\bm{s}_{0})\\\\left\\\\{\\\\prod_{t=0}^{T-1}p(\\\\bm{a}_{t}|\\\\bm% {s}_{t},\\\\theta)p(\\\\bm{s}_{t+1}|\\\\bm{s}_{t},\\\\bm{a}_{t})\\\\right\\\\}}_{\\\\stackrel{{% \\\\scriptstyle\\\\text{Markov property}}}{{:=}}p(\\\\tau|\\\\theta)}\\\\cdot\\\\underbrace{p(% \\\\theta|D)}_{:=p_{D}(\\\\theta)}\\\\mathrm{d}\\\\theta under\\u23df start_ARG italic_p ( bold_italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) { \\u220f start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_p ( bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03b8 ) italic_p ( bold_italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) } end_ARG start_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG := end_ARG start_ARG Markov property end_ARG end_RELOP italic_p ( italic_\\u03c4 | italic_\\u03b8 ) end_POSTSUBSCRIPT \\u22c5 under\\u23df start_ARG italic_p ( italic_\\u03b8 | italic_D ) end_ARG start_POSTSUBSCRIPT := italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) end_POSTSUBSCRIPT roman_d italic_\\u03b8 where \\ud835\\udc94 t subscript \\ud835\\udc94 \\ud835\\udc61 \\\\bm{s}_{t} bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , \\ud835\\udc82 t subscript \\ud835\\udc82 \\ud835\\udc61 \\\\bm{a}_{t} bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , \\u03c4 = { ( \\ud835\\udc94 t , \\ud835\\udc82 t ) } t = 0 T \\u2212 1 \\ud835\\udf0f superscript subscript subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\ud835\\udc61 0 \\ud835\\udc47 1 \\\\tau=\\\\left\\\\{(\\\\bm{s}_{t},\\\\bm{a}_{t})\\\\right\\\\}_{t=0}^{T-1} italic_\\u03c4 = { ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT and D = { ( \\ud835\\udc94 t , \\ud835\\udc82 t , \\ud835\\udc94 t + 1 ) } \\ud835\\udc37 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 subscript \\ud835\\udc94 \\ud835\\udc61 1 D=\\\\left\\\\{(\\\\bm{s}_{t},\\\\bm{a}_{t},\\\\bm{s}_{t+1})\\\\right\\\\} italic_D = { ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) } are states, actions, a trajectory and observed training dataset. \\ud835\\udcaa t = { \\ud835\\udcaa r , t , \\ud835\\udcaa g i , t } \\u2208 { 0 , 1 } subscript \\ud835\\udcaa \\ud835\\udc61 subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udc61 subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udc61 0 1 \\\\mathcal{O}_{t}=\\\\{\\\\mathcal{O}_{r,t},\\\\mathcal{O}_{g_{i},t}\\\\}\\\\in\\\\left\\\\{0,1\\\\right\\\\} caligraphic_O start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { caligraphic_O start_POSTSUBSCRIPT italic_r , italic_t end_POSTSUBSCRIPT , caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t end_POSTSUBSCRIPT } \\u2208 { 0 , 1 } represents an additional binary variable of the optimality for ( \\ud835\\udc94 t , \\ud835\\udc82 t ) subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 (\\\\bm{s}_{t},\\\\bm{a}_{t}) ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) in PGM (Levine, 2018 ; Okada & Taniguchi, 2020 ) . \\ud835\\udcaa r , t = 1 subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udc61 1 \\\\mathcal{O}_{r,t}=1 caligraphic_O start_POSTSUBSCRIPT italic_r , italic_t end_POSTSUBSCRIPT = 1 and \\ud835\\udcaa g i , t = 1 subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udc61 1 \\\\mathcal{O}_{g_{i},t}=1 caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t end_POSTSUBSCRIPT = 1 signify that the trajectory \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 is optimized and compliant with the constraints, respectively. In Equation 1 , we can deconstruct the various components: the probability p \\u2062 ( a t | s t , \\u03b8 ) \\ud835\\udc5d conditional subscript \\ud835\\udc4e \\ud835\\udc61 subscript \\ud835\\udc60 \\ud835\\udc61 \\ud835\\udf03 p(\\\\bm{a}_{t}|\\\\bm{s}_{t},\\\\theta) italic_p ( bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03b8 ) signifies the stationary policy \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 which maps one state \\ud835\\udc94 t subscript \\ud835\\udc94 \\ud835\\udc61 \\\\bm{s}_{t} bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT to one action \\ud835\\udc82 t subscript \\ud835\\udc82 \\ud835\\udc61 \\\\bm{a}_{t} bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , where \\ud835\\udc82 t \\u223c p ( \\u22c5 | \\ud835\\udc94 t , \\u03b8 ) = \\u03c0 ( \\u22c5 | \\ud835\\udc94 t ) \\\\bm{a}_{t}\\\\sim p(\\\\cdot|\\\\bm{s}_{t},\\\\theta)=\\\\pi(\\\\cdot|\\\\bm{s}_{t}) bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \\u223c italic_p ( \\u22c5 | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03b8 ) = italic_\\u03c0 ( \\u22c5 | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) at each time step t \\ud835\\udc61 t italic_t ; the transition probability p \\u2062 ( s t + 1 | s t , a t ) \\ud835\\udc5d conditional subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 p(\\\\bm{s}_{t+1}|\\\\bm{s}_{t},\\\\bm{a}_{t}) italic_p ( bold_italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) represents state transitions (also known as forward-dynamics models), where \\ud835\\udc94 t + 1 \\u223c p ( \\u22c5 | \\ud835\\udc94 t , \\ud835\\udc82 t ) \\\\bm{s}_{t+1}\\\\sim p(\\\\cdot|\\\\bm{s}_{t},\\\\bm{a}_{t}) bold_italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT \\u223c italic_p ( \\u22c5 | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) (Chua et al., 2018 ) at each time step t \\ud835\\udc61 t italic_t ; the prior probability p D \\u2062 ( \\u03b8 ) subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p_{D}(\\\\theta) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) is derived from the posterior probability p \\u2062 ( \\u03b8 | D ) \\ud835\\udc5d conditional \\ud835\\udf03 \\ud835\\udc37 p(\\\\theta|D) italic_p ( italic_\\u03b8 | italic_D ) , where the parameter \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 is inferred from the training dataset D \\ud835\\udc37 D italic_D ; and lastly, the optimality likelihood p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) is defined in relation to the expected reward and utility formulation of several trajectories, expressed as \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) := r ~ \\u2062 ( \\u03c4 ) assign \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f ~ \\ud835\\udc5f \\ud835\\udf0f \\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right):=\\\\widetilde{r}(\\\\tau) caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) := over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) and \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) := g ~ i \\u2062 ( \\u03c4 ) assign \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right):=\\\\widetilde{g}_{i}% (\\\\tau) caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) := over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) , where the operator family \\u2131 = { \\u2131 r , \\u2131 g } \\u2131 subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}=\\\\left\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\right\\\\} caligraphic_F = { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } and the optimality family \\ud835\\udcaa = { \\ud835\\udcaa r , \\ud835\\udcaa g i } \\ud835\\udcaa subscript \\ud835\\udcaa \\ud835\\udc5f subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\\\mathcal{O}=\\\\{\\\\mathcal{O}_{r},\\\\mathcal{O}_{g_{i}}\\\\} caligraphic_O = { caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT } establish this relationship. In Section 4.1 and Section 5 , we offer theoretical understanding to illustrate how such specific definitions influence the RL\\u2019s global convergence. Constrained Reinforcement Learning as Probabilistic Graphical Models. Specifically, we consider a Constrained Markov Decision Process (CMDP) (Altman, 1999 ) , a formal framework for constrained RL, which is formulated as a discounted Markov decision process with additional constrained objectives, i.e., a tuple \\u27e8 S , A , P , R , G , \\u03b3 \\u27e9 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc43 \\ud835\\udc45 \\ud835\\udc3a \\ud835\\udefe \\\\left\\\\langle S,A,P,R,G,\\\\gamma\\\\right\\\\rangle \\u27e8 italic_S , italic_A , italic_P , italic_R , italic_G , italic_\\u03b3 \\u27e9 : S \\ud835\\udc46 S italic_S is a finite set of states { \\ud835\\udc94 } \\ud835\\udc94 {\\\\left\\\\{\\\\bm{s}\\\\right\\\\}} { bold_italic_s } ; A \\ud835\\udc34 A italic_A is a finite set of actions { \\ud835\\udc82 } \\ud835\\udc82 {\\\\left\\\\{\\\\bm{a}\\\\right\\\\}} { bold_italic_a } ; P : S \\u00d7 A \\u2192 S : \\ud835\\udc43 \\u2192 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc46 P:S\\\\times A\\\\rightarrow S italic_P : italic_S \\u00d7 italic_A \\u2192 italic_S is a finite set of transition probabilities { p \\u2062 ( \\ud835\\udc94 \\u2032 | \\ud835\\udc94 , \\ud835\\udc82 ) } \\ud835\\udc5d conditional superscript \\ud835\\udc94 bold-\\u2032 \\ud835\\udc94 \\ud835\\udc82 {\\\\left\\\\{p(\\\\bm{s^{\\\\prime}}|\\\\bm{s},\\\\bm{a})\\\\right\\\\}} { italic_p ( bold_italic_s start_POSTSUPERSCRIPT bold_\\u2032 end_POSTSUPERSCRIPT | bold_italic_s , bold_italic_a ) } ; R : S \\u00d7 A \\u00d7 S \\u2192 \\u211d : \\ud835\\udc45 \\u2192 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc46 \\u211d R:S\\\\times A\\\\times S\\\\rightarrow\\\\mathbb{R} italic_R : italic_S \\u00d7 italic_A \\u00d7 italic_S \\u2192 blackboard_R is a finite set of bounded immediate rewards { r } \\ud835\\udc5f {\\\\left\\\\{r\\\\right\\\\}} { italic_r } ; G : S \\u00d7 A \\u00d7 S \\u2192 \\u211d : \\ud835\\udc3a \\u2192 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc46 \\u211d G:S\\\\times A\\\\times S\\\\rightarrow\\\\mathbb{R} italic_G : italic_S \\u00d7 italic_A \\u00d7 italic_S \\u2192 blackboard_R comprises a finite collection of unity functions { g } \\ud835\\udc54 {\\\\left\\\\{g\\\\right\\\\}} { italic_g } , where, upon satisfying the expected constraints g i subscript \\ud835\\udc54 \\ud835\\udc56 g_{i} italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , the unity-optimality variable is specified as \\ud835\\udcaa g i = 1 subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 1 \\\\mathcal{O}_{g_{i}}=1 caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 1 ; and \\u03b3 \\u2208 [ 0 , 1 ] \\ud835\\udefe 0 1 \\\\gamma\\\\in[0,1] italic_\\u03b3 \\u2208 [ 0 , 1 ] is the discount rate. A CMDP is presented as: max \\ud835\\udf0b \\ud835\\udca5 r ( \\u03c0 ) , s . t . \\ud835\\udca5 g , i ( \\u03c0 ) \\u2264 \\ud835\\udc1b i + \\ud835\\udf49 c , i = 1 , \\u2026 , n \\\\underset{\\\\pi}{\\\\rm{max}}\\\\>\\\\mathcal{J}_{r}(\\\\pi),\\\\quad{\\\\rm{s.t.}}\\\\quad\\\\mathcal{J% }_{g,i}(\\\\pi)\\\\leq\\\\bm{b}_{i}+\\\\bm{\\\\tau}_{c},\\\\quad i=1,...,n underitalic_\\u03c0 start_ARG roman_max end_ARG caligraphic_J start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT ( italic_\\u03c0 ) , roman_s . roman_t . caligraphic_J start_POSTSUBSCRIPT roman_g , roman_i end_POSTSUBSCRIPT ( italic_\\u03c0 ) \\u2264 bold_b start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT + bold_italic_\\u03c4 start_POSTSUBSCRIPT roman_c end_POSTSUBSCRIPT , roman_i = 1 , \\u2026 , roman_n (2) where \\ud835\\udca5 r \\u2062 ( \\u03c0 ) := \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) | \\u03c0 , \\ud835\\udc94 0 = s ] assign subscript \\ud835\\udca5 \\ud835\\udc5f \\ud835\\udf0b \\ud835\\udd3c delimited-[] conditional superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\ud835\\udf0b subscript \\ud835\\udc94 0 \\ud835\\udc60 \\\\mathcal{J}_{r}(\\\\pi):={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{\\\\infty}\\\\gamma^{t}}r(\\\\bm% {s}_{t},\\\\bm{a}_{t})|\\\\pi,{\\\\bm{s}_{0}}=s] caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_\\u03c0 ) := blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | italic_\\u03c0 , bold_italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_s ] and \\ud835\\udca5 g , i \\u2062 ( \\u03c0 ) := \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 g i \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) | \\u03c0 , \\ud835\\udc94 0 = s ] assign subscript \\ud835\\udca5 \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0b \\ud835\\udd3c delimited-[] conditional superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udc56 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\ud835\\udf0b subscript \\ud835\\udc94 0 \\ud835\\udc60 \\\\mathcal{J}_{g,i}(\\\\pi):={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{\\\\infty}\\\\gamma^{t}}g_{% i}(\\\\bm{s}_{t},\\\\bm{a}_{t})|\\\\pi,{\\\\bm{s}_{0}}=s] caligraphic_J start_POSTSUBSCRIPT italic_g , italic_i end_POSTSUBSCRIPT ( italic_\\u03c0 ) := blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | italic_\\u03c0 , bold_italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_s ] are the value function associated with the immediate reward r \\ud835\\udc5f r italic_r and the utility g \\ud835\\udc54 g italic_g , respectively; b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a fixed limit for the i \\ud835\\udc56 i italic_i -th constraint; and \\ud835\\udf49 c subscript \\ud835\\udf49 \\ud835\\udc50 \\\\bm{\\\\tau}_{c} bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT is the tolerance. Figure 1 shows how constrained RL can be viewed as a novel variation of PGMs. A complete table of nomenclature is provided in Appendix A for convenient reference. 4 Method: Adaptive Sliced Wasserstein Variational Optimization (AWaVO) In this section, we present AWaVO\\u2019s two primary submodules: WVI and ORPO-DR. The detailed algorithm is outlined in Algorithm 2 , and the overarching algorithmic structure is depicted in Figure 2 . Figure 2: The algorithmic framework of AWaVO. We reform constrained RL as a Wasserstein variational optimization setup, consisting of two primary submodules: ORPO-DR and WVI ( Section 4 ). 4.1 WVI: Wasserstein Variational Inference Variational Inference for Dynamic Uncertainties. Given uncertainties in a dynamics model, it is reasonable to assume that the optimal trajectories { \\u03c4 } \\ud835\\udf0f \\\\left\\\\{\\\\tau\\\\right\\\\} { italic_\\u03c4 } are uncertain. To infer optimal policies under uncertainties, let us consider a variational inference: D ( q \\u03b8 ( \\u03c4 ) | | p ( \\u03c4 | \\ud835\\udcaa ) ) D(q_{\\\\theta}(\\\\tau)||p(\\\\tau|\\\\mathcal{O})) italic_D ( italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) | | italic_p ( italic_\\u03c4 | caligraphic_O ) ) , where, for simplicity, we use p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa p(\\\\tau|\\\\mathcal{O}) italic_p ( italic_\\u03c4 | caligraphic_O ) to represent p \\u2062 ( \\u03c4 | \\ud835\\udcaa t : T = 1 ) \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udcaa : \\ud835\\udc61 \\ud835\\udc47 1 p(\\\\tau|\\\\mathcal{O}_{t:T}=1) italic_p ( italic_\\u03c4 | caligraphic_O start_POSTSUBSCRIPT italic_t : italic_T end_POSTSUBSCRIPT = 1 ) ; and D ( \\u22c5 | | \\u22c5 ) D(\\\\cdot||\\\\cdot) italic_D ( \\u22c5 | | \\u22c5 ) represents a distance metric between two probabilities. Building upon Equation 1 , the variational distribution q \\u03b8 \\u2062 ( \\u03c4 ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f q_{\\\\theta}(\\\\tau) italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) is constructed as q \\u03b8 \\u2062 ( \\u03c4 ) = q \\u2062 ( \\ud835\\udc82 ) \\u2062 p \\u2062 ( \\u03c4 | \\u03b8 ) \\u2062 p D \\u2062 ( \\u03b8 ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f \\ud835\\udc5e \\ud835\\udc82 \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 q_{\\\\theta}(\\\\tau)=q(\\\\bm{a})p(\\\\tau|\\\\theta)p_{D}(\\\\theta) italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) = italic_q ( bold_italic_a ) italic_p ( italic_\\u03c4 | italic_\\u03b8 ) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) . The construction suggests an assumption that the state transitions are controlled by p \\u2062 ( \\ud835\\udc94 t + 1 | \\ud835\\udc94 t , \\ud835\\udc82 t ) \\ud835\\udc5d conditional subscript \\ud835\\udc94 \\ud835\\udc61 1 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 p(\\\\bm{s}_{t+1}|\\\\bm{s}_{t},\\\\bm{a}_{t}) italic_p ( bold_italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) . According to Equation 1 , we formulate the posterior as p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) \\u221d p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u2062 p \\u2062 ( \\u03c4 | \\u03b8 ) \\u2062 p D \\u2062 ( \\u03b8 ) proportional-to \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p(\\\\tau|\\\\mathcal{O})\\\\propto p(\\\\mathcal{O}|\\\\tau)p(\\\\tau|\\\\theta)p_{D}(\\\\theta) italic_p ( italic_\\u03c4 | caligraphic_O ) \\u221d italic_p ( caligraphic_O | italic_\\u03c4 ) italic_p ( italic_\\u03c4 | italic_\\u03b8 ) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) (see 2 for our implementation details). While Kullback-Leibler (KL) divergence is widely used in conventional variational inference, its application in certain practical implementations can be risky due to its limitations, including asymmetry and infinity, arising when there are unequal supports. In this section, we extend the Wasserstein distance into the variational inference, and present the derivation of how we transform the GSWD between the two posteriors to the optimality likelihood p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) and its approximation q \\u2062 ( \\ud835\\udc82 ) \\ud835\\udc5e \\ud835\\udc82 q(\\\\bm{a}) italic_q ( bold_italic_a ) . Adaptive Generalized Sliced Wasserstein Distance. GSWD has exhibited high projection efficiency in previous studies (Kolouri et al., 2019 ; Chen et al., 2021 ) (please refer to Appendix B for a comprehensive background and definition of Wasserstein distance). However, the identification of the hypersurface hyperparameters, such as l \\ud835\\udc59 l italic_l and \\u03b8 ~ ~ \\ud835\\udf03 \\\\widetilde{\\\\theta} over~ start_ARG italic_\\u03b8 end_ARG , remains to be a challenge. The selection of these parameters, specifying the hypersurface along with its slicing direction, is generally a task-specific problem and requires prior knowledge or domain expertise. We now present a new adaptive sliced Wasserstein distance, called A-GSWD, that integrates GSWD with ORPO-DR, an adaptive process for determining the parameters of a hypersurface. Definition 4.1 . Given SWD and GSWD (defined in Appendix B.1 and Appendix B.2 , respectively), we define A-GSWD by utilizing ORPO-DR for the adaptive slicing: \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc24 ( \\\\displaystyle\\\\bf{A}-\\\\bf{GSWD}_{k}( bold_A - bold_GSWD start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT ( \\u03bc , \\u03bd ) = \\\\displaystyle\\\\mu,\\\\nu)= italic_\\u03bc , italic_\\u03bd ) = ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udc9c \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc9c \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\\\displaystyle\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(% \\\\mathcal{A}_{\\\\mu}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right),\\\\mathcal{A}_{\\\\nu}\\\\left(% \\\\cdot,\\\\widetilde{\\\\theta}\\\\right)\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{% \\\\frac{1}{k}} ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT where \\u03bc , \\u03bd \\u2208 P k \\u2062 ( \\ud835\\udcb3 ) \\ud835\\udf07 \\ud835\\udf08 subscript \\ud835\\udc43 \\ud835\\udc58 \\ud835\\udcb3 \\\\mu,\\\\nu\\\\in P_{k}(\\\\mathcal{X}) italic_\\u03bc , italic_\\u03bd \\u2208 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_X ) are two measures of probability distributions over the space \\ud835\\udcb3 \\ud835\\udcb3 \\\\mathcal{X} caligraphic_X (see Appendix B.1 for details). l \\u2208 \\u211d \\ud835\\udc59 \\u211d l\\\\in\\\\mathbb{R} italic_l \\u2208 blackboard_R and \\u03b8 ~ \\u2208 \\u211b \\u03b8 ~ ~ \\ud835\\udf03 subscript \\u211b ~ \\ud835\\udf03 \\\\widetilde{\\\\theta}\\\\in\\\\mathcal{R}_{\\\\widetilde{\\\\theta}} over~ start_ARG italic_\\u03b8 end_ARG \\u2208 caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT represent the parameters of hypersurfaces, both of which are the outputs from actor networks in ORPO-DR (see Figure 2 for details). The Adaptive Generalized Radon Transforms (AGRT) \\ud835\\udc9c \\ud835\\udc9c \\\\mathcal{A} caligraphic_A is used as a push-forward operator \\ud835\\udc9c \\u03bc subscript \\ud835\\udc9c \\ud835\\udf07 \\\\mathcal{A}_{\\\\mu} caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT , defined by \\ud835\\udc9c \\u03bc \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\ud835\\udd3e d \\u03b4 \\u2062 ( l \\u2212 \\u03b1 \\u2062 ( x , \\u03b8 ~ ) ) \\u2062 d \\u03bc subscript \\ud835\\udc9c \\ud835\\udf07 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\ud835\\udd3e \\ud835\\udc51 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udefc \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udf07 \\\\mathcal{A}_{\\\\mu}(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{G}^{d}}\\\\delta(l-\\\\alpha(x% ,\\\\widetilde{\\\\theta}))\\\\mathrm{d}\\\\mu caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_G start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03b4 ( italic_l - italic_\\u03b1 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d italic_\\u03bc , where \\u03b1 \\u2062 ( x , \\u03b8 ~ ) \\ud835\\udefc \\ud835\\udc65 ~ \\ud835\\udf03 \\\\alpha(x,\\\\widetilde{\\\\theta}) italic_\\u03b1 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) is a defining function satisfying the conditions H.1-H.4 in (Kolouri et al., 2019 ) . \\u211b \\u03b8 ~ \\u2282 \\u211d d subscript \\u211b ~ \\ud835\\udf03 superscript \\u211d \\ud835\\udc51 \\\\mathcal{R}_{\\\\widetilde{\\\\theta}}\\\\subset\\\\mathbb{R}^{d} caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT \\u2282 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT is a compact set of all feasible parameters \\u03b8 ~ ~ \\ud835\\udf03 \\\\widetilde{\\\\theta} over~ start_ARG italic_\\u03b8 end_ARG , where \\u211b \\u03b8 ~ = \\ud835\\udd4a d \\u2212 1 subscript \\u211b ~ \\ud835\\udf03 superscript \\ud835\\udd4a \\ud835\\udc51 1 \\\\mathcal{R}_{\\\\widetilde{\\\\theta}}=\\\\mathbb{S}^{d-1} caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT = blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT for \\u03b1 \\u2062 ( \\u22c5 , \\u03b8 ~ ) = \\u27e8 \\u22c5 , \\u03b8 ~ \\u27e9 \\ud835\\udefc \\u22c5 ~ \\ud835\\udf03 \\u22c5 ~ \\ud835\\udf03 \\\\alpha(\\\\cdot,\\\\widetilde{\\\\theta})=\\\\langle\\\\cdot,\\\\widetilde{\\\\theta}\\\\rangle italic_\\u03b1 ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u27e8 \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG \\u27e9 . Although the proposed adaptive slicing method, i.e., A-GSWD, improves the efficiency and accuracy of the Wasserstein distance computation, its demonstration on a valid metric guarantee remains a problem (Kolouri et al., 2019 ) . In Section 5 , we prove that the proposed A-GSWD is a true metric that satisfies non-negativity, symmetry, the triangle inequality and \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bc ) = 0 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 0 {\\\\bf{A-GSWD}}_{k}(\\\\mu,\\\\mu)=0 bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = 0 , respectively. We then employ A-GSWD to address the variational inference, i.e., minimizing the distance D ( q \\u03b8 ( \\u03c4 ) | | p ( \\u03c4 | \\ud835\\udcaa ) ) = \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k ( q \\u03b8 ( \\u03c4 ) , p ( \\u03c4 | \\ud835\\udcaa ) ) D(q_{\\\\theta}(\\\\tau)||p(\\\\tau|\\\\mathcal{O}))={\\\\bf{A-GSWD}}_{k}(q_{\\\\theta}(\\\\tau),p(% \\\\tau|\\\\mathcal{O})) italic_D ( italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) | | italic_p ( italic_\\u03c4 | caligraphic_O ) ) = bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) , italic_p ( italic_\\u03c4 | caligraphic_O ) ) between the variational distribution q \\u03b8 \\u2062 ( \\u03c4 ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f q_{\\\\theta}(\\\\tau) italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) and the posterior distribution p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa p(\\\\tau|\\\\mathcal{O}) italic_p ( italic_\\u03c4 | caligraphic_O ) . Subsequently, the variational inference can be reformulated to the minimization problem, as shown in WVI of Figure 2 : arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u2062 ( \\ud835\\udc1a ) , p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k q \\ud835\\udc1a p conditional \\ud835\\udcaa \\ud835\\udf0f \\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}{\\\\bf{A-GSWD}}_{k}\\\\left(q\\\\left(\\\\bm{a}% \\\\right),p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)\\\\right) roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q ( bold_a ) , roman_p ( caligraphic_O | italic_\\u03c4 ) ) , where p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) represents the optimality likelihood, and the detailed derivation is in Appendix D.1 . 4.2 ORPO-DR: Optimality-Rectified Policy Optimization using Distributional Representation The current policy optimization for constrained RL can be classified into two categories: primal-dual and primal approaches (Xu et al., 2021 ) . The former, transforming the constrained problem into an unconstrained one, are most commonly used although sensitive to Lagrange multipliers and other hyperparameters, such as the learning rate. On the other hand, the latter (i.e., primal approaches) require less hyperparameter tuning but have received less attention in terms of convergence demonstration compared to the primal-dual approaches. Policy Optimization combining Optimality Likelihood. Based on Section 4.1 , a constrained RL problem, as outlined in Equation 2 , can be iteratively substituted and resolved as: { arg \\u2061 max q \\u2062 ( \\ud835\\udc82 ) \\u2062 \\ud835\\udd3c \\u2062 [ \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) ] , \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] \\u2264 \\ud835\\udc1b i + \\ud835\\udf49 c arg \\u2061 min q \\u2062 ( \\ud835\\udc82 ) \\u2062 \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] , otherwise \\\\left\\\\{\\\\begin{aligned} &\\\\arg\\\\underset{q(\\\\bm{a})}{\\\\rm{max}}\\\\mathbb{E}[\\\\mathcal{% F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right)],\\\\;{\\\\mathbb{E}[\\\\mathcal{F}_{g}% \\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right)]}\\\\leq\\\\bm{b}_{i}+\\\\bm{\\\\tau}_{c}\\\\\\\\ &\\\\arg\\\\underset{q(\\\\bm{a})}{\\\\rm{min}}\\\\mathbb{E}[\\\\mathcal{F}_{g}\\\\cdot p\\\\left(% \\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right)],\\\\;\\\\;otherwise\\\\end{aligned}\\\\right. { start_ROW start_CELL end_CELL start_CELL roman_arg start_UNDERACCENT italic_q ( bold_italic_a ) end_UNDERACCENT start_ARG roman_max end_ARG blackboard_E [ caligraphic_F start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT \\u22c5 roman_p ( caligraphic_O start_POSTSUBSCRIPT roman_r end_POSTSUBSCRIPT | italic_\\u03c4 ) ] , blackboard_E [ caligraphic_F start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT \\u22c5 roman_p ( caligraphic_O start_POSTSUBSCRIPT roman_g start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] \\u2264 bold_b start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT + bold_italic_\\u03c4 start_POSTSUBSCRIPT roman_c end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL roman_arg start_UNDERACCENT italic_q ( bold_italic_a ) end_UNDERACCENT start_ARG roman_min end_ARG blackboard_E [ caligraphic_F start_POSTSUBSCRIPT roman_g end_POSTSUBSCRIPT \\u22c5 roman_p ( caligraphic_O start_POSTSUBSCRIPT roman_g start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] , roman_otherwise end_CELL end_ROW where we recall that { \\u2131 r , \\u2131 g } subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\left\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\right\\\\} { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } are two operators defined as \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) := r ~ \\u2062 ( \\u03c4 ) assign \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f ~ \\ud835\\udc5f \\ud835\\udf0f \\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right):=\\\\widetilde{r}(\\\\tau) caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) := over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) and \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) := g ~ i \\u2062 ( \\u03c4 ) assign \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right):=\\\\widetilde{g}_{i}% (\\\\tau) caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) := over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) , respectively. Furthermore, we can calculate the accumulated reward and utility function: r ~ \\u2062 ( \\u03c4 ) = \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 T \\u2212 1 \\u03b3 t \\u2062 r \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) ] ~ \\ud835\\udc5f \\ud835\\udf0f \\ud835\\udd3c delimited-[] superscript subscript \\ud835\\udc61 0 \\ud835\\udc47 1 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\\\widetilde{r}(\\\\tau)={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{T-1}\\\\gamma^{t}}r(\\\\bm{s}_{% t},\\\\bm{a}_{t})] over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) = blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] and g ~ i \\u2062 ( \\u03c4 ) = \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 T \\u2212 1 \\u03b3 t \\u2062 g i \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) ] subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\ud835\\udd3c delimited-[] superscript subscript \\ud835\\udc61 0 \\ud835\\udc47 1 superscript \\ud835\\udefe \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udc56 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\\\widetilde{g}_{i}(\\\\tau)={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{T-1}\\\\gamma^{t}}g_{i}(% \\\\bm{s}_{t},\\\\bm{a}_{t})] over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) = blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] . Consequently, we obtain \\ud835\\udca5 r \\u2062 ( \\u03c0 ) = \\ud835\\udd3c \\u2062 [ r ~ \\u2062 ( \\u03c4 ) ] subscript \\ud835\\udca5 \\ud835\\udc5f \\ud835\\udf0b \\ud835\\udd3c delimited-[] ~ \\ud835\\udc5f \\ud835\\udf0f \\\\mathcal{J}_{r}(\\\\pi)={\\\\mathbb{E}}[\\\\widetilde{r}(\\\\tau)] caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_\\u03c0 ) = blackboard_E [ over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) ] and \\ud835\\udca5 g , i \\u2062 ( \\u03c0 ) = \\ud835\\udd3c \\u2062 [ g ~ i \\u2062 ( \\u03c4 ) ] subscript \\ud835\\udca5 \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0b \\ud835\\udd3c delimited-[] subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathcal{J}_{g,i}(\\\\pi)={\\\\mathbb{E}}[\\\\widetilde{g}_{i}(\\\\tau)] caligraphic_J start_POSTSUBSCRIPT italic_g , italic_i end_POSTSUBSCRIPT ( italic_\\u03c0 ) = blackboard_E [ over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) ] if T = \\u221e \\ud835\\udc47 T=\\\\infty italic_T = \\u221e . If we only define \\u2131 r \\u221d log \\u2061 [ \\u22c5 ] proportional-to subscript \\u2131 \\ud835\\udc5f \\u22c5 \\\\mathcal{F}_{r}\\\\propto\\\\log[\\\\cdot] caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u221d roman_log [ \\u22c5 ] , it becomes equivalent to the formulation used in (Levine, 2018 ; Okada & Taniguchi, 2020 , 2018 ) . In this case, we can retrieve an optimization process that resembles Model Predictive Path Integral (MPPI) (Okada & Taniguchi, 2018 ) . The design of reward functions in the traditional RL is typically based on task-specific heuristics which is often considered as much an art as science. We will present such interpretation in Section 5 to show how the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F acts on convergence, as well as a more rigorous approach to ensure guaranteed global convergence rate during the training process. Additionally, in Section 6 , we empirically verify these theoretical guarantees. Policy Updating. As shown in Algorithm 1 , we first update the policy towards either maximizing \\ud835\\udd3c \\u2062 [ \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) ] \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f \\\\mathbb{E}[\\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right)] blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) ] or minimizing \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathbb{E}[\\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right)] blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] by using the distributional representation (introduced in Appendix C ), where the gradient of actor and critic network, denoted as \\u03b4 \\u03b8 \\u03bc subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udf07 \\\\delta_{\\\\theta^{\\\\mu}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and \\u03b4 \\u03b8 Q subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udc44 \\\\delta_{\\\\theta^{Q}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , are defined in Equation 8 in Appendix C . Then, as shown in ORPO-DR of Figure 2 , the actor network outputs the parameters to dynamically determine the hypersurfaces and the corresponding slicing directions; and the critic network provides an entire state-action distribution, which is directly utilized as the variational distribution of the optimality likelihood q \\u2062 ( \\ud835\\udc82 ) \\ud835\\udc5e \\ud835\\udc82 q(\\\\bm{a}) italic_q ( bold_italic_a ) in A-GSWD, as shown in Figure 2 . Algorithm 1 ORPO-DR: Optimality-Rectified Policy Optimization using Distributional Representation Input: \\ud835\\udc94 k subscript \\ud835\\udc94 \\ud835\\udc58 \\\\bm{s}_{k} bold_italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \\ud835\\udc94 k + 1 subscript \\ud835\\udc94 \\ud835\\udc58 1 \\\\bm{s}_{k+1} bold_italic_s start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT , \\ud835\\udf49 c subscript \\ud835\\udf49 \\ud835\\udc50 \\\\bm{\\\\tau}_{c} bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , \\u03b8 \\u03bc superscript \\ud835\\udf03 \\ud835\\udf07 \\\\theta^{\\\\mu} italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , \\u03b8 Q superscript \\ud835\\udf03 \\ud835\\udc44 \\\\theta^{Q} italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT Output: updated \\u03b8 \\u03bc superscript \\ud835\\udf03 \\ud835\\udf07 \\\\theta^{\\\\mu} italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , \\u03b8 Q superscript \\ud835\\udf03 \\ud835\\udc44 \\\\theta^{Q} italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT 1: Constraint Estimation : \\ud835\\udca5 g , i \\u2062 ( \\u03c0 \\u03b8 \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) ) = \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] subscript \\ud835\\udca5 \\ud835\\udc54 \\ud835\\udc56 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f {\\\\mathcal{J}_{g,i}}(\\\\pi_{\\\\theta}(\\\\bm{s},\\\\bm{a}))=\\\\mathbb{E}[\\\\mathcal{F}_{g}% \\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right)] caligraphic_J start_POSTSUBSCRIPT italic_g , italic_i end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) ) = blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] , \\u2200 i \\u2208 [ 1 , p ] for-all \\ud835\\udc56 1 \\ud835\\udc5d \\\\ \\\\forall i\\\\in[1,p] \\u2200 italic_i \\u2208 [ 1 , italic_p ] 2: Policy Improvement : 3: if \\ud835\\udca5 g , i \\u2062 ( \\ud835\\udf45 ) \\u2264 \\ud835\\udc83 i + \\ud835\\udf49 c , \\u2200 i \\u2208 [ 1 , p ] formulae-sequence subscript \\ud835\\udca5 \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf45 subscript \\ud835\\udc83 \\ud835\\udc56 subscript \\ud835\\udf49 \\ud835\\udc50 for-all \\ud835\\udc56 1 \\ud835\\udc5d {\\\\mathcal{J}_{g,i}}(\\\\bm{\\\\pi})\\\\leq\\\\bm{b}_{i}+\\\\bm{\\\\tau}_{c},\\\\forall i\\\\in[1,p] caligraphic_J start_POSTSUBSCRIPT italic_g , italic_i end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) \\u2264 bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , \\u2200 italic_i \\u2208 [ 1 , italic_p ] then 4: update the policy towards maximizing \\ud835\\udd3c \\u2062 [ \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) ] \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f \\\\mathbb{E}[\\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right)] blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) ] : \\u03b8 \\u03bc \\u2190 \\u03b8 \\u03bc + l \\u03bc \\u2062 \\u03b4 \\u03b8 \\u03bc \\u2190 superscript \\ud835\\udf03 \\ud835\\udf07 superscript \\ud835\\udf03 \\ud835\\udf07 subscript \\ud835\\udc59 \\ud835\\udf07 subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udf07 \\\\theta^{\\\\mu}\\\\leftarrow\\\\theta^{\\\\mu}+l_{\\\\mu}\\\\delta_{\\\\theta^{\\\\mu}} italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT \\u2190 italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT + italic_l start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , and \\u03b8 Q \\u2190 \\u03b8 Q + l \\u03b8 \\u2062 \\u03b4 \\u03b8 Q \\u2190 superscript \\ud835\\udf03 \\ud835\\udc44 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc59 \\ud835\\udf03 subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udc44 \\\\theta^{Q}\\\\leftarrow\\\\theta^{Q}+l_{\\\\theta}\\\\delta_{\\\\theta^{Q}} italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT \\u2190 italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT + italic_l start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT 5: else 6: update the policy towards minimizing \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathbb{E}[\\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right)] blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] : \\u03b8 \\u03bc \\u2190 \\u03b8 \\u03bc \\u2212 l \\u03bc \\u2062 \\u2207 \\u03b8 \\u03bc g ~ i \\u2062 ( \\u03c4 ) \\u2190 superscript \\ud835\\udf03 \\ud835\\udf07 superscript \\ud835\\udf03 \\ud835\\udf07 subscript \\ud835\\udc59 \\ud835\\udf07 subscript \\u2207 superscript \\ud835\\udf03 \\ud835\\udf07 subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\theta^{\\\\mu}\\\\leftarrow\\\\theta^{\\\\mu}-l_{\\\\mu}\\\\nabla_{\\\\theta^{\\\\mu}}\\\\widetilde{g}_{% i}(\\\\tau) italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT \\u2190 italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT - italic_l start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) , and \\u03b8 Q \\u2190 \\u03b8 Q \\u2212 l Q \\u2062 \\u2207 \\u03b8 Q g ~ i \\u2062 ( \\u03c4 ) \\u2190 superscript \\ud835\\udf03 \\ud835\\udc44 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc59 \\ud835\\udc44 subscript \\u2207 superscript \\ud835\\udf03 \\ud835\\udc44 subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\theta^{Q}\\\\leftarrow\\\\theta^{Q}-l_{Q}\\\\nabla_{\\\\theta^{Q}}\\\\widetilde{g}_{i}(\\\\tau) italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT \\u2190 italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT - italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) 7: end if Algorithm 2 AWaVO: Adaptive Sliced Wasserstein Variational Optimization Input: \\ud835\\udc94 k subscript \\ud835\\udc94 \\ud835\\udc58 \\\\bm{s}_{k} bold_italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \\ud835\\udc94 k + 1 subscript \\ud835\\udc94 \\ud835\\udc58 1 \\\\bm{s}_{k+1} bold_italic_s start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT , \\u03b8 \\u03bc superscript \\ud835\\udf03 \\ud835\\udf07 \\\\theta^{\\\\mu} italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , \\u03b8 Q superscript \\ud835\\udf03 \\ud835\\udc44 \\\\theta^{Q} italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT Output: \\ud835\\udc82 k subscript \\ud835\\udc82 \\ud835\\udc58 \\\\bm{a}_{k} bold_italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT 1: Initialize : \\ud835\\udf3d = [ \\u03b8 \\u03bc , \\u03b8 Q ] \\ud835\\udf3d superscript \\ud835\\udf03 \\ud835\\udf07 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\bm{\\\\theta}=[\\\\theta^{\\\\mu},\\\\theta^{Q}] bold_italic_\\u03b8 = [ italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ] : the parameters of actor and critic network 2: repeat 3: for t = 0 , 1 , 2 , \\u2026 , T \\u2212 1 \\ud835\\udc61 0 1 2 \\u2026 \\ud835\\udc47 1 t=0,1,2,...,T-1 italic_t = 0 , 1 , 2 , \\u2026 , italic_T - 1 do 4: Parameter Identification: achieve p D \\u2062 ( \\u03b8 ) subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p_{D}(\\\\theta) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) by doing inference of the posteriors p \\u2062 ( \\u03b8 | D ) \\ud835\\udc5d conditional \\ud835\\udf03 \\ud835\\udc37 p(\\\\theta|D) italic_p ( italic_\\u03b8 | italic_D ) (Section 3 ) 5: Policy Updating: { \\u03b8 \\u03bc , \\u03b8 Q } \\u2190 \\u2190 superscript \\ud835\\udf03 \\ud835\\udf07 superscript \\ud835\\udf03 \\ud835\\udc44 absent \\\\left\\\\{\\\\theta^{\\\\mu},\\\\theta^{Q}\\\\right\\\\}\\\\leftarrow { italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT } \\u2190 Exec. Algorithm 1 ( \\ud835\\udc94 k (\\\\bm{s}_{k} ( bold_italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , \\ud835\\udc94 k + 1 subscript \\ud835\\udc94 \\ud835\\udc58 1 \\\\bm{s}_{k+1} bold_italic_s start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT , \\ud835\\udf49 c subscript \\ud835\\udf49 \\ud835\\udc50 \\\\bm{\\\\tau}_{c} bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , \\u03b8 \\u03bc superscript \\ud835\\udf03 \\ud835\\udf07 \\\\theta^{\\\\mu} italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT , \\u03b8 Q ) \\\\theta^{Q}) italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) 6: Inference Execution: do inference of the posterior probability, as described in Section 4.1 : p \\u2062 ( \\u03c4 | \\ud835\\udcaa t : T ) \\u2190 arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u2062 ( \\ud835\\udc1a ) , p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) \\u2190 \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udcaa : \\ud835\\udc61 \\ud835\\udc47 subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k q \\ud835\\udc1a p conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\tau|\\\\mathcal{O}_{t:T})\\\\leftarrow\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}{% \\\\bf{A-GSWD}}_{k}\\\\left(q\\\\left(\\\\bm{a}\\\\right),p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)\\\\right) italic_p ( italic_\\u03c4 | caligraphic_O start_POSTSUBSCRIPT italic_t : italic_T end_POSTSUBSCRIPT ) \\u2190 roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q ( bold_a ) , roman_p ( caligraphic_O | italic_\\u03c4 ) ) 7: sample actions \\ud835\\udc82 k \\u2190 p \\u2062 ( \\u03c4 | \\ud835\\udcaa t : T ) \\u2190 subscript \\ud835\\udc82 \\ud835\\udc58 \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udcaa : \\ud835\\udc61 \\ud835\\udc47 \\\\bm{a}_{k}\\\\leftarrow p(\\\\tau|\\\\mathcal{O}_{t:T}) bold_italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \\u2190 italic_p ( italic_\\u03c4 | caligraphic_O start_POSTSUBSCRIPT italic_t : italic_T end_POSTSUBSCRIPT ) , execute \\ud835\\udc82 k subscript \\ud835\\udc82 \\ud835\\udc58 \\\\bm{a}_{k} bold_italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , and observe \\ud835\\udc94 k + 1 subscript \\ud835\\udc94 \\ud835\\udc58 1 \\\\bm{s}_{k+1} bold_italic_s start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT 8: end for 9: until convergence (a) Acrobot tasks in OpenAI Gym (b) Cartpole tasks in OpenAI Gym (c) Walker tasks in GUARD (d) Drone tasks in GUARD Figure 3: Performance comparison over 10 seeds. CRPO and AWaVO outperform PaETS, with a trade-off highlighted: although PaETS offers probabilistic interpretation with Bayesian networks, its convergence is generally unstable. Our proposed AWaVO achieves a better balance between high performance and interpretability. In contrast to two other constrained RL algorithms, i.e., TRPO-IPO and PCPO, we observe an interesting result: PCPO performs better in tasks like Acrobot, Cartpole, and Walker, while TRPO-IPO outperforms PCPO in the more complex drone tasks (Figure 3(d) ). Further, in Figure 5 , we will explore more complex real-world tasks using an aerial robot. 5 Formal Methods for Interpretability Proposition 5.1 . (Pseudo-metric): Given two probability measures \\u03bc , \\u03bd \\u2208 P k \\u2062 ( \\ud835\\udcb3 ) \\ud835\\udf07 \\ud835\\udf08 subscript \\ud835\\udc43 \\ud835\\udc58 \\ud835\\udcb3 \\\\mu,\\\\nu\\\\in P_{k}(\\\\mathcal{X}) italic_\\u03bc , italic_\\u03bd \\u2208 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_X ) and a mapping \\u03b1 : \\ud835\\udcb3 \\u2192 \\u211b \\u03b8 ~ : \\ud835\\udefc \\u2192 \\ud835\\udcb3 subscript \\u211b ~ \\ud835\\udf03 \\\\alpha:\\\\mathcal{X}\\\\rightarrow\\\\mathcal{R}_{\\\\widetilde{\\\\theta}} italic_\\u03b1 : caligraphic_X \\u2192 caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , the adaptive slicing A-GSWD, defined in Definition 4.1 , with order k \\ud835\\udc58 k italic_k in the range [ 1 , \\u221e ) 1 [1,\\\\infty) [ 1 , \\u221e ) , is a pseudo-metric that satisfies non-negativity, symmetry, the triangle inequality and \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bc ) = 0 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 0 {\\\\bf{A-GSWD}}_{k}(\\\\mu,\\\\mu)=0 bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = 0 . See Appendix D.3 for Proof. Remark 5.2 . The adaptive slicing A-GSWD, with order k \\u2208 [ 1 , \\u221e ) \\ud835\\udc58 1 k\\\\in[1,\\\\infty) italic_k \\u2208 [ 1 , \\u221e ) , is a true metric if and only if the AGRT \\ud835\\udc9c \\ud835\\udc9c \\\\mathcal{A} caligraphic_A , defined in Definition 4.1 , is an injective mapping. We make the following three assumptions. Assumption 1 . We define the function: p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) = p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u2062 p \\u2062 ( \\u03c4 | \\u03b8 ) \\u2062 p D \\u2062 ( \\u03b8 ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p(\\\\tau|\\\\mathcal{O})=p(\\\\mathcal{O}|\\\\tau)p(\\\\tau|\\\\theta)p_{D}(\\\\theta) italic_p ( italic_\\u03c4 | caligraphic_O ) = italic_p ( caligraphic_O | italic_\\u03c4 ) italic_p ( italic_\\u03c4 | italic_\\u03b8 ) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) . Assumption 2 . Let \\u03a8 \\u2062 ( s , a ) \\u03a8 \\ud835\\udc60 \\ud835\\udc4e \\\\Psi(s,a) roman_\\u03a8 ( italic_s , italic_a ) be a feature vector, and \\u03c7 \\u03c0 subscript \\ud835\\udf12 \\ud835\\udf0b \\\\chi_{\\\\pi} italic_\\u03c7 start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT be a stationary distribution in CMDP: ( s , a ) \\u223c \\u03c7 \\u03c0 similar-to \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf12 \\ud835\\udf0b (s,a)\\\\sim\\\\chi_{\\\\pi} ( italic_s , italic_a ) \\u223c italic_\\u03c7 start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT . There exists a constant C 0 ^ ^ subscript \\ud835\\udc36 0 \\\\hat{C_{0}} over^ start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG such that for any \\u03f1 \\u2265 0 italic-\\u03f1 0 \\\\varrho\\\\geq 0 italic_\\u03f1 \\u2265 0 , it holds that p \\u2062 ( | x \\ud835\\uddb3 \\u2062 \\u03a8 \\u2062 ( s , a ) | \\u2264 \\u03f1 ) \\u2264 C 0 ^ \\u22c5 \\u03f1 \\ud835\\udc5d superscript \\ud835\\udc65 \\ud835\\uddb3 \\u03a8 \\ud835\\udc60 \\ud835\\udc4e italic-\\u03f1 \\u22c5 ^ subscript \\ud835\\udc36 0 italic-\\u03f1 p(\\\\left|x^{\\\\mathsf{T}}\\\\Psi(s,a)\\\\right|\\\\leq\\\\varrho)\\\\leq\\\\hat{C_{0}}\\\\cdot\\\\varrho italic_p ( | italic_x start_POSTSUPERSCRIPT sansserif_T end_POSTSUPERSCRIPT roman_\\u03a8 ( italic_s , italic_a ) | \\u2264 italic_\\u03f1 ) \\u2264 over^ start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG \\u22c5 italic_\\u03f1 , where x \\u2208 \\u211d d \\ud835\\udc65 superscript \\u211d \\ud835\\udc51 x\\\\in\\\\mathbb{R}^{d} italic_x \\u2208 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT . Assumption 3 . We define the family of functions: \\u212c R , \\u221e subscript \\u212c \\ud835\\udc45 \\\\displaystyle\\\\mathcal{B}_{R,\\\\infty} caligraphic_B start_POSTSUBSCRIPT italic_R , \\u221e end_POSTSUBSCRIPT = f \\u2062 ( ( s , a ) ; \\u03b8 q ) = f \\u2062 ( ( s , a ) ; \\u03b8 q , 0 ) absent \\ud835\\udc53 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf03 \\ud835\\udc5e \\ud835\\udc53 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf03 \\ud835\\udc5e 0 \\\\displaystyle=f((s,a);\\\\theta_{q})=f((s,a);\\\\theta_{q,0}) = italic_f ( ( italic_s , italic_a ) ; italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) = italic_f ( ( italic_s , italic_a ) ; italic_\\u03b8 start_POSTSUBSCRIPT italic_q , 0 end_POSTSUBSCRIPT ) + \\u222b \\ud835\\udfcf \\u2062 ( \\u03b8 q \\ud835\\uddb3 \\u2062 \\u03a8 \\u2062 ( s , a ) > 0 ) \\u22c5 \\u03c9 \\u2062 ( \\u03b8 q ) \\ud835\\uddb3 \\u2062 \\u03a8 \\u2062 ( s , a ) \\u2062 d \\u03c6 \\u2062 ( \\u03b8 q ) \\u22c5 1 superscript subscript \\ud835\\udf03 \\ud835\\udc5e \\ud835\\uddb3 \\u03a8 \\ud835\\udc60 \\ud835\\udc4e 0 \\ud835\\udf14 superscript subscript \\ud835\\udf03 \\ud835\\udc5e \\ud835\\uddb3 \\u03a8 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udf11 subscript \\ud835\\udf03 \\ud835\\udc5e \\\\displaystyle+\\\\int\\\\mathbf{1}({\\\\theta_{q}}^{\\\\mathsf{T}}\\\\Psi(s,a)>0)\\\\cdot\\\\omega(% \\\\theta_{q})^{\\\\mathsf{T}}\\\\Psi(s,a)\\\\mathrm{d}\\\\varphi(\\\\theta_{q}) + \\u222b bold_1 ( italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT sansserif_T end_POSTSUPERSCRIPT roman_\\u03a8 ( italic_s , italic_a ) > 0 ) \\u22c5 italic_\\u03c9 ( italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT sansserif_T end_POSTSUPERSCRIPT roman_\\u03a8 ( italic_s , italic_a ) roman_d italic_\\u03c6 ( italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) where f \\u2062 ( ( s , a ) ; \\u03b8 q ) \\ud835\\udc53 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf03 \\ud835\\udc5e f((s,a);\\\\theta_{q}) italic_f ( ( italic_s , italic_a ) ; italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) is an H \\ud835\\udc3b H italic_H -layer neural network corresponding to the initial parameter \\u03b8 q , 0 subscript \\ud835\\udf03 \\ud835\\udc5e 0 \\\\theta_{q,0} italic_\\u03b8 start_POSTSUBSCRIPT italic_q , 0 end_POSTSUBSCRIPT . The weighted function \\u03c9 \\u2062 ( \\u03b8 q ) : \\u211d d \\u2192 \\u211d d : \\ud835\\udf14 subscript \\ud835\\udf03 \\ud835\\udc5e \\u2192 superscript \\u211d \\ud835\\udc51 superscript \\u211d \\ud835\\udc51 \\\\omega(\\\\theta_{q}):\\\\mathbb{R}^{d}\\\\rightarrow\\\\mathbb{R}^{d} italic_\\u03c9 ( italic_\\u03b8 start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ) : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \\u2192 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT satisfies \\u2016 \\u03c9 \\u2062 ( \\u22c5 ) \\u2016 \\u221e \\u2264 C R / d subscript norm \\ud835\\udf14 \\u22c5 subscript \\ud835\\udc36 \\ud835\\udc45 \\ud835\\udc51 \\\\left\\\\|\\\\omega(\\\\cdot)\\\\right\\\\|_{\\\\infty}\\\\leq C_{R}/\\\\sqrt{d} \\u2225 italic_\\u03c9 ( \\u22c5 ) \\u2225 start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT \\u2264 italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT / square-root start_ARG italic_d end_ARG , where C R \\u2208 \\u211d subscript \\ud835\\udc36 \\ud835\\udc45 \\u211d C_{R}\\\\in\\\\mathbb{R} italic_C start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT \\u2208 blackboard_R denotes an upper bounded value and d \\u2265 2 \\ud835\\udc51 2 d\\\\geq 2 italic_d \\u2265 2 . \\u03c6 \\u2062 ( \\u22c5 ) : \\u211d d \\u2192 \\u211d : \\ud835\\udf11 \\u22c5 \\u2192 superscript \\u211d \\ud835\\udc51 \\u211d \\\\varphi(\\\\cdot):\\\\mathbb{R}^{d}\\\\rightarrow\\\\mathbb{R} italic_\\u03c6 ( \\u22c5 ) : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \\u2192 blackboard_R represents the density of the weight distribution. We assume Q \\u03c0 \\u2208 \\u212c R , \\u221e superscript \\ud835\\udc44 \\ud835\\udf0b subscript \\u212c \\ud835\\udc45 Q^{\\\\pi}\\\\in\\\\mathcal{B}_{R,\\\\infty} italic_Q start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT \\u2208 caligraphic_B start_POSTSUBSCRIPT italic_R , \\u221e end_POSTSUBSCRIPT , for all \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 . 1 specifies that in our implementation, the term p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa p(\\\\tau|\\\\mathcal{O}) italic_p ( italic_\\u03c4 | caligraphic_O ) is explicitly formulated as p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u2062 p \\u2062 ( \\u03c4 | \\u03b8 ) \\u2062 p D \\u2062 ( \\u03b8 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p(\\\\mathcal{O}|\\\\tau)p(\\\\tau|\\\\theta)p_{D}(\\\\theta) italic_p ( caligraphic_O | italic_\\u03c4 ) italic_p ( italic_\\u03c4 | italic_\\u03b8 ) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) . 2 implies that the probability density of the distribution \\u03a8 \\u2062 ( s , a ) \\u03a8 \\ud835\\udc60 \\ud835\\udc4e \\\\Psi(s,a) roman_\\u03a8 ( italic_s , italic_a ) is uniformly upper-bounded over the unit sphere, a condition achievable in most ergodic Markov chains (Mitrophanov, 2005 ; Xu et al., 2021 ) . 3 implies a mild and broadly applicable regularity condition on Q \\u03c0 superscript \\ud835\\udc44 \\ud835\\udf0b Q^{\\\\pi} italic_Q start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT , as \\u212c R , \\u221e subscript \\u212c \\ud835\\udc45 \\\\mathcal{B}_{R,\\\\infty} caligraphic_B start_POSTSUBSCRIPT italic_R , \\u221e end_POSTSUBSCRIPT can be interpreted as a function class with infinite width neural networks, thus representing a sufficiently general set of functions. To establish a link between the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F and the global convergence of ORPO-DR, here, we introduce 5.3 and then present Theorem 5.4 (Global Convergence) . Conditions 5.3 . The reward operator family \\u2131 = { \\u2131 r , \\u2131 g } \\u2131 subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}=\\\\left\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\right\\\\} caligraphic_F = { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } satisfies that: (i) \\u2131 r subscript \\u2131 \\ud835\\udc5f \\\\mathcal{F}_{r} caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is monotonically increasing and continuously defined on ( 0 , 1 ] 0 1 (0,1] ( 0 , 1 ] , and the range covers [ r min , r max ] subscript \\ud835\\udc5f subscript \\ud835\\udc5f [r_{\\\\min},r_{\\\\max}] [ italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] ; and (ii) \\u2131 g subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}_{g} caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT is monotonically decreasing and continuously defined on ( 0 , 1 ] 0 1 (0,1] ( 0 , 1 ] , and the range covers [ r min , r max ] subscript \\ud835\\udc5f subscript \\ud835\\udc5f [r_{\\\\min},r_{\\\\max}] [ italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] . Theorem 5.4 . (Global Convergence): Given the policy in the i \\ud835\\udc56 i italic_i -th policy improvement \\ud835\\uded1 \\ud835\\udc22 superscript \\ud835\\uded1 \\ud835\\udc22 \\\\bm{\\\\pi}^{\\\\bm{i}} bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT , \\ud835\\uded1 \\ud835\\udc22 \\u2192 \\ud835\\uded1 \\u2217 \\u2192 superscript \\ud835\\uded1 \\ud835\\udc22 superscript \\ud835\\uded1 \\\\bm{\\\\pi}^{\\\\bm{i}}\\\\rightarrow\\\\bm{\\\\pi}^{*} bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT \\u2192 bold_italic_\\u03c0 start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT and i \\u2192 \\u221e \\u2192 \\ud835\\udc56 i\\\\rightarrow\\\\infty italic_i \\u2192 \\u221e , suppose 1 holds, there exists Q \\ud835\\uded1 \\u2217 \\u2062 ( s , a ) \\u2265 Q \\ud835\\uded1 \\ud835\\udc22 \\u2062 ( s , a ) superscript \\ud835\\udc44 superscript \\ud835\\uded1 \\ud835\\udc60 \\ud835\\udc4e superscript \\ud835\\udc44 superscript \\ud835\\uded1 \\ud835\\udc22 \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}^{*}}(s,a)\\\\geq Q^{\\\\bm{\\\\pi}^{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) \\u2265 italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies the both 5.3 . See Appendix D.3 for Proof. Subsequently, we present a more rigorous comprehension of how \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F precisely influences the convergence rate. To our best knowledge, this study represents the first attempt to develop an intrinsic interpretation of how the reward function design influences convergence within the RL community. Theorem 5.5 . (Global Convergence Rate): Let m \\ud835\\udc5a m italic_m and H \\ud835\\udc3b H italic_H be the width and layers of a neural network, K t \\u2062 d = ( 1 \\u2212 \\u03b3 ) \\u2212 3 2 \\u2062 m H 2 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 superscript 1 \\ud835\\udefe 3 2 superscript \\ud835\\udc5a \\ud835\\udc3b 2 K_{td}=(1-\\\\gamma)^{-\\\\frac{3}{2}}m^{\\\\frac{H}{2}} italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT = ( 1 - italic_\\u03b3 ) start_POSTSUPERSCRIPT - divide start_ARG 3 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT be the iterations required for convergence of the distributional Temporal Difference (TD) learning (defined in Equation 10 ), l Q = 1 T subscript \\ud835\\udc59 \\ud835\\udc44 1 \\ud835\\udc47 l_{Q}=\\\\frac{1}{\\\\sqrt{T}} italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_T end_ARG end_ARG be the policy update (in Line 4 of Algorithm 1 ) and \\ud835\\uded5 c = \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 ) subscript \\ud835\\uded5 \\ud835\\udc50 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\bm{\\\\tau}_{c}=\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}})+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)% Tm^{\\\\frac{H}{4}}}) bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG ) be the tolerance (in Line 3 of Algorithm 1 ). Suppose Assumptions 1-3 hold. There exists a global convergence rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) , and a sublinear rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) if the constraints are violated with an error of \\u0398 \\u2062 ( 1 / m H 4 ) \\u0398 1 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\Theta(1/{m^{\\\\frac{H}{4}}}) roman_\\u0398 ( 1 / italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) , with probability of at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 . This holds if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies 5.3 . See Appendix D.3 for Proof. Probabilistic interpretation on sequential decisions. We now quantitatively establish the relationships between latent factors, such as disturbances, that possibly influence decision-making and the sequential decisions, namely trajectories, by providing a probabilistic interpretation. Referring to the abbreviation presented in Equation 1 , we reform it as: p \\u2062 ( \\u03c4 | D ) = p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u22c5 p \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 | \\u03b8 ) \\u22c5 p D \\u2062 ( \\u03b8 ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udc37 \\u22c5 \\u22c5 \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f \\ud835\\udc5d \\ud835\\udc94 conditional \\ud835\\udc82 \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p(\\\\tau|D)=p(\\\\mathcal{O}|\\\\tau)\\\\cdot p(\\\\bm{s},\\\\bm{a}|\\\\theta)\\\\cdot p_{D}(\\\\theta) italic_p ( italic_\\u03c4 | italic_D ) = italic_p ( caligraphic_O | italic_\\u03c4 ) \\u22c5 italic_p ( bold_italic_s , bold_italic_a | italic_\\u03b8 ) \\u22c5 italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) . Then, the latent factors are denoted by L = { L i } i = 0 M \\u2212 1 \\ud835\\udc3f superscript subscript subscript \\ud835\\udc3f \\ud835\\udc56 \\ud835\\udc56 0 \\ud835\\udc40 1 L=\\\\left\\\\{L_{i}\\\\right\\\\}_{i=0}^{M-1} italic_L = { italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M - 1 end_POSTSUPERSCRIPT , where M \\ud835\\udc40 M italic_M represents the total number of defined factors. By applying the chain rule to the posterior probability p \\u2062 ( \\u03c4 | D ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udc37 p(\\\\tau|D) italic_p ( italic_\\u03c4 | italic_D ) , we have { p \\u2062 ( \\u03c4 | L i ) } i = 0 M = { p \\u2062 ( \\u03c4 | D ) p \\u2062 ( L i | D ) } i = 0 M superscript subscript \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udc3f \\ud835\\udc56 \\ud835\\udc56 0 \\ud835\\udc40 superscript subscript \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udc37 \\ud835\\udc5d conditional subscript \\ud835\\udc3f \\ud835\\udc56 \\ud835\\udc37 \\ud835\\udc56 0 \\ud835\\udc40 \\\\left\\\\{p(\\\\tau|L_{i})\\\\right\\\\}_{i=0}^{M}=\\\\left\\\\{\\\\frac{p(\\\\tau|D)}{p(L_{i}|D)}% \\\\right\\\\}_{i=0}^{M} { italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT = { divide start_ARG italic_p ( italic_\\u03c4 | italic_D ) end_ARG start_ARG italic_p ( italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_D ) end_ARG } start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT , where the equation provides a decomposition of the joint posterior probability p \\u2062 ( \\u03c4 | D ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udc37 p(\\\\tau|D) italic_p ( italic_\\u03c4 | italic_D ) into conditional probabilities that involve individual factors L i subscript \\ud835\\udc3f \\ud835\\udc56 L_{i} italic_L start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . This decomposition is not only notable for its theoretical simplicity but facilitates a practical probabilistic understanding of how each factor influences policy in real-world safety-critical scenarios, such as robot autonomy. In Section 6 , we showcase numerical examples to illustrate such probabilistic interpretation. Figure 4: We use our AWaVO as the tracking controller for a quadrotor, where ORPO-DR is employed as the uncertainty estimator, and WVI using A-GSWD is leveraged as the controller. Figure 5: Performance comparison in a real quadrotor: our AWaVO slightly outperforms the constrained RL approach, i.e., PCPO, whilst achieving interpretability in Figure 7 . 6 Experiments Figure 6: Real quadrotor Flight Tasks (FTs): (i) FT 1 - tracking reference trajectories under external forces without obstacles; (ii) FT 2 - tracking trajectories around dense obstacles; and (iii) FT 3 - tracking trajectories under external forces around dense obstacles. In this section, we explain our empirical assessments of AWaVO\\u2019s performance in simulated platforms and real-world robot tasks. Initially, we perform tasks with multiple constraints in OpenAI Gym framework (Brockman et al., 2016 ) . Then we showcase AWaVO\\u2019s practicality through real quadrotor Flight Tasks (FTs) to provide a more comprehensive assessment of its performance. These evaluations serve a dual purpose: to validate AWaVO\\u2019s performance; and, critically, to empirically demonstrate its quantitative interpretability. This interpretability includes confirming properties such as the guaranteed convergence rate as demonstrated in Theorem 5.5 and the probabilistic decision interpretation discussed in Section 5 within the context of sequential decision-making tasks. Comparative Performance in Simulated Tasks. We conduct tasks with multiple constraints in OpenAI Gym (Brockman et al., 2016 ) and GUARD (Zhao et al., 2023 ) (a constrained RL benchmark): Acrobot, Cartpole, Walker and Drone. We use four appropriate constrained RL benchmarks: PaETS (Okada & Taniguchi, 2020 ) , i.e., a Bayesian RL combining with variational inference, TRPO-IPO (Liu et al., 2020 ) , i.e., an enhanced variant of TRPO-Lagrangian (Bohez et al., 2019 ) , PCPO (Yang et al., 2020 ) , i.e., an advanced variant of CPO (Achiam et al., 2017 ) and CRPO (Xu et al., 2021 ) , i.e., a primal constrained RL approach. The AWaVO parameter settings given in Table 2 of Appendix E.1 are based on selected benchmarks, i.e., CRPO (Xu et al., 2021 ) and GUARD (Zhao et al., 2023 ) . According to our proposed Proposition 5.1 and the Proposition 1 presented in (Kolouri et al., 2019 ) , the defining function \\u03b1 \\u2062 ( \\u22c5 , \\u03b8 ~ ) \\ud835\\udefc \\u22c5 ~ \\ud835\\udf03 \\\\alpha(\\\\cdot,\\\\widetilde{\\\\theta}) italic_\\u03b1 ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) can be defined as homogeneous polynomials, i.e., \\u03b1 \\u2062 ( \\u22c5 , \\u03b8 ~ ) = \\u2211 | \\u03ba | = m \\u03b8 ~ \\u03ba \\u2062 x \\u03ba \\ud835\\udefc \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udf05 \\ud835\\udc5a subscript ~ \\ud835\\udf03 \\ud835\\udf05 superscript \\ud835\\udc65 \\ud835\\udf05 \\\\alpha(\\\\cdot,\\\\widetilde{\\\\theta})=\\\\sum_{\\\\left|\\\\kappa\\\\right|=m}\\\\widetilde{\\\\theta% }_{\\\\kappa}x^{\\\\kappa} italic_\\u03b1 ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u2211 start_POSTSUBSCRIPT | italic_\\u03ba | = italic_m end_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG start_POSTSUBSCRIPT italic_\\u03ba end_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_\\u03ba end_POSTSUPERSCRIPT , where the defining function \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 is injective if the degree of the polynomial m \\ud835\\udc5a m italic_m is odd. Thus we set m = 3 \\ud835\\udc5a 3 m=3 italic_m = 3 based on (Kolouri et al., 2019 ) . The comprehensive task descriptions are available in Appendix E.2 . AWaVO\\u2019s training depicted in Figure 3 initially corresponds to the benchmarks provided by CRPO (Xu et al., 2021 ) and GUARD (Zhao et al., 2023 ) . The distinction in iterations lies in showcasing the entire convergence process across four discrete tasks. We establish the constraint limit to facilitate a straightforward comparison of constraint convergence; see Appendix E.3 for additional details. The tolerance is set as \\ud835\\udf49 c = 0.5 subscript \\ud835\\udf49 \\ud835\\udc50 0.5 \\\\bm{\\\\tau}_{c}=0.5 bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 0.5 , following CRPO (Xu et al., 2021 ) . By analyzing the comparative training performances in Figure 3 , we observe that the superiority of CRPO and AWaVO stems from their primal constrained RL nature, which involves training under constraints and ensuring global convergence rate. Although CRPO exhibits comparable or slightly better convergence performance than AWaVO, as evident in Figure 3(d) , we place greater emphasis on two other aspects: training convergence under uncertainties and decision-making interpretation. In Figure 5 below, we provide comparative demonstrations in real robot tasks to showcase how AWaVO effectively balances a trade-off between performance and interpretability in a more complex sequential decision-making scenario. Furthermore, we empirically verify the formal method Theorem 5.5 (Global Convergence Rate) on the convergence rate, and conclude that, based on the average performance, the convergence rate of AWaVO is in the range of \\u0398 \\u2062 ( 1 / T ) < C r \\u2062 a \\u2062 t \\u2062 e \\u2264 \\u0398 \\u2062 ( 1 / T 1.2 ) \\u0398 1 \\ud835\\udc47 subscript \\ud835\\udc36 \\ud835\\udc5f \\ud835\\udc4e \\ud835\\udc61 \\ud835\\udc52 \\u0398 1 superscript \\ud835\\udc47 1.2 \\\\Theta(1/\\\\sqrt{T})<C_{rate}\\\\leq\\\\Theta(1/T^{1.2}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) < italic_C start_POSTSUBSCRIPT italic_r italic_a italic_t italic_e end_POSTSUBSCRIPT \\u2264 roman_\\u0398 ( 1 / italic_T start_POSTSUPERSCRIPT 1.2 end_POSTSUPERSCRIPT ) . According to the results shown in Figure 3(d) , CRPO performs better than our AWaVO in the simulated drone task, with the absence of disturbances. Subsequently, in Figure 5 below, we further evaluate these approaches in a real-world physical environment characterized by varying uncertainties, leading to different outcomes. It is worth noting that our approach incorporates two optimizations for handling uncertainties: variational inference and policy updating. This combination reduces the frequency of policy updates whilst enhancing our ability to handle uncertainties. In the upcoming real robot task, we will introduce variable disturbances to demonstrate our capability to optimize policies under uncertain conditions. Figure 7: Probabilistic interpretation of decisions: the probability p \\u2062 ( \\u03c4 | L 0 ) \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udc3f 0 p(\\\\tau|L_{0}) italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) reveals the degree to which the measurement of external forces (Ding et al., 2021 ) , denoted as n f subscript \\ud835\\udc5b \\ud835\\udc53 n_{f} italic_n start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT , influences the decisions made by the quadrotor. For additional discussion on the case of \\u2018RS 02\\u2019, as an example instance, please refer to Appendix E.4 . Comparative Performance in Real-world Tasks. We demonstrate the effectiveness of AWaVO by practical implementation in real-world decision-making problems. The quadrotor\\u2019s tracking control system, shown in Figure 4 , is an end-to-end learning-based framework. The technical specification of our quadrotor is shown in Table 3 of Appendix E.1 . The training convergence is demonstrated in Figure 5 . The aim of the real-world tasks (shown in Figure 6 ) is to track the reference effectively and accurately, where VID-Fusion (Ding et al., 2021 ) is used to measure external forces such as aerodynamic effects. To view the hardware experiments in action, please refer to the accompanying video demonstration at https://github.com/Alex-yanranwang/AWaVO . Next, we illustrate the interpretation of sequential decisions, i.e., the actual control commands fed into the four motors. Leveraging the Intel RealSense D435i depth camera onboard, we can detect obstacles and estimate external forces. These latent factors, denoted as L = L 0 , L 1 \\ud835\\udc3f subscript \\ud835\\udc3f 0 subscript \\ud835\\udc3f 1 L={L_{0},L_{1}} italic_L = italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , represent external forces and obstacles, respectively. The probability p \\u2062 ( \\u03c4 | L ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udc3f p(\\\\tau|L) italic_p ( italic_\\u03c4 | italic_L ) reveals why the quadrotor makes these decisions and quantifies the extent to which factor L \\ud835\\udc3f L italic_L contributes to the sequential decisions, i.e., the real-time trajectory \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 . Figure 7 presents a quantitative interpretation, i.e., p \\u2062 ( \\u03c4 | L 0 ) \\ud835\\udc5d conditional \\ud835\\udf0f subscript \\ud835\\udc3f 0 p(\\\\tau|L_{0}) italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , indicating the magnitude and evolution that the external force n f subscript \\ud835\\udc5b \\ud835\\udc53 n_{f} italic_n start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT impacts on the current control decisions. Please see Appendix E.4 for further discussion on Figure 7 . Practically, this probabilistic interpretation represents significant progress in addressing a longstanding and challenging question: why do machine systems powered by Artificial Intelligence (AI) technologies make certain decisions, and what are the exact latent factors influencing those decisions? Such progress holds particular value for safety-critical industries like self-driving vehicles, aerospace engineering and high-frequency trading in financial services, particularly in cases where AI-based approaches exhibit erratic performance and thorough analysis is necessary. 7 Limitation The primary limitation we encounter is ensuring the trustworthiness of the posterior probability generated by the critic network, which operates as a Bayesian network. Our ongoing efforts involve applying statistical methods to establish a specific confidence interval for the Bayesian network\\u2019s outcomes. Additionally, we intend to study AWaVO\\u2019s suitability for more real-world safety-critical applications. For scalability, please refer to Appendix E.5 . This may serve as a starting point from which to formally analyze AWaVO\\u2019s scalability and how the approach could extend to larger and more complex real-world domains. Another limitation is the lack of human-centered validation (although this would need to be taken on an ad hoc basis per deployment context), and considering policy or regulatory issues. 8 Conclusion Enthusiasm towards the possible applications of constrained RL is growing worldwide. The insufficient ability to interpret agent actions and policy optimizations, however, poses a significant hurdle in deploying RL in safety-critical domains like advanced manufacturing and financial trading. Our primary motivation in introducing AWaVO, an intrinsically interpretable RL framework, is to tackle key challenges concerning convergence guarantees, optimization transparency, and sequential-decision interpretation. Empirical results demonstrate that the proposed AWaVO balances a reasonable trade-off between high performance and quantitative interpretability in both simulation and real quadrotor tasks. Acknowledgments This work was partially supported by NSF-UKRI [grant number NE/T011467/1]; and the Engineering and Physical Sciences Research Council [grant number EP/X040518/1]. Impact Statement This paper presents work whose goal is to advance knowledge about interpretability and reproducibility in the RL community. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. Additionally, we provide the video and additional demonstration to the real-world quadrotor experiments. References Achiam et al. (2017) Achiam, J., Held, D., Tamar, A., and Abbeel, P. Constrained policy optimization. In International conference on machine learning , pp. 22\\u201331. PMLR, 2017. Altman (1999) Altman, E. Constrained Markov decision processes: stochastic modeling . Routledge, 1999. Altschuler et al. (2017) Altschuler, J., Niles-Weed, J., and Rigollet, P. Near-linear time approximation algorithms for optimal transport via sinkhorn iteration. Advances in neural information processing systems , 30, 2017. Bahouri et al. (2011) Bahouri, H., Chemin, J.-Y., and Danchin, R. Fourier analysis and nonlinear partial differential equations , volume 343. Springer, 2011. Bellemare et al. (2017) Bellemare, M. G., Dabney, W., and Munos, R. A distributional perspective on reinforcement learning. In International Conference on Machine Learning , pp. 449\\u2013458. PMLR, 2017. Beylkin (1984) Beylkin, G. The inversion problem and applications of the generalized radon transform. Communications on pure and applied mathematics , 37(5):579\\u2013599, 1984. Bohez et al. (2019) Bohez, S., Abdolmaleki, A., Neunert, M., Buchli, J., Heess, N., and Hadsell, R. Value constrained model-free continuous control. arXiv preprint arXiv:1902.04623 , 2019. Bonneel et al. (2015) Bonneel, N., Rabin, J., Peyr\\u00e9, G., and Pfister, H. Sliced and radon wasserstein barycenters of measures. Journal of Mathematical Imaging and Vision , 51:22\\u201345, 2015. Bonnotte (2013) Bonnotte, N. Unidimensional and evolution methods for optimal transportation . PhD thesis, Universit\\u00e9 Paris Sud-Paris XI; Scuola normale superiore (Pise, Italie), 2013. Brat (2021) Brat, G. Are we ready for the first easa guidance on the use of ml in aviation? In SAE G34 Meeting , 2021. Brockman et al. (2016) Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., and Zaremba, W. Openai gym. arXiv preprint arXiv:1606.01540 , 2016. Cai et al. (2019) Cai, Q., Yang, Z., Lee, J. D., and Wang, Z. Neural temporal-difference and q-learning provably converge to global optima. arXiv preprint arXiv:1905.10027 , 2019. Chen et al. (2021) Chen, X., Yang, Y., and Li, Y. Augmented sliced wasserstein distances. In International Conference on Learning Representations , 2021. Chua et al. (2018) Chua, K., Calandra, R., McAllister, R., and Levine, S. Deep reinforcement learning in a handful of trials using probabilistic dynamics models. Advances in neural information processing systems , 31, 2018. Clement & Desch (2008) Clement, P. and Desch, W. An elementary proof of the triangle inequality for the wasserstein metric. Proceedings of the American Mathematical Society , 136(1):333\\u2013339, 2008. Cuturi (2013) Cuturi, M. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information processing systems , 26, 2013. Dabney et al. (2018) Dabney, W., Rowland, M., Bellemare, M., and Munos, R. Distributional reinforcement learning with quantile regression. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 32, 2018. Deshpande et al. (2019) Deshpande, I., Hu, Y.-T., Sun, R., Pyrros, A., Siddiqui, N., Koyejo, S., Zhao, Z., Forsyth, D., and Schwing, A. G. Max-sliced wasserstein distance and its use for gans. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10648\\u201310656, 2019. Devidze et al. (2021) Devidze, R., Radanovic, G., Kamalaruban, P., and Singla, A. Explicable reward design for reinforcement learning agents. Advances in Neural Information Processing Systems , 34:20118\\u201320131, 2021. Ding et al. (2021) Ding, Z., Yang, T., Zhang, K., Xu, C., and Gao, F. Vid-fusion: Robust visual-inertial-dynamics odometry for accurate external force estimation. In 2021 IEEE International Conference on Robotics and Automation (ICRA) , pp. 14469\\u201314475. IEEE, 2021. Ehrenpreis (2003) Ehrenpreis, L. The universality of the Radon transform . OUP Oxford, 2003. Fern\\u00e1ndez Llorca & G\\u00f3mez (2021) Fern\\u00e1ndez Llorca, D. and G\\u00f3mez, E. Trustworthy autonomous vehicles. Publications Office of the European Union, Luxembourg,, EUR , 30942, 2021. Fernandez-Llorca & G\\u00f3mez (2023) Fernandez-Llorca, D. and G\\u00f3mez, E. Trustworthy artificial intelligence requirements in the autonomous driving domain. Computer , 56(2):29\\u201339, 2023. Gannoun et al. (2007) Gannoun, A., Saracco, J., and Yu, K. Comparison of kernel estimators of conditional distribution function and quantile regression under censoring. Statistical Modelling , 7(4):329\\u2013344, 2007. Gorbach et al. (2017) Gorbach, N. S., Bauer, S., and Buhmann, J. M. Scalable variational inference for dynamical systems. Advances in neural information processing systems , 30, 2017. Homan & Zhou (2017) Homan, A. and Zhou, H. Injectivity and stability for a generic class of generalized radon transforms. The Journal of Geometric Analysis , 27:1515\\u20131529, 2017. Kakade & Langford (2002) Kakade, S. and Langford, J. Approximately optimal approximate reinforcement learning. In In Proc. 19th International Conference on Machine Learning . Citeseer, 2002. Kappen et al. (2012) Kappen, H. J., G\\u00f3mez, V., and Opper, M. Optimal control as a graphical model inference problem. Machine learning , 87:159\\u2013182, 2012. Kenny et al. (2021) Kenny, E. M., Ford, C., Quinn, M., and Keane, M. T. Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in xai user studies. Artificial Intelligence , 294:103459, 2021. Kenny et al. (2022) Kenny, E. M., Tucker, M., and Shah, J. Towards interpretable deep reinforcement learning with human-friendly prototypes. In The Eleventh International Conference on Learning Representations , 2022. Koenker (2005) Koenker, R. Quantile regression , volume 38. Cambridge university press, 2005. Koller & Friedman (2009) Koller, D. and Friedman, N. Probabilistic graphical models: principles and techniques . MIT press, 2009. Kolouri et al. (2017) Kolouri, S., Park, S. R., Thorpe, M., Slepcev, D., and Rohde, G. K. Optimal mass transport: Signal processing and machine-learning applications. IEEE signal processing magazine , 34(4):43\\u201359, 2017. Kolouri et al. (2019) Kolouri, S., Nadjahi, K., Simsekli, U., Badeau, R., and Rohde, G. Generalized sliced wasserstein distances. Advances in neural information processing systems , 32, 2019. Kullback & Leibler (1951) Kullback, S. and Leibler, R. A. On information and sufficiency. The annals of mathematical statistics , 22(1):79\\u201386, 1951. Levine (2018) Levine, S. Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv preprint arXiv:1805.00909 , 2018. Levine (2022) Levine, S. Understanding the world through action. In Conference on Robot Learning , pp. 1752\\u20131757. PMLR, 2022. Lipton (2018) Lipton, Z. C. The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Queue , 16(3):31\\u201357, 2018. Liu et al. (2020) Liu, Y., Ding, J., and Liu, X. Ipo: Interior-point policy optimization under constraints. In Proceedings of the AAAI conference on artificial intelligence , volume 34, pp. 4940\\u20134947, 2020. Liu et al. (2022) Liu, Z., Cen, Z., Isenbaev, V., Liu, W., Wu, S., Li, B., and Zhao, D. Constrained variational policy optimization for safe reinforcement learning. In International Conference on Machine Learning , pp. 13644\\u201313668. PMLR, 2022. Lorenz & Emanuel (1998) Lorenz, E. N. and Emanuel, K. A. Optimal sites for supplementary weather observations: Simulation with a small model. Journal of the Atmospheric Sciences , 55(3):399\\u2013414, 1998. McNamara (2016) McNamara, S. The law and ethics of high-frequency trading. Minn. JL Sci. & Tech. , 17:71, 2016. Mitrophanov (2005) Mitrophanov, A. Y. Sensitivity and convergence of uniformly ergodic markov chains. Journal of Applied Probability , 42(4):1003\\u20131014, 2005. Nadjahi et al. (2020) Nadjahi, K., Durmus, A., Chizat, L., Kolouri, S., Shahrampour, S., and Simsekli, U. Statistical and topological properties of sliced probability divergences. Advances in Neural Information Processing Systems , 33:20802\\u201320812, 2020. Napoleone et al. (2020) Napoleone, A., Macchi, M., and Pozzetti, A. A review on the characteristics of cyber-physical systems for the future smart factories. Journal of manufacturing systems , 54:305\\u2013335, 2020. Ng (2005) Ng, R. Fourier slice photography. In ACM Siggraph 2005 Papers , pp. 735\\u2013744. 2005. Nietert et al. (2022) Nietert, S., Goldfeld, Z., Sadhu, R., and Kato, K. Statistical, robustness, and computational guarantees for sliced wasserstein distances. Advances in Neural Information Processing Systems , 35:28179\\u201328193, 2022. O\\u2019Donoghue et al. (2020) O\\u2019Donoghue, B., Osband, I., and Ionescu, C. Making sense of reinforcement learning and probabilistic inference. arXiv preprint arXiv:2001.00805 , 2020. Okada & Taniguchi (2018) Okada, M. and Taniguchi, T. Acceleration of gradient-based path integral method for efficient optimal and inverse optimal control. In 2018 IEEE International Conference on Robotics and Automation (ICRA) , pp. 3013\\u20133020. IEEE, 2018. Okada & Taniguchi (2020) Okada, M. and Taniguchi, T. Variational inference mpc for bayesian model-based reinforcement learning. In Conference on robot learning , pp. 258\\u2013272. PMLR, 2020. Peyr\\u00e9 et al. (2017) Peyr\\u00e9, G., Cuturi, M., et al. Computational optimal transport. Center for Research in Economics and Statistics Working Papers , (2017-86), 2017. Rabin et al. (2012) Rabin, J., Peyr\\u00e9, G., Delon, J., and Bernot, M. Wasserstein barycenter and its application to texture mixing. In Scale Space and Variational Methods in Computer Vision: Third International Conference, SSVM 2011, Ein-Gedi, Israel, May 29\\u2013June 2, 2011, Revised Selected Papers 3 , pp. 435\\u2013446. Springer, 2012. Radon (2005) Radon, J. 1.1 \\u00fcber die bestimmung von funktionen durch ihre integralwerte l\\u00e4ngs gewisser mannigfaltigkeiten. Classic papers in modern diagnostic radiology , 5(21):124, 2005. Rahimi & Recht (2008) Rahimi, A. and Recht, B. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. Advances in neural information processing systems , 21, 2008. Rudin (2019) Rudin, C. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature machine intelligence , 1(5):206\\u2013215, 2019. Schmitz et al. (2018) Schmitz, M. A., Heitz, M., Bonneel, N., Ngole, F., Coeurjolly, D., Cuturi, M., Peyr\\u00e9, G., and Starck, J.-L. Wasserstein dictionary learning: Optimal transport-based unsupervised nonlinear dictionary learning. SIAM Journal on Imaging Sciences , 11(1):643\\u2013678, 2018. Slack et al. (2020) Slack, D., Hilgard, S., Jia, E., Singh, S., and Lakkaraju, H. Fooling lime and shap: Adversarial attacks on post hoc explanation methods. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society , pp. 180\\u2013186, 2020. Solomon et al. (2014) Solomon, J., Rustamov, R., Guibas, L., and Butscher, A. Wasserstein propagation for semi-supervised learning. In International Conference on Machine Learning , pp. 306\\u2013314. PMLR, 2014. Torens et al. (2022) Torens, C., Durak, U., and Dauer, J. C. Guidelines and regulatory framework for machine learning in aviation. In AIAA Scitech 2022 Forum , pp. 1132, 2022. Toussaint & Storkey (2006) Toussaint, M. and Storkey, A. Probabilistic inference for solving discrete and continuous state markov decision processes. In Proceedings of the 23rd international conference on Machine learning , pp. 945\\u2013952, 2006. Villani (2009) Villani, C. The wasserstein distances. In Optimal transport , pp. 93\\u2013111. Springer, 2009. Villani et al. (2009) Villani, C. et al. Optimal transport: old and new , volume 338. Springer, 2009. Wang & Boyle (2023) Wang, Y. and Boyle, D. Trustworthy reinforcement learning for quadrotor uav tracking control systems. arXiv preprint arXiv:2302.11694 , 2023. Wang et al. (2023) Wang, Y., O\\u2019Keeffe, J., Qian, Q., and Boyle, D. Quadue-ccm: Interpretable distributional reinforcement learning using uncertain contraction metrics for precise quadrotor trajectory tracking. In Conference on Robot Learning , pp. 2306\\u20132316. PMLR, 2023. Welch et al. (1995) Welch, G., Bishop, G., et al. An introduction to the kalman filter. 1995. Xu et al. (2021) Xu, T., Liang, Y., and Lan, G. Crpo: A new approach for safe reinforcement learning with convergence guarantee. In International Conference on Machine Learning , pp. 11480\\u201311491. PMLR, 2021. Yang et al. (2020) Yang, T. Y., Rosca, J., Narasimhan, K., and Ramadge, P. J. Projection-based constrained policy optimization. In 8th International Conference on Learning Representations, ICLR 2020 , 2020. Zhao et al. (2023) Zhao, W., Chen, R., Sun, Y., Liu, R., Wei, T., and Liu, C. Guard: A safe reinforcement learning benchmark. arXiv preprint arXiv:2305.13681 , 2023. Zhou et al. (2022) Zhou, Y., Booth, S., Ribeiro, M. T., and Shah, J. Do feature attribution methods correctly attribute features? In Proceedings of the AAAI Conference on Artificial Intelligence , volume 36, pp. 9623\\u20139633, 2022. Appendix Appendix A Notation Table Table 1: Main Notation Conventions Parameters Definition \\ud835\\udc94 t subscript \\ud835\\udc94 \\ud835\\udc61 \\\\bm{s}_{t} bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT A state \\ud835\\udc94 \\ud835\\udc94 \\\\bm{s} bold_italic_s sampled at a discrete timestamp t \\ud835\\udc61 t italic_t . \\ud835\\udc82 t subscript \\ud835\\udc82 \\ud835\\udc61 \\\\bm{a}_{t} bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT An action \\ud835\\udc82 \\ud835\\udc82 \\\\bm{a} bold_italic_a sampled at a discrete timestamp t \\ud835\\udc61 t italic_t . \\\\hdashline \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 A trajectory. D \\ud835\\udc37 D italic_D Observed training dataset. \\\\hdashline S \\ud835\\udc46 S italic_S A finite set of states { \\ud835\\udc94 } \\ud835\\udc94 {\\\\{\\\\bm{s}\\\\}} { bold_italic_s } . A \\ud835\\udc34 A italic_A A finite set of actions { \\ud835\\udc82 } \\ud835\\udc82 {\\\\{\\\\bm{a}\\\\}} { bold_italic_a } . P \\ud835\\udc43 P italic_P A finite set of transition probabilities { p } \\ud835\\udc5d {\\\\{p\\\\}} { italic_p } . R \\ud835\\udc45 R italic_R A finite set of bounded immediate rewards { r } \\ud835\\udc5f {\\\\{r\\\\}} { italic_r } . G \\ud835\\udc3a G italic_G A finite collection of unity functions { g } \\ud835\\udc54 {\\\\{g\\\\}} { italic_g } . \\\\hdashline \\ud835\\udcaa t = { \\ud835\\udcaa r , t , \\ud835\\udcaa g i , t } subscript \\ud835\\udcaa \\ud835\\udc61 subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udc61 subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udc61 \\\\mathcal{O}_{t}=\\\\{\\\\mathcal{O}_{r,t},\\\\mathcal{O}_{g_{i},t}\\\\} caligraphic_O start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = { caligraphic_O start_POSTSUBSCRIPT italic_r , italic_t end_POSTSUBSCRIPT , caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t end_POSTSUBSCRIPT } Binary variables of the optimality. \\ud835\\udcaa r , t = 1 subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udc61 1 \\\\mathcal{O}_{r,t}=1 caligraphic_O start_POSTSUBSCRIPT italic_r , italic_t end_POSTSUBSCRIPT = 1 and \\ud835\\udcaa g i , t = 1 subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udc61 1 \\\\mathcal{O}_{g_{i},t}=1 caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t end_POSTSUBSCRIPT = 1 signify that the trajectory \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 is optimized and compliant with the constraints. \\\\hdashline p D \\u2062 ( \\u03b8 ) subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 p_{D}(\\\\theta) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) The posterior probability p \\u2062 ( \\u03b8 | D ) \\ud835\\udc5d conditional \\ud835\\udf03 \\ud835\\udc37 p(\\\\theta|D) italic_p ( italic_\\u03b8 | italic_D ) . p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) The optimality likelihood. \\\\hdashline r ~ \\u2062 ( \\u03c4 ) ~ \\ud835\\udc5f \\ud835\\udf0f \\\\widetilde{r}(\\\\tau) over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) The accumulated reward r ~ \\u2062 ( \\u03c4 ) = \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 T \\u2212 1 \\u03b3 t \\u2062 r \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) ] ~ \\ud835\\udc5f \\ud835\\udf0f \\ud835\\udd3c delimited-[] superscript subscript \\ud835\\udc61 0 \\ud835\\udc47 1 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\\\widetilde{r}(\\\\tau)={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{T-1}\\\\gamma^{t}}r(\\\\bm{s}_{% t},\\\\bm{a}_{t})] over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) = blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] . g ~ i \\u2062 ( \\u03c4 ) subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\widetilde{g}_{i}(\\\\tau) over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) The utility function g ~ i \\u2062 ( \\u03c4 ) = \\ud835\\udd3c \\u2062 [ \\u2211 t = 0 T \\u2212 1 \\u03b3 t \\u2062 g i \\u2062 ( \\ud835\\udc94 t , \\ud835\\udc82 t ) ] subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\ud835\\udd3c delimited-[] superscript subscript \\ud835\\udc61 0 \\ud835\\udc47 1 superscript \\ud835\\udefe \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udc56 subscript \\ud835\\udc94 \\ud835\\udc61 subscript \\ud835\\udc82 \\ud835\\udc61 \\\\widetilde{g}_{i}(\\\\tau)={\\\\mathbb{E}}[{\\\\sum\\\\limits_{t=0}^{T-1}\\\\gamma^{t}}g_{i}(% \\\\bm{s}_{t},\\\\bm{a}_{t})] over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) = blackboard_E [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] . \\\\hdashline \\u2131 = { \\u2131 r , \\u2131 g } \\u2131 subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}=\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\} caligraphic_F = { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } \\u2131 r subscript \\u2131 \\ud835\\udc5f \\\\mathcal{F}_{r} caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and \\u2131 g subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}_{g} caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT are the operators, with specifically defined as \\u2131 r \\u22c5 \\\\mathcal{F}_{r}\\\\cdot caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f p(\\\\mathcal{O}_{r}|\\\\tau) italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) := r ~ \\u2062 ( \\u03c4 ) assign absent ~ \\ud835\\udc5f \\ud835\\udf0f :=\\\\widetilde{r}(\\\\tau) := over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) and \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) := g ~ i \\u2062 ( \\u03c4 ) assign \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\mathcal{F}_{g}\\\\cdot p(\\\\mathcal{O}_{g_{i}}|\\\\tau):=\\\\widetilde{g}_{i}(\\\\tau) caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) := over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) . \\\\hdashline b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT A fixed limit for the i \\ud835\\udc56 i italic_i -th constraint. \\ud835\\udf49 c subscript \\ud835\\udf49 \\ud835\\udc50 \\\\bm{\\\\tau}_{c} bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT The tolerance. \\\\hdashline l \\ud835\\udc59 l italic_l A curve on the hypersurface in the spatial Radon transform. \\u03b8 ~ ~ \\ud835\\udf03 \\\\widetilde{\\\\theta} over~ start_ARG italic_\\u03b8 end_ARG An unit vector tangent to l \\ud835\\udc59 l italic_l . Both l \\ud835\\udc59 l italic_l and \\u03b8 ~ ~ \\ud835\\udf03 \\\\widetilde{\\\\theta} over~ start_ARG italic_\\u03b8 end_ARG represent the parameters of hypersurfaces. \\\\hdashline q \\u03b8 \\u2062 ( \\u03c4 ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f q_{\\\\theta}(\\\\tau) italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) A variational distribution. q \\u2062 ( \\ud835\\udc82 ) \\ud835\\udc5e \\ud835\\udc82 q(\\\\bm{a}) italic_q ( bold_italic_a ) An approximation of p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) . Appendix B Background on Wasserstein Distance B.1 Sliced Wasserstein Distance A fundamental challenge in both machine learning and statistics communities is to form effective metrics between pairs of probability distributions. Weaker notions, such as divergence measures, including KL divergence (Kullback & Leibler, 1951 ) , have been proposed and widely used. However, such measures do not satisfy the two basic properties of a metric, namely symmetry and triangle inequality. To address this issue, interest has rapidly increased in optimal transport in recent years. In this subsection, we introduce the Wasserstein distance and its variants, including SWD (Rabin et al., 2012 ; Nietert et al., 2022 ) and GSWD (Kolouri et al., 2019 ) , as metrics that conditionally satisfy the properties. Let \\u0393 \\u2062 ( \\u03bc , \\u03bd ) \\u0393 \\ud835\\udf07 \\ud835\\udf08 \\\\Gamma(\\\\mu,\\\\nu) roman_\\u0393 ( italic_\\u03bc , italic_\\u03bd ) be a set of all transportation plans \\u03b3 \\u2208 \\u0393 \\u2062 ( \\u03bc , \\u03bd ) \\ud835\\udefe \\u0393 \\ud835\\udf07 \\ud835\\udf08 \\\\gamma\\\\in\\\\Gamma(\\\\mu,\\\\nu) italic_\\u03b3 \\u2208 roman_\\u0393 ( italic_\\u03bc , italic_\\u03bd ) , where \\u03b3 \\ud835\\udefe \\\\gamma italic_\\u03b3 is a joint distribution over the space \\ud835\\udcb3 \\u00d7 \\ud835\\udcb3 \\ud835\\udcb3 \\ud835\\udcb3 \\\\mathcal{X}\\\\times\\\\mathcal{X} caligraphic_X \\u00d7 caligraphic_X , and \\u03bc , \\u03bd \\u2208 P k \\u2062 ( \\ud835\\udcb3 ) \\ud835\\udf07 \\ud835\\udf08 subscript \\ud835\\udc43 \\ud835\\udc58 \\ud835\\udcb3 \\\\mu,\\\\nu\\\\in P_{k}(\\\\mathcal{X}) italic_\\u03bc , italic_\\u03bd \\u2208 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_X ) are two measures of probability distributions over \\ud835\\udcb3 \\ud835\\udcb3 \\\\mathcal{X} caligraphic_X . P k \\u2062 ( \\ud835\\udcb3 ) subscript \\ud835\\udc43 \\ud835\\udc58 \\ud835\\udcb3 P_{k}(\\\\mathcal{X}) italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_X ) represents a set of Borel probability measures with finite k \\ud835\\udc58 k italic_k -th moment on a Polish metric space (Villani et al., 2009 ) . d \\u2062 ( x , y ) \\ud835\\udc51 \\ud835\\udc65 \\ud835\\udc66 d(x,y) italic_d ( italic_x , italic_y ) represents a distance function over \\ud835\\udcb3 \\ud835\\udcb3 \\\\mathcal{X} caligraphic_X . The Wasserstein distance of order k \\u2208 [ 1 , \\u221e ) \\ud835\\udc58 1 k\\\\in[1,\\\\infty) italic_k \\u2208 [ 1 , \\u221e ) between two measures \\u03bc , \\u03bd \\ud835\\udf07 \\ud835\\udf08 \\\\mu,\\\\nu italic_\\u03bc , italic_\\u03bd is defined as (Villani et al., 2009 ) : W k \\u2062 ( \\u03bc , \\u03bd ) = ( inf \\u03b3 \\u2208 \\u0393 \\u2062 ( P , Q ) \\u222b \\ud835\\udcb3 \\u00d7 \\ud835\\udcb3 d \\u2062 ( x , y ) k \\u2062 d \\u03b3 \\u2062 ( x , y ) ) 1 / k subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf08 superscript subscript infimum \\ud835\\udefe \\u0393 \\ud835\\udc43 \\ud835\\udc44 subscript \\ud835\\udcb3 \\ud835\\udcb3 \\ud835\\udc51 superscript \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udc58 differential-d \\ud835\\udefe \\ud835\\udc65 \\ud835\\udc66 1 \\ud835\\udc58 W_{k}(\\\\mu,\\\\nu)=\\\\left(\\\\inf_{\\\\gamma\\\\in\\\\Gamma(P,Q)}\\\\int_{\\\\mathcal{X}\\\\times% \\\\mathcal{X}}d(x,y)^{k}\\\\mathrm{d}\\\\gamma(x,y)\\\\right)^{1/k} italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bd ) = ( roman_inf start_POSTSUBSCRIPT italic_\\u03b3 \\u2208 roman_\\u0393 ( italic_P , italic_Q ) end_POSTSUBSCRIPT \\u222b start_POSTSUBSCRIPT caligraphic_X \\u00d7 caligraphic_X end_POSTSUBSCRIPT italic_d ( italic_x , italic_y ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT roman_d italic_\\u03b3 ( italic_x , italic_y ) ) start_POSTSUPERSCRIPT 1 / italic_k end_POSTSUPERSCRIPT . This definition, however, involves solving an optimization problem that is computationally expensive in practical implementation, particularly for high-dimensional distributions. Thus sliced k \\ud835\\udc58 k italic_k -Wasserstein distance (Rabin et al., 2012 ; Nietert et al., 2022 ) , defined over spaces of hyperplanes in \\u211d d superscript \\u211d \\ud835\\udc51 \\\\mathbb{R}^{d} blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT , is proposed as a computationally efficient approximation: \\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bd ) = ( \\u222b \\ud835\\udd4a d \\u2212 1 W k k \\u2062 ( \\u211b \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\u211b \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k subscript \\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf08 superscript subscript superscript \\ud835\\udd4a \\ud835\\udc51 1 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\u211b \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 subscript \\u211b \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 {\\\\bf{SWD}}_{k}(\\\\mu,\\\\nu)=\\\\left(\\\\int_{\\\\mathbb{S}^{d-1}}W_{k}^{k}\\\\left(\\\\mathcal{R% }_{\\\\mu}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right),\\\\mathcal{R}_{\\\\nu}\\\\left(\\\\cdot,% \\\\widetilde{\\\\theta}\\\\right)\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{% k}} bold_SWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bd ) = ( \\u222b start_POSTSUBSCRIPT blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_R start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_R start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT (3) where Radon transform \\u211b \\u211b \\\\mathcal{R} caligraphic_R (Radon, 2005 ) is introduced in SWD to map a function f \\u2062 ( \\u22c5 ) \\ud835\\udc53 \\u22c5 f(\\\\cdot) italic_f ( \\u22c5 ) to the hyperplanes { x \\u2208 \\u211d d | \\u27e8 x , \\u03b8 ~ \\u27e9 = l } conditional-set \\ud835\\udc65 superscript \\u211d \\ud835\\udc51 \\ud835\\udc65 ~ \\ud835\\udf03 \\ud835\\udc59 \\\\left\\\\{x\\\\in\\\\mathbb{R}^{d}|\\\\langle x,\\\\widetilde{\\\\theta}\\\\rangle=l\\\\right\\\\} { italic_x \\u2208 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT | \\u27e8 italic_x , over~ start_ARG italic_\\u03b8 end_ARG \\u27e9 = italic_l } , i.e., \\u211b \\u2062 f \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\u211d d f \\u2062 ( x ) \\u2062 \\u03b4 \\u2062 ( l \\u2212 \\u27e8 x , \\u03b8 ~ \\u27e9 ) \\u2062 d x \\u211b \\ud835\\udc53 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\u211d \\ud835\\udc51 \\ud835\\udc53 \\ud835\\udc65 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udc65 \\\\mathcal{R}f(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{R}^{d}}f(x)\\\\delta(l-\\\\langle x% ,\\\\widetilde{\\\\theta}\\\\rangle)\\\\mathrm{d}x caligraphic_R italic_f ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_f ( italic_x ) italic_\\u03b4 ( italic_l - \\u27e8 italic_x , over~ start_ARG italic_\\u03b8 end_ARG \\u27e9 ) roman_d italic_x : l \\u2208 \\u211d \\ud835\\udc59 \\u211d l\\\\in\\\\mathbb{R} italic_l \\u2208 blackboard_R and \\u03b8 ~ \\u2208 \\ud835\\udd4a d \\u2212 1 \\u2282 \\u211d d ~ \\ud835\\udf03 superscript \\ud835\\udd4a \\ud835\\udc51 1 superscript \\u211d \\ud835\\udc51 \\\\widetilde{\\\\theta}\\\\in\\\\mathbb{S}^{d-1}\\\\subset\\\\mathbb{R}^{d} over~ start_ARG italic_\\u03b8 end_ARG \\u2208 blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT \\u2282 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT represent the parameters of these hyperplanes. In the definition of SWD, the Radon transform \\u211b \\u03bc subscript \\u211b \\ud835\\udf07 \\\\mathcal{R}_{\\\\mu} caligraphic_R start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT is employed as the push-forward operators, defined by \\u211b \\u03bc \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\u211d d \\u03b4 \\u2062 ( l \\u2212 \\u27e8 x , \\u03b8 ~ \\u27e9 ) \\u2062 d \\u03bc subscript \\u211b \\ud835\\udf07 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\u211d \\ud835\\udc51 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udf07 \\\\mathcal{R}_{\\\\mu}(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{R}^{d}}\\\\delta(l-\\\\langle x% ,\\\\widetilde{\\\\theta}\\\\rangle)\\\\mathrm{d}\\\\mu caligraphic_R start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03b4 ( italic_l - \\u27e8 italic_x , over~ start_ARG italic_\\u03b8 end_ARG \\u27e9 ) roman_d italic_\\u03bc (Kolouri et al., 2019 ) . B.2 Generalized Sliced Wasserstein Distance While SWD offers a computationally efficient way to approximate the Wasserstein distance, the projections are limited to linear subspaces, such as hyperplanes { x } \\ud835\\udc65 \\\\left\\\\{x\\\\right\\\\} { italic_x } . Due to the nature of these linear projections, the resulting metrics typically have low projection efficiency in high-dimensional spaces (Kolouri et al., 2019 ; Deshpande et al., 2019 ) . Thus various variants of SWD are proposed to enhance its projection effectiveness. Specifically, the GSWD (Kolouri et al., 2019 ) , defined in Equation 4 , is proposed by incorporating nonlinear projections. Its main novelty is that Generalized Radon Transforms (GRTs) \\ud835\\udca2 \\ud835\\udca2 \\\\mathcal{G} caligraphic_G (Beylkin, 1984 ; Ehrenpreis, 2003 ; Homan & Zhou, 2017 ) , i.e., \\ud835\\udca2 \\u2062 f \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\u211d d f \\u2062 ( x ) \\u2062 \\u03b4 \\u2062 ( l \\u2212 \\u03b2 \\u2062 ( x , \\u03b8 ~ ) ) \\u2062 d x \\ud835\\udca2 \\ud835\\udc53 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\u211d \\ud835\\udc51 \\ud835\\udc53 \\ud835\\udc65 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udefd \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udc65 \\\\mathcal{G}f(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{R}^{d}}f(x)\\\\delta(l-\\\\beta(x,% \\\\widetilde{\\\\theta}))\\\\mathrm{d}x caligraphic_G italic_f ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_f ( italic_x ) italic_\\u03b4 ( italic_l - italic_\\u03b2 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d italic_x , are used to define the nonlinear projections towards hypersurfaces rather than linear projections to the hyperplanes in SWD. Let \\u03b2 \\u2062 ( x , \\u03b8 ~ ) \\ud835\\udefd \\ud835\\udc65 ~ \\ud835\\udf03 \\\\beta(x,\\\\widetilde{\\\\theta}) italic_\\u03b2 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) be a defining function when satisfying the conditions H.1-H.4 in (Kolouri et al., 2019 ) . \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bd ) = ( \\u222b \\ud835\\udcb3 \\u03b8 ~ W k k \\u2062 ( \\ud835\\udca2 \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udca2 \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf08 superscript subscript subscript \\ud835\\udcb3 ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udca2 \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udca2 \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 {\\\\bf{GSWD}}_{k}(\\\\mu,\\\\nu)=\\\\left(\\\\int_{\\\\mathcal{X}_{\\\\widetilde{\\\\theta}}}W_{k}^{k% }\\\\left(\\\\mathcal{G}_{\\\\mu}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right),\\\\mathcal{G}_{\\\\nu% }\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right)\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}% \\\\right)^{\\\\frac{1}{k}} bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bd ) = ( \\u222b start_POSTSUBSCRIPT caligraphic_X start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_G start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_G start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT (4) where \\u03b8 ~ \\u2208 \\ud835\\udcb3 \\u03b8 ~ ~ \\ud835\\udf03 subscript \\ud835\\udcb3 ~ \\ud835\\udf03 \\\\widetilde{\\\\theta}\\\\in\\\\mathcal{X}_{\\\\widetilde{\\\\theta}} over~ start_ARG italic_\\u03b8 end_ARG \\u2208 caligraphic_X start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT and \\ud835\\udcb3 \\u03b8 ~ subscript \\ud835\\udcb3 ~ \\ud835\\udf03 \\\\mathcal{X}_{\\\\widetilde{\\\\theta}} caligraphic_X start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT is a compact set of all feasible parameters \\u03b8 ~ ~ \\ud835\\udf03 \\\\widetilde{\\\\theta} over~ start_ARG italic_\\u03b8 end_ARG for \\u03b2 \\u2062 ( \\u22c5 , \\u03b8 ~ ) \\ud835\\udefd \\u22c5 ~ \\ud835\\udf03 \\\\beta(\\\\cdot,\\\\widetilde{\\\\theta}) italic_\\u03b2 ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , e.g., \\ud835\\udcb3 \\u03b8 ~ = \\ud835\\udd4a d \\u2212 1 subscript \\ud835\\udcb3 ~ \\ud835\\udf03 superscript \\ud835\\udd4a \\ud835\\udc51 1 \\\\mathcal{X}_{\\\\widetilde{\\\\theta}}=\\\\mathbb{S}^{d-1} caligraphic_X start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT = blackboard_S start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT for \\u03b2 \\u2062 ( \\u22c5 , \\u03b8 ~ ) = \\u27e8 \\u22c5 , \\u03b8 ~ \\u27e9 \\ud835\\udefd \\u22c5 ~ \\ud835\\udf03 \\u22c5 ~ \\ud835\\udf03 \\\\beta(\\\\cdot,\\\\widetilde{\\\\theta})=\\\\langle\\\\cdot,\\\\widetilde{\\\\theta}\\\\rangle italic_\\u03b2 ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u27e8 \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG \\u27e9 . The GRT operator \\ud835\\udca2 \\u03bc subscript \\ud835\\udca2 \\ud835\\udf07 \\\\mathcal{G}_{\\\\mu} caligraphic_G start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT is utilized as the push-forward operator, i.e., \\ud835\\udca2 \\u03bc \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\ud835\\udd3e d \\u03b4 \\u2062 ( l \\u2212 \\u03b2 \\u2062 ( x , \\u03b8 ~ ) ) \\u2062 d \\u03bc subscript \\ud835\\udca2 \\ud835\\udf07 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\ud835\\udd3e \\ud835\\udc51 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udefd \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udf07 \\\\mathcal{G}_{\\\\mu}(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{G}^{d}}\\\\delta(l-\\\\beta(x,% \\\\widetilde{\\\\theta}))\\\\mathrm{d}\\\\mu caligraphic_G start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_G start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03b4 ( italic_l - italic_\\u03b2 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d italic_\\u03bc . For the theoretical properties of a metric, SWD is a true metric that satisfies both symmetry and triangle inequality (Bonnotte, 2013 ) , where the approximation error is obtained and analyzed in (Nadjahi et al., 2020 ) . The GSWD defined by Equation 4 is a true metric if and only if \\u03b2 \\u2062 ( \\u22c5 ) \\ud835\\udefd \\u22c5 \\\\beta(\\\\cdot) italic_\\u03b2 ( \\u22c5 ) in \\ud835\\udca2 \\ud835\\udca2 \\\\mathcal{G} caligraphic_G is an injective mapping (Chen et al., 2021 ) . Appendix C Background on Distributional Representation in Bellman Equation and Temporal Difference Learning C.1 Reasoning behind Distributional Representation The motivation for employing a distributional representation is twofold. Firstly, it provides more comprehensive and richer value-distribution information, thereby enhancing the stability of the learning process. This stability is particularly important for Bayesian learning processes, which often encounter challenges in achieving stable convergence. Secondly, the distributional representation contributes significantly to interpretability. As illustrated in Equation 16 of the proof, it uses quantiles derived from the distributional representation to formally establish the transparency of the convergence process outlined in Theorem 5.5 . C.2 Distributional Representation in Bellman Equation Unlike traditional RL, where the primary objective is to maximize the expected action-value function Q \\ud835\\udc44 Q italic_Q , the distributional Bellman equation (Bellemare et al., 2017 ) was proposed to approximate and parameterize the entire distribution of future rewards. In the setting of policy evaluation, given a deterministic policy \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 , the Bellman operator \\ud835\\udcaf \\u03c0 superscript \\ud835\\udcaf \\ud835\\udf0b \\\\mathcal{T}^{\\\\pi} caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT is defined as (Bellemare et al., 2017 ; Dabney et al., 2018 ) : \\ud835\\udcaf \\u03c0 \\u2062 Z \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2062 := \\ud835\\udc37 \\u2062 R \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + \\u03b3 \\u2062 Z \\u2062 ( S \\u2032 , A \\u2032 ) superscript \\ud835\\udcaf \\ud835\\udf0b \\ud835\\udc4d \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udc37 assign \\ud835\\udc45 \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udefe \\ud835\\udc4d superscript \\ud835\\udc46 \\u2032 superscript \\ud835\\udc34 \\u2032 \\\\mathcal{T}^{\\\\pi}Z(\\\\bm{s},\\\\bm{a})\\\\overset{D}{:=}R(\\\\bm{s},\\\\bm{a})+\\\\gamma Z(S^{% \\\\prime},A^{\\\\prime}) caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z ( bold_italic_s , bold_italic_a ) overitalic_D start_ARG := end_ARG italic_R ( bold_italic_s , bold_italic_a ) + italic_\\u03b3 italic_Z ( italic_S start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT , italic_A start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) (5) where Z \\u03c0 superscript \\ud835\\udc4d \\ud835\\udf0b Z^{\\\\pi} italic_Z start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT denotes the state-action distribution, and R \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\ud835\\udc45 \\ud835\\udc94 \\ud835\\udc82 R(\\\\bm{s},\\\\bm{a}) italic_R ( bold_italic_s , bold_italic_a ) denotes the reward distribution. In control setting, a distributional Bellman optimality operator \\ud835\\udcaf \\ud835\\udcaf \\\\mathcal{T} caligraphic_T with quantile approximation is proposed in (Dabney et al., 2018 ) : \\ud835\\udcaf \\u2062 Z \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2062 := \\ud835\\udc37 \\u2062 R \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + \\u03b3 \\u2062 Z \\u2062 ( \\ud835\\udc94 \\u2032 , arg \\u2062 m \\u2062 a \\u2062 x a \\u2032 \\u2062 \\ud835\\udd3c \\ud835\\udc91 , R \\u2062 [ Z \\u2062 ( \\ud835\\udc94 \\u2032 , \\ud835\\udc82 \\u2032 ) ] ) \\ud835\\udcaf \\ud835\\udc4d \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udc37 assign \\ud835\\udc45 \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udefe \\ud835\\udc4d superscript \\ud835\\udc94 bold-\\u2032 arg superscript \\ud835\\udc4e \\u2032 \\ud835\\udc5a \\ud835\\udc4e \\ud835\\udc65 \\ud835\\udc91 \\ud835\\udc45 \\ud835\\udd3c delimited-[] \\ud835\\udc4d superscript \\ud835\\udc94 bold-\\u2032 superscript \\ud835\\udc82 bold-\\u2032 \\\\mathcal{T}Z(\\\\bm{s},\\\\bm{a})\\\\overset{D}{:=}R(\\\\bm{s},\\\\bm{a})+\\\\gamma Z(\\\\bm{s^{% \\\\prime}},{\\\\rm{arg}}\\\\underset{a^{\\\\prime}}{max}\\\\underset{\\\\bm{p},R}{\\\\mathbb{E}}[Z% (\\\\bm{s^{\\\\prime}},\\\\bm{a^{\\\\prime}})]) caligraphic_T italic_Z ( bold_italic_s , bold_italic_a ) overitalic_D start_ARG := end_ARG italic_R ( bold_italic_s , bold_italic_a ) + italic_\\u03b3 italic_Z ( bold_italic_s start_POSTSUPERSCRIPT bold_\\u2032 end_POSTSUPERSCRIPT , roman_arg start_UNDERACCENT italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT end_UNDERACCENT start_ARG italic_m italic_a italic_x end_ARG start_UNDERACCENT bold_italic_p , italic_R end_UNDERACCENT start_ARG blackboard_E end_ARG [ italic_Z ( bold_italic_s start_POSTSUPERSCRIPT bold_\\u2032 end_POSTSUPERSCRIPT , bold_italic_a start_POSTSUPERSCRIPT bold_\\u2032 end_POSTSUPERSCRIPT ) ] ) (6) where we let Z \\u03b8 := 1 N \\u2062 \\u2211 i = 1 N \\u03b4 q i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) assign subscript \\ud835\\udc4d \\ud835\\udf03 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udeff subscript \\ud835\\udc5e \\ud835\\udc56 \\ud835\\udc94 \\ud835\\udc82 Z_{\\\\theta}:=\\\\frac{1}{N}\\\\sum\\\\limits_{i=1}^{N}\\\\delta_{q_{i}(\\\\bm{s},\\\\bm{a})} italic_Z start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT := divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_\\u03b4 start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) end_POSTSUBSCRIPT be a quantile distribution mapping one state-action pair ( \\ud835\\udc94 , \\ud835\\udc82 ) \\ud835\\udc94 \\ud835\\udc82 (\\\\bm{s},\\\\bm{a}) ( bold_italic_s , bold_italic_a ) to a uniform probability distribution supported on q i subscript \\ud835\\udc5e \\ud835\\udc56 q_{i} italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Based on Equation 5 , a contraction is demonstrated (Dabney et al., 2018 ) over the Wasserstein metric: d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z 1 , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z 2 ) \\u2264 d - \\u221e \\u2062 ( Z 1 , Z 2 ) subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d 1 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d 2 subscript \\ud835\\udc51 subscript \\ud835\\udc4d 1 subscript \\ud835\\udc4d 2 \\\\overset{-}{d}_{\\\\infty}(\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}Z_{1},\\\\Pi_{W_{1}}\\\\mathcal{% T}^{\\\\pi}Z_{2})\\\\leq\\\\overset{-}{d}_{\\\\infty}(Z_{1},Z_{2}) over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) \\u2264 over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , where d - k := sup \\u2062 W k \\u2062 ( Z 1 , Z 2 ) assign subscript \\ud835\\udc51 \\ud835\\udc58 sup subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc4d 1 subscript \\ud835\\udc4d 2 \\\\overset{-}{d}_{k}:={\\\\rm{sup}}W_{k}(Z_{1},Z_{2}) over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT := roman_sup italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) denotes the maximal form of the k \\ud835\\udc58 k italic_k -Wasserstein metrics. W k subscript \\ud835\\udc4a \\ud835\\udc58 W_{k} italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , k \\u2208 [ 1 , \\u221e ] \\ud835\\udc58 1 k\\\\in[1,\\\\infty] italic_k \\u2208 [ 1 , \\u221e ] denotes the k \\ud835\\udc58 k italic_k -Wasserstein distance. \\u03a0 W 1 subscript \\u03a0 subscript \\ud835\\udc4a 1 \\\\Pi_{W_{1}} roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a quantile approximation under the minimal 1-Wasserstein distance W 1 subscript \\ud835\\udc4a 1 W_{1} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . C.3 Distributional Representation in Temporal Difference Learning Building upon the aforementioned contraction guarantees, we utilize distributional TD learning to estimate the distribution of state-action value, denoted as Z \\ud835\\udc4d Z italic_Z . In each iteration, we have the following: \\u03b6 k + 1 i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 1 \\ud835\\udc94 \\ud835\\udc82 \\\\displaystyle\\\\zeta^{i}_{k+1}(\\\\bm{s},\\\\bm{a}) italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) = \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + l t \\u2062 d \\u2062 \\ud835\\udeab k i absent subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 subscript superscript \\ud835\\udeab \\ud835\\udc56 \\ud835\\udc58 \\\\displaystyle=\\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})+l_{td}\\\\bm{\\\\Delta}^{i}_{k} = italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) + italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT bold_\\u0394 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT (7) = \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + l t \\u2062 d \\u00d7 d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 ( h i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) + \\u03b3 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 \\u2032 ) ) , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) ) absent subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\u210e \\ud835\\udc56 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 \\ud835\\udefe subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 superscript \\ud835\\udc94 \\u2032 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 \\\\displaystyle=\\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})+l_{td}\\\\times\\\\overset{-}{d}_{\\\\infty}% (\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}(h_{i}(\\\\bm{s},\\\\bm{a},\\\\bm{s}^{\\\\prime})+\\\\gamma\\\\zeta% ^{i}_{k}(\\\\bm{s}^{\\\\prime})),\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}\\\\zeta^{i}_{k}(\\\\bm{s},% \\\\bm{a})) = italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) + italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT \\u00d7 over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) + italic_\\u03b3 italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ) , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) ) where \\u03b6 k i \\u2208 S \\u00d7 A subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc46 \\ud835\\udc34 \\\\zeta^{i}_{k}\\\\in S\\\\times A italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \\u2208 italic_S \\u00d7 italic_A represents the estimated distribution of the state-action distribution Z \\ud835\\udc4d Z italic_Z in the k \\ud835\\udc58 k italic_k -th TD-learning-iteration for all i = 0 , \\u2026 , p \\ud835\\udc56 0 \\u2026 \\ud835\\udc5d i=0,...,p italic_i = 0 , \\u2026 , italic_p . The TD learning rate is denoted as l t \\u2062 d subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 l_{td} italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT . The function h i : S \\u00d7 A \\u00d7 S \\u2192 \\u211d : subscript \\u210e \\ud835\\udc56 \\u2192 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc46 \\u211d h_{i}:S\\\\times A\\\\times S\\\\rightarrow\\\\mathbb{R} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_S \\u00d7 italic_A \\u00d7 italic_S \\u2192 blackboard_R maps the triple ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 (\\\\bm{s},\\\\bm{a},\\\\bm{s}^{\\\\prime}) ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) to a real number . Specifically, h i subscript \\u210e \\ud835\\udc56 h_{i} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is defined as h i = r subscript \\u210e \\ud835\\udc56 \\ud835\\udc5f h_{i}=r italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_r when i = 0 ; \\ud835\\udc56 0 i=0; italic_i = 0 ; and h i = g i subscript \\u210e \\ud835\\udc56 subscript \\ud835\\udc54 \\ud835\\udc56 h_{i}=g_{i} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT when i \\u2208 [ 1 , n ] \\ud835\\udc56 1 \\ud835\\udc5b i\\\\in[1,n] italic_i \\u2208 [ 1 , italic_n ] . The distributional TD error \\ud835\\udeab k i subscript superscript \\ud835\\udeab \\ud835\\udc56 \\ud835\\udc58 \\\\bm{\\\\Delta}^{i}_{k} bold_\\u0394 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in Equation 10 is calculated by d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 ( h i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) + \\u03b3 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 \\u2032 ) ) , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) ) subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\u210e \\ud835\\udc56 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 \\ud835\\udefe subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 superscript \\ud835\\udc94 \\u2032 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 \\\\overset{-}{d}_{\\\\infty}(\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}(h_{i}(\\\\bm{s},\\\\bm{a},\\\\bm{s% }^{\\\\prime})+\\\\gamma\\\\zeta^{i}_{k}(\\\\bm{s}^{\\\\prime})),\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}% \\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})) over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) + italic_\\u03b3 italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ) , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) ) . In Algorithm 1 , the gradient of actor and critic network, denoted as \\u03b4 \\u03b8 \\u03bc subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udf07 \\\\delta_{\\\\theta^{\\\\mu}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and \\u03b4 \\u03b8 Q subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udc44 \\\\delta_{\\\\theta^{Q}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , can be calculated as follows: \\u03b4 \\u03b8 \\u03bc subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udf07 \\\\displaystyle\\\\delta_{\\\\theta^{\\\\mu}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = ( 1 / N ) \\u2062 \\u2211 \\u2207 \\u03b8 \\u03bc \\u03c0 \\u03b8 \\u03bc \\u2062 ( \\ud835\\udc94 n ) \\u2062 \\ud835\\udd3c \\u2062 [ \\u2207 a Z \\u03b8 Q \\u2062 ( \\ud835\\udc94 n , \\ud835\\udc82 ) ] a = \\u03c0 \\u03b8 \\u03bc \\u2062 ( \\ud835\\udc94 n ) absent 1 \\ud835\\udc41 subscript \\u2207 superscript \\ud835\\udf03 \\ud835\\udf07 subscript \\ud835\\udf0b superscript \\ud835\\udf03 \\ud835\\udf07 subscript \\ud835\\udc94 \\ud835\\udc5b \\ud835\\udd3c subscript delimited-[] subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc4d superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc94 \\ud835\\udc5b \\ud835\\udc82 \\ud835\\udc4e subscript \\ud835\\udf0b superscript \\ud835\\udf03 \\ud835\\udf07 subscript \\ud835\\udc94 \\ud835\\udc5b \\\\displaystyle=(1/N)\\\\sum\\\\limits{\\\\nabla_{\\\\theta^{\\\\mu}}}{\\\\pi_{\\\\theta^{\\\\mu}}}(\\\\bm{% s}_{n})\\\\mathbb{E}[{\\\\nabla_{a}}Z_{\\\\theta^{Q}}(\\\\bm{s}_{n},\\\\bm{a})]_{a=\\\\pi_{% \\\\theta^{\\\\mu}}(\\\\bm{s}_{n})} = ( 1 / italic_N ) \\u2211 \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , bold_italic_a ) ] start_POSTSUBSCRIPT italic_a = italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_\\u03bc end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT (8) \\u03b4 \\u03b8 Q subscript \\ud835\\udeff superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle\\\\delta_{\\\\theta^{Q}} italic_\\u03b4 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = ( 1 / N ) \\u2062 \\u2211 \\u2207 \\u03b8 Q d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z \\u03b8 Q \\u2062 ( \\ud835\\udc94 n , \\ud835\\udc82 n ) , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 g ~ i \\u2062 ( \\u03c4 ) ) absent 1 \\ud835\\udc41 subscript \\u2207 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc94 \\ud835\\udc5b subscript \\ud835\\udc82 \\ud835\\udc5b subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\displaystyle=(1/N)\\\\sum\\\\limits\\\\nabla_{\\\\theta^{Q}}\\\\overset{-}{d}_{\\\\infty}(\\\\Pi_{% W_{1}}\\\\mathcal{T}^{\\\\pi}Z_{\\\\theta^{Q}}(\\\\bm{s}_{n},\\\\bm{a}_{n}),\\\\Pi_{W_{1}}% \\\\mathcal{T}^{\\\\pi}\\\\widetilde{g}_{i}(\\\\tau)) = ( 1 / italic_N ) \\u2211 \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , bold_italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT over~ start_ARG italic_g end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_\\u03c4 ) ) where \\u03a0 W 1 subscript \\u03a0 subscript \\ud835\\udc4a 1 \\\\Pi_{W_{1}} roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT represents a quantile approximation under the minimal 1-Wasserstein distance W 1 subscript \\ud835\\udc4a 1 W_{1} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . Appendix D Algorithm Details and Proofs D.1 Detailed Derivation of the Objective Function The aim of variational inference is to minimize the distance D ( q \\u03b8 ( \\u03c4 ) | | p ( \\u03c4 | \\ud835\\udcaa ) ) = \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k ( q \\u03b8 ( \\u03c4 ) , p ( \\u03c4 | \\ud835\\udcaa ) ) D(q_{\\\\theta}(\\\\tau)||p(\\\\tau|\\\\mathcal{O}))={\\\\bf{A-GSWD}}_{k}(q_{\\\\theta}(\\\\tau),p(% \\\\tau|\\\\mathcal{O})) italic_D ( italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) | | italic_p ( italic_\\u03c4 | caligraphic_O ) ) = bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) , italic_p ( italic_\\u03c4 | caligraphic_O ) ) between the variational distribution q \\u03b8 \\u2062 ( \\u03c4 ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f q_{\\\\theta}(\\\\tau) italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) and the posterior distribution p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) \\ud835\\udc5d conditional \\ud835\\udf0f \\ud835\\udcaa p(\\\\tau|\\\\mathcal{O}) italic_p ( italic_\\u03c4 | caligraphic_O ) . Let \\ud835\\udcab t \\u2062 r \\u2062 a \\u2062 n \\u2062 s = p \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 | \\u03b8 ) \\u2062 p D \\u2062 ( \\u03b8 ) subscript \\ud835\\udcab \\ud835\\udc61 \\ud835\\udc5f \\ud835\\udc4e \\ud835\\udc5b \\ud835\\udc60 \\ud835\\udc5d \\ud835\\udc94 conditional \\ud835\\udc82 \\ud835\\udf03 subscript \\ud835\\udc5d \\ud835\\udc37 \\ud835\\udf03 \\\\mathcal{P}_{trans}=p\\\\left(\\\\bm{s},\\\\bm{a}|\\\\theta\\\\right)p_{D}\\\\left(\\\\theta\\\\right) caligraphic_P start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT = italic_p ( bold_italic_s , bold_italic_a | italic_\\u03b8 ) italic_p start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_\\u03b8 ) , x ~ = x / \\ud835\\udcab t \\u2062 r \\u2062 a \\u2062 n \\u2062 s ~ \\ud835\\udc65 \\ud835\\udc65 subscript \\ud835\\udcab \\ud835\\udc61 \\ud835\\udc5f \\ud835\\udc4e \\ud835\\udc5b \\ud835\\udc60 \\\\tilde{x}=x/\\\\mathcal{P}_{trans} over~ start_ARG italic_x end_ARG = italic_x / caligraphic_P start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT and y ~ = y / \\ud835\\udcab t \\u2062 r \\u2062 a \\u2062 n \\u2062 s ~ \\ud835\\udc66 \\ud835\\udc66 subscript \\ud835\\udcab \\ud835\\udc61 \\ud835\\udc5f \\ud835\\udc4e \\ud835\\udc5b \\ud835\\udc60 \\\\tilde{y}=y/\\\\mathcal{P}_{trans} over~ start_ARG italic_y end_ARG = italic_y / caligraphic_P start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT and recall Definition 4.1 , i.e., the definition of \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 {\\\\bf{A-GSWD}}_{k} bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT . Then, the variational inference can be reformulated to the minimization problem: arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u03b8 \\u2062 ( \\u03c4 ) , p \\u2062 ( \\u03c4 | \\ud835\\udcaa ) ) = arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u2062 ( \\ud835\\udc1a ) \\u22c5 \\ud835\\udcab trans , p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u22c5 \\ud835\\udcab trans ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k subscript q \\ud835\\udf03 \\ud835\\udf0f p conditional \\ud835\\udf0f \\ud835\\udcaa subscript q \\ud835\\udf03 \\ud835\\udf0f min \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u22c5 q \\ud835\\udc1a subscript \\ud835\\udcab trans \\u22c5 p conditional \\ud835\\udcaa \\ud835\\udf0f subscript \\ud835\\udcab trans \\\\displaystyle\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}{\\\\bf{A-GSWD}}_{k}\\\\left(q% _{\\\\theta}\\\\left(\\\\tau\\\\right),p\\\\left(\\\\tau|\\\\mathcal{O}\\\\right)\\\\right)=\\\\arg\\\\underset% {q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}{\\\\bf{A-GSWD}}_{k}\\\\left(q\\\\left(\\\\bm{a}\\\\right)\\\\cdot% \\\\mathcal{P}_{trans},p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)\\\\cdot\\\\mathcal{P}_{trans}\\\\right) roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) , roman_p ( italic_\\u03c4 | caligraphic_O ) ) = roman_arg start_UNDERACCENT roman_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q ( bold_a ) \\u22c5 caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT , roman_p ( caligraphic_O | italic_\\u03c4 ) \\u22c5 caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT ) (9) = arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 ( \\u222b \\ud835\\udcb3 \\u03b8 W k k \\u2062 ( \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) \\u22c5 \\ud835\\udcab trans \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u22c5 \\ud835\\udcab trans \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k absent subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min superscript subscript subscript \\ud835\\udcb3 \\ud835\\udf03 superscript subscript W k k subscript \\ud835\\udc9c \\u22c5 q \\ud835\\udc1a subscript \\ud835\\udcab trans \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc9c \\u22c5 p conditional \\ud835\\udcaa \\ud835\\udf0f subscript \\ud835\\udcab trans \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle=\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\left(\\\\int_{\\\\mathcal{X}% _{\\\\theta}}W_{k}^{k}\\\\left(\\\\mathcal{A}_{q\\\\left(\\\\bm{a}\\\\right)\\\\cdot\\\\mathcal{P}_{% trans}}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right),\\\\mathcal{A}_{p\\\\left(\\\\mathcal{O}|% \\\\tau\\\\right)\\\\cdot\\\\mathcal{P}_{trans}}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right)% \\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} = roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG ( \\u222b start_POSTSUBSCRIPT caligraphic_X start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_W start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) \\u22c5 caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) \\u22c5 caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = ( i ) \\u2062 arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 ( \\u222b \\ud835\\udcb3 \\u03b8 W k k \\u2062 ( \\ud835\\udcab trans \\u22c5 \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udcab trans \\u22c5 \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k \\ud835\\udc56 subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min superscript subscript subscript \\ud835\\udcb3 \\ud835\\udf03 superscript subscript W k k \\u22c5 subscript \\ud835\\udcab trans subscript \\ud835\\udc9c q \\ud835\\udc1a \\u22c5 ~ \\ud835\\udf03 \\u22c5 subscript \\ud835\\udcab trans subscript \\ud835\\udc9c p conditional \\ud835\\udcaa \\ud835\\udf0f \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle\\\\overset{(i)}{=}\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\left(% \\\\int_{\\\\mathcal{X}_{\\\\theta}}W_{k}^{k}\\\\left(\\\\mathcal{P}_{trans}\\\\cdot\\\\mathcal{A}_% {q\\\\left(\\\\bm{a}\\\\right)}\\\\left(\\\\cdot,\\\\widetilde{\\\\theta}\\\\right),\\\\mathcal{P}_{trans% }\\\\cdot\\\\mathcal{A}_{p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)}\\\\left(\\\\cdot,\\\\widetilde{% \\\\theta}\\\\right)\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} start_OVERACCENT ( italic_i ) end_OVERACCENT start_ARG = end_ARG roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG ( \\u222b start_POSTSUBSCRIPT caligraphic_X start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_W start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 inf \\u03b3 \\u2208 \\u0393 \\u2062 ( \\ud835\\udcab trans \\u22c5 \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) , \\ud835\\udcab trans \\u22c5 \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) ( \\u222b \\ud835\\udcb3 \\u03b8 \\u222b \\ud835\\udcb3 \\u00d7 \\ud835\\udcb3 d \\u2062 ( x , y ) k \\u2062 d \\u03b3 \\u2062 ( x , y ) \\u2062 d \\u03b8 ~ ) 1 k absent subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min subscript infimum \\ud835\\udefe \\u0393 \\u22c5 subscript \\ud835\\udcab trans subscript \\ud835\\udc9c q \\ud835\\udc1a \\u22c5 subscript \\ud835\\udcab trans subscript \\ud835\\udc9c p conditional \\ud835\\udcaa \\ud835\\udf0f superscript subscript subscript \\ud835\\udcb3 \\ud835\\udf03 subscript \\ud835\\udcb3 \\ud835\\udcb3 d superscript x y k differential-d \\ud835\\udefe x y differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle=\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\inf_{\\\\gamma\\\\in\\\\Gamma(% \\\\mathcal{P}_{trans}\\\\cdot\\\\mathcal{A}_{q\\\\left(\\\\bm{a}\\\\right)},\\\\mathcal{P}_{trans}% \\\\cdot\\\\mathcal{A}_{p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)})}\\\\left(\\\\int_{\\\\mathcal{X}_{% \\\\theta}}\\\\int_{\\\\mathcal{X}\\\\times\\\\mathcal{X}}d(x,y)^{k}\\\\mathrm{d}\\\\gamma(x,y)% \\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} = roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG roman_inf start_POSTSUBSCRIPT italic_\\u03b3 \\u2208 roman_\\u0393 ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) end_POSTSUBSCRIPT , caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT ( \\u222b start_POSTSUBSCRIPT caligraphic_X start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT \\u222b start_POSTSUBSCRIPT caligraphic_X \\u00d7 caligraphic_X end_POSTSUBSCRIPT roman_d ( roman_x , roman_y ) start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT roman_d italic_\\u03b3 ( roman_x , roman_y ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 inf \\u03b3 \\u2208 \\u0393 \\u2062 ( \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) , \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) ( \\u222b \\u222b d \\u2062 ( \\ud835\\udcab trans \\u2062 x ~ , \\ud835\\udcab trans \\u2062 y ~ ) k \\u2062 d \\u03b3 \\u2062 ( \\ud835\\udcab trans \\u2062 x ~ , \\ud835\\udcab trans \\u2062 y ~ ) \\u2062 d \\u03b8 ~ ) 1 k absent subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min subscript infimum \\ud835\\udefe \\u0393 subscript \\ud835\\udc9c q \\ud835\\udc1a subscript \\ud835\\udc9c p conditional \\ud835\\udcaa \\ud835\\udf0f superscript d superscript subscript \\ud835\\udcab trans ~ x subscript \\ud835\\udcab trans ~ y k differential-d \\ud835\\udefe subscript \\ud835\\udcab trans ~ x subscript \\ud835\\udcab trans ~ y differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle=\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\inf_{\\\\gamma\\\\in\\\\Gamma(% \\\\mathcal{A}_{q\\\\left(\\\\bm{a}\\\\right)},\\\\mathcal{A}_{p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)% })}\\\\left(\\\\int\\\\int d(\\\\mathcal{P}_{trans}\\\\tilde{x},\\\\mathcal{P}_{trans}\\\\tilde{y})% ^{k}\\\\mathrm{d}\\\\gamma(\\\\mathcal{P}_{trans}\\\\tilde{x},\\\\mathcal{P}_{trans}\\\\tilde{y}% )\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} = roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG roman_inf start_POSTSUBSCRIPT italic_\\u03b3 \\u2208 roman_\\u0393 ( caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT ( \\u222b \\u222b roman_d ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_x end_ARG , caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_y end_ARG ) start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT roman_d italic_\\u03b3 ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_x end_ARG , caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_y end_ARG ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = ( i \\u2062 i ) \\u2062 arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 inf \\u03b3 \\u2208 \\u0393 \\u2062 ( \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) , \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) ( \\u222b \\u222b ( \\ud835\\udcab trans \\u22c5 d \\u2062 ( x ~ , y ~ ) ) k \\u2062 d \\u03b3 \\u2062 ( \\ud835\\udcab trans \\u2062 x ~ , \\ud835\\udcab trans \\u2062 y ~ ) \\u2062 d \\u03b8 ~ ) 1 k \\ud835\\udc56 \\ud835\\udc56 subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min subscript infimum \\ud835\\udefe \\u0393 subscript \\ud835\\udc9c q \\ud835\\udc1a subscript \\ud835\\udc9c p conditional \\ud835\\udcaa \\ud835\\udf0f superscript superscript \\u22c5 subscript \\ud835\\udcab trans d ~ x ~ y k differential-d \\ud835\\udefe subscript \\ud835\\udcab trans ~ x subscript \\ud835\\udcab trans ~ y differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle\\\\overset{(ii)}{=}\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\inf_{% \\\\gamma\\\\in\\\\Gamma(\\\\mathcal{A}_{q\\\\left(\\\\bm{a}\\\\right)},\\\\mathcal{A}_{p\\\\left(% \\\\mathcal{O}|\\\\tau\\\\right)})}\\\\left(\\\\int\\\\int\\\\left(\\\\mathcal{P}_{trans}\\\\cdot d(% \\\\tilde{x},\\\\tilde{y})\\\\right)^{k}\\\\mathrm{d}\\\\gamma(\\\\mathcal{P}_{trans}\\\\tilde{x},% \\\\mathcal{P}_{trans}\\\\tilde{y})\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} start_OVERACCENT ( italic_i italic_i ) end_OVERACCENT start_ARG = end_ARG roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG roman_inf start_POSTSUBSCRIPT italic_\\u03b3 \\u2208 roman_\\u0393 ( caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT ( \\u222b \\u222b ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 roman_d ( over~ start_ARG roman_x end_ARG , over~ start_ARG roman_y end_ARG ) ) start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT roman_d italic_\\u03b3 ( caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_x end_ARG , caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT over~ start_ARG roman_y end_ARG ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = ( i \\u2062 i \\u2062 i ) \\u2062 arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udcab trans \\u22c5 inf \\u03b3 \\u2208 \\u0393 \\u2062 ( \\ud835\\udc9c q \\u2062 ( \\ud835\\udc1a ) , \\ud835\\udc9c p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) ( \\u222b \\u222b d \\u2062 ( x ~ , y ~ ) k \\u2062 d \\u03b3 \\u2062 ( x ~ , y ~ ) \\u2062 d \\u03b8 ~ ) 1 k \\u22c5 \\ud835\\udc56 \\ud835\\udc56 \\ud835\\udc56 subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min subscript \\ud835\\udcab trans subscript infimum \\ud835\\udefe \\u0393 subscript \\ud835\\udc9c q \\ud835\\udc1a subscript \\ud835\\udc9c p conditional \\ud835\\udcaa \\ud835\\udf0f superscript d superscript ~ x ~ y k differential-d \\ud835\\udefe ~ x ~ y differential-d ~ \\ud835\\udf03 1 k \\\\displaystyle\\\\overset{(iii)}{=}\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}% \\\\mathcal{P}_{trans}\\\\cdot\\\\inf_{\\\\gamma\\\\in\\\\Gamma(\\\\mathcal{A}_{q\\\\left(\\\\bm{a}\\\\right% )},\\\\mathcal{A}_{p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)})}\\\\left(\\\\int\\\\int d(\\\\tilde{x},% \\\\tilde{y})^{k}\\\\mathrm{d}\\\\gamma(\\\\tilde{x},\\\\tilde{y})\\\\mathrm{d}\\\\widetilde{\\\\theta% }\\\\right)^{\\\\frac{1}{k}} start_OVERACCENT ( italic_i italic_i italic_i ) end_OVERACCENT start_ARG = end_ARG roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 roman_inf start_POSTSUBSCRIPT italic_\\u03b3 \\u2208 roman_\\u0393 ( caligraphic_A start_POSTSUBSCRIPT roman_q ( bold_a ) end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT roman_p ( caligraphic_O | italic_\\u03c4 ) end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT ( \\u222b \\u222b roman_d ( over~ start_ARG roman_x end_ARG , over~ start_ARG roman_y end_ARG ) start_POSTSUPERSCRIPT roman_k end_POSTSUPERSCRIPT roman_d italic_\\u03b3 ( over~ start_ARG roman_x end_ARG , over~ start_ARG roman_y end_ARG ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG roman_k end_ARG end_POSTSUPERSCRIPT = arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udcab trans \\u22c5 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u2062 ( \\ud835\\udc1a ) , p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) absent \\u22c5 subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min subscript \\ud835\\udcab trans \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k q \\ud835\\udc1a p conditional \\ud835\\udcaa \\ud835\\udf0f \\\\displaystyle=\\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}\\\\mathcal{P}_{trans}% \\\\cdot{\\\\bf{A-GSWD}}_{k}\\\\left(q\\\\left(\\\\bm{a}\\\\right),p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right% )\\\\right) = roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG caligraphic_P start_POSTSUBSCRIPT roman_trans end_POSTSUBSCRIPT \\u22c5 bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q ( bold_a ) , roman_p ( caligraphic_O | italic_\\u03c4 ) ) where ( i ) \\ud835\\udc56 (i) ( italic_i ) follows from the push-forward operator definition: \\ud835\\udc9c \\u03bc \\u2062 ( l , \\u03b8 ~ ) = \\u222b \\ud835\\udd3e d \\u03b4 \\u2062 ( l \\u2212 \\u03b1 \\u2062 ( x , \\u03b8 ~ ) ) \\u2062 d \\u03bc subscript \\ud835\\udc9c \\ud835\\udf07 \\ud835\\udc59 ~ \\ud835\\udf03 subscript superscript \\ud835\\udd3e \\ud835\\udc51 \\ud835\\udeff \\ud835\\udc59 \\ud835\\udefc \\ud835\\udc65 ~ \\ud835\\udf03 differential-d \\ud835\\udf07 \\\\mathcal{A}_{\\\\mu}(l,\\\\widetilde{\\\\theta})=\\\\int_{\\\\mathbb{G}^{d}}\\\\delta(l-\\\\alpha(x% ,\\\\widetilde{\\\\theta}))\\\\mathrm{d}\\\\mu caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = \\u222b start_POSTSUBSCRIPT blackboard_G start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_\\u03b4 ( italic_l - italic_\\u03b1 ( italic_x , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d italic_\\u03bc . ( i \\u2062 i ) \\ud835\\udc56 \\ud835\\udc56 (ii) ( italic_i italic_i ) follows from d \\u2062 ( c \\u2062 x ~ , c \\u2062 y ~ ) = c \\u2062 d \\u2062 ( x ~ , y ~ ) , c \\u2208 ( 0 , 1 ) formulae-sequence \\ud835\\udc51 \\ud835\\udc50 ~ \\ud835\\udc65 \\ud835\\udc50 ~ \\ud835\\udc66 \\ud835\\udc50 \\ud835\\udc51 ~ \\ud835\\udc65 ~ \\ud835\\udc66 \\ud835\\udc50 0 1 d(c\\\\tilde{x},c\\\\tilde{y})=cd(\\\\tilde{x},\\\\tilde{y}),c\\\\in(0,1) italic_d ( italic_c over~ start_ARG italic_x end_ARG , italic_c over~ start_ARG italic_y end_ARG ) = italic_c italic_d ( over~ start_ARG italic_x end_ARG , over~ start_ARG italic_y end_ARG ) , italic_c \\u2208 ( 0 , 1 ) as d \\ud835\\udc51 d italic_d is a metric. ( i \\u2062 i \\u2062 i ) \\ud835\\udc56 \\ud835\\udc56 \\ud835\\udc56 (iii) ( italic_i italic_i italic_i ) follows from the fact that d \\u2062 \\u03b3 \\u2062 ( c \\u2062 x ~ , c \\u2062 y ~ ) = d \\u2062 \\u03b3 \\u2062 ( c \\u2062 x , c \\u2062 y ) = d \\u2062 \\u03b3 \\u2062 ( x , y ) = d \\u2062 \\u03b3 \\u2062 ( x ~ , y ~ ) d \\ud835\\udefe \\ud835\\udc50 ~ \\ud835\\udc65 \\ud835\\udc50 ~ \\ud835\\udc66 d \\ud835\\udefe \\ud835\\udc50 \\ud835\\udc65 \\ud835\\udc50 \\ud835\\udc66 d \\ud835\\udefe \\ud835\\udc65 \\ud835\\udc66 d \\ud835\\udefe ~ \\ud835\\udc65 ~ \\ud835\\udc66 \\\\mathrm{d}\\\\gamma(c\\\\tilde{x},c\\\\tilde{y})=\\\\mathrm{d}\\\\gamma(cx,cy)=\\\\mathrm{d}% \\\\gamma(x,y)=\\\\mathrm{d}\\\\gamma(\\\\tilde{x},\\\\tilde{y}) roman_d italic_\\u03b3 ( italic_c over~ start_ARG italic_x end_ARG , italic_c over~ start_ARG italic_y end_ARG ) = roman_d italic_\\u03b3 ( italic_c italic_x , italic_c italic_y ) = roman_d italic_\\u03b3 ( italic_x , italic_y ) = roman_d italic_\\u03b3 ( over~ start_ARG italic_x end_ARG , over~ start_ARG italic_y end_ARG ) , since d \\u2062 \\u03b3 \\u2062 ( c \\u2062 x ~ , c \\u2062 y ~ ) d \\ud835\\udefe \\ud835\\udc50 ~ \\ud835\\udc65 \\ud835\\udc50 ~ \\ud835\\udc66 \\\\mathrm{d}\\\\gamma(c\\\\tilde{x},c\\\\tilde{y}) roman_d italic_\\u03b3 ( italic_c over~ start_ARG italic_x end_ARG , italic_c over~ start_ARG italic_y end_ARG ) is the measure of the subset of \\ud835\\udcb3 \\u00d7 \\ud835\\udcb3 \\ud835\\udcb3 \\ud835\\udcb3 \\\\mathcal{X}\\\\times\\\\mathcal{X} caligraphic_X \\u00d7 caligraphic_X , which is just the re-scaled version of the subset ( x ~ , y ~ ) ~ \\ud835\\udc65 ~ \\ud835\\udc66 (\\\\tilde{x},\\\\tilde{y}) ( over~ start_ARG italic_x end_ARG , over~ start_ARG italic_y end_ARG ) by the map ( x , y ) \\u21a6 ( x , y ) maps-to \\ud835\\udc65 \\ud835\\udc66 \\ud835\\udc65 \\ud835\\udc66 (x,y)\\\\mapsto(x,y) ( italic_x , italic_y ) \\u21a6 ( italic_x , italic_y ) . Equation 9 presents that the objective can be transformed to the minimization problem, i.e., arg \\u2061 min q \\u03b8 \\u2062 ( \\u03c4 ) \\u2062 \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( q \\u2062 ( \\ud835\\udc1a ) , p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) ) subscript \\ud835\\udc5e \\ud835\\udf03 \\ud835\\udf0f min \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k q \\ud835\\udc1a p conditional \\ud835\\udcaa \\ud835\\udf0f \\\\arg\\\\underset{q_{\\\\theta}(\\\\tau)}{\\\\rm{min}}{\\\\bf{A-GSWD}}_{k}\\\\left(q\\\\left(\\\\bm{a}% \\\\right),p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right)\\\\right) roman_arg start_UNDERACCENT italic_q start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_\\u03c4 ) end_UNDERACCENT start_ARG roman_min end_ARG bold_A - bold_GSWD start_POSTSUBSCRIPT roman_k end_POSTSUBSCRIPT ( roman_q ( bold_a ) , roman_p ( caligraphic_O | italic_\\u03c4 ) ) , where p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p(\\\\mathcal{O}|\\\\tau) italic_p ( caligraphic_O | italic_\\u03c4 ) represents the optimality likelihood. D.2 Definition of Distributional Temporal Difference We use distributional TD learning to estimate the distribution of state-action value, denoted as Z \\ud835\\udc4d Z italic_Z . In each iteration, we have the following: \\u03b6 k + 1 i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 1 \\ud835\\udc94 \\ud835\\udc82 \\\\displaystyle\\\\zeta^{i}_{k+1}(\\\\bm{s},\\\\bm{a}) italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) = \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + l t \\u2062 d \\u2062 \\ud835\\udeab k i absent subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 subscript superscript \\ud835\\udeab \\ud835\\udc56 \\ud835\\udc58 \\\\displaystyle=\\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})+l_{td}\\\\bm{\\\\Delta}^{i}_{k} = italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) + italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT bold_\\u0394 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT (10) = \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) + l t \\u2062 d \\u00d7 d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 ( h i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) + \\u03b3 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 \\u2032 ) ) , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) ) absent subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\u210e \\ud835\\udc56 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 \\ud835\\udefe subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 superscript \\ud835\\udc94 \\u2032 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 \\\\displaystyle=\\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})+l_{td}\\\\times\\\\overset{-}{d}_{\\\\infty}% (\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}(h_{i}(\\\\bm{s},\\\\bm{a},\\\\bm{s}^{\\\\prime})+\\\\gamma\\\\zeta% ^{i}_{k}(\\\\bm{s}^{\\\\prime})),\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}\\\\zeta^{i}_{k}(\\\\bm{s},% \\\\bm{a})) = italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) + italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT \\u00d7 over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) + italic_\\u03b3 italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ) , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) ) where \\u03b6 k i \\u2208 S \\u00d7 A subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc46 \\ud835\\udc34 \\\\zeta^{i}_{k}\\\\in S\\\\times A italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \\u2208 italic_S \\u00d7 italic_A represents the estimated distribution of the state-action distribution Z \\ud835\\udc4d Z italic_Z in the k \\ud835\\udc58 k italic_k -th TD-learning-iteration for all i = 0 , \\u2026 , p \\ud835\\udc56 0 \\u2026 \\ud835\\udc5d i=0,...,p italic_i = 0 , \\u2026 , italic_p . The TD learning rate is denoted as l t \\u2062 d subscript \\ud835\\udc59 \\ud835\\udc61 \\ud835\\udc51 l_{td} italic_l start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT . The function h i : S \\u00d7 A \\u00d7 S \\u2192 \\u211d : subscript \\u210e \\ud835\\udc56 \\u2192 \\ud835\\udc46 \\ud835\\udc34 \\ud835\\udc46 \\u211d h_{i}:S\\\\times A\\\\times S\\\\rightarrow\\\\mathbb{R} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : italic_S \\u00d7 italic_A \\u00d7 italic_S \\u2192 blackboard_R maps the triple ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 (\\\\bm{s},\\\\bm{a},\\\\bm{s}^{\\\\prime}) ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) to a real number . Specifically, h i subscript \\u210e \\ud835\\udc56 h_{i} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is defined as h i = r subscript \\u210e \\ud835\\udc56 \\ud835\\udc5f h_{i}=r italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_r when i = 0 ; \\ud835\\udc56 0 i=0; italic_i = 0 ; and h i = g i subscript \\u210e \\ud835\\udc56 superscript \\ud835\\udc54 \\ud835\\udc56 h_{i}=g^{i} italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_g start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT when i \\u2208 [ 1 , p ] \\ud835\\udc56 1 \\ud835\\udc5d i\\\\in[1,p] italic_i \\u2208 [ 1 , italic_p ] . The distributional TD error \\ud835\\udeab k i subscript superscript \\ud835\\udeab \\ud835\\udc56 \\ud835\\udc58 \\\\bm{\\\\Delta}^{i}_{k} bold_\\u0394 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in Equation 10 is calculated by d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 ( h i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 , \\ud835\\udc94 \\u2032 ) + \\u03b3 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 \\u2032 ) ) , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 \\u03b6 k i \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) ) subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\u210e \\ud835\\udc56 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc94 \\u2032 \\ud835\\udefe subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 superscript \\ud835\\udc94 \\u2032 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript superscript \\ud835\\udf01 \\ud835\\udc56 \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 \\\\overset{-}{d}_{\\\\infty}(\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}(h_{i}(\\\\bm{s},\\\\bm{a},\\\\bm{s% }^{\\\\prime})+\\\\gamma\\\\zeta^{i}_{k}(\\\\bm{s}^{\\\\prime})),\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}% \\\\zeta^{i}_{k}(\\\\bm{s},\\\\bm{a})) over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a , bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) + italic_\\u03b3 italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ) , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_\\u03b6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) ) . D.3 Proofs Here we present the proofs of Proposition 5.1 (Pseudo-metric) , Theorem 5.4 (Global Convergence) and Theorem 5.5 (Global Convergence Rate) , as outlined in Section 5 . The associated propositions, namely Proposition D.1 (Policy Evaluation) and Proposition D.2 (Policy Improvement) , are explicated and clarified by their respective proofs below. Proposition 5.1 . (Pseudo-metric): Given two probability measures \\u03bc , \\u03bd \\u2208 P k \\u2062 ( \\ud835\\udcb3 ) \\ud835\\udf07 \\ud835\\udf08 subscript \\ud835\\udc43 \\ud835\\udc58 \\ud835\\udcb3 \\\\mu,\\\\nu\\\\in P_{k}(\\\\mathcal{X}) italic_\\u03bc , italic_\\u03bd \\u2208 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_X ) and a mapping \\u03b1 : \\ud835\\udcb3 \\u2192 \\u211b \\u03b8 ~ : \\ud835\\udefc \\u2192 \\ud835\\udcb3 subscript \\u211b ~ \\ud835\\udf03 \\\\alpha:\\\\mathcal{X}\\\\rightarrow\\\\mathcal{R}_{\\\\widetilde{\\\\theta}} italic_\\u03b1 : caligraphic_X \\u2192 caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , the adaptive slicing A-GSWD, defined in Definition 4.1 , with order k \\ud835\\udc58 k italic_k in the range [ 1 , \\u221e ) 1 [1,\\\\infty) [ 1 , \\u221e ) , is a pseudo-metric. This pseudo-metric satisfies non-negativity, symmetry, the triangle inequality, and \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bc ) = 0 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 0 {\\\\bf{A-GSWD}}_{k}(\\\\mu,\\\\mu)=0 bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = 0 . Proof : The non-negativity property naturally arises from the fact that the Wasserstein distance W k subscript \\ud835\\udc4a \\ud835\\udc58 W_{k} italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is a metric (Villani et al., 2009 ) . To prove symmetry, since the k-Wasserstein distance is a metric (Villani et al., 2009 ) : W k \\u2062 ( \\ud835\\udc9c \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ; \\u03b1 ) , \\ud835\\udc9c \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) = W k \\u2062 ( \\ud835\\udc9c \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udc9c \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 \\ud835\\udefc subscript \\ud835\\udc9c \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc9c \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 W_{k}\\\\left(\\\\mathcal{A}_{\\\\mu}(\\\\cdot,\\\\widetilde{\\\\theta};\\\\alpha),\\\\mathcal{A}_{\\\\nu% }(\\\\cdot,\\\\widetilde{\\\\theta})\\\\right)=W_{k}\\\\left(\\\\mathcal{A}_{\\\\nu}(\\\\cdot,% \\\\widetilde{\\\\theta}),\\\\mathcal{A}_{\\\\mu}(\\\\cdot,\\\\widetilde{\\\\theta})\\\\right) italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ; italic_\\u03b1 ) , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) = italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) Thus, there exists (Chen et al., 2021 ) : \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc24 \\u2062 ( \\u03bc , \\u03bd ) \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc24 \\ud835\\udf07 \\ud835\\udf08 \\\\displaystyle\\\\bf{A-GSWD}_{k}(\\\\mu,\\\\nu) bold_A - bold_GSWD start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bd ) = ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udc9c \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k absent superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc9c \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\\\displaystyle=\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(% \\\\mathcal{A}_{\\\\mu}(\\\\cdot,\\\\widetilde{\\\\theta}),\\\\mathcal{A}_{\\\\nu}(\\\\cdot,\\\\widetilde% {\\\\theta})\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} = ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT = ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bd \\u2062 ( \\u22c5 , \\u03b8 ~ ) , \\ud835\\udc9c \\u03bc \\u2062 ( \\u22c5 , \\u03b8 ~ ) ) \\u2062 d \\u03b8 ~ ) 1 k = \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc24 \\u2062 ( \\u03bd , \\u03bc ) absent superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf08 \\u22c5 ~ \\ud835\\udf03 subscript \\ud835\\udc9c \\ud835\\udf07 \\u22c5 ~ \\ud835\\udf03 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc24 \\ud835\\udf08 \\ud835\\udf07 \\\\displaystyle=\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(% \\\\mathcal{A}_{\\\\nu}(\\\\cdot,\\\\widetilde{\\\\theta}),\\\\mathcal{A}_{\\\\mu}(\\\\cdot,\\\\widetilde% {\\\\theta})\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}}=\\\\bf{A-GSWD}_% {k}(\\\\nu,\\\\mu) = ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bd end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ( \\u22c5 , over~ start_ARG italic_\\u03b8 end_ARG ) ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT = bold_A - bold_GSWD start_POSTSUBSCRIPT bold_k end_POSTSUBSCRIPT ( italic_\\u03bd , italic_\\u03bc ) Therefore, symmetry holds. Then, we prove the triangle inequality. Since the triangle inequality holds for the Wasserstein distance, we can obtain W k \\u2062 ( \\ud835\\udc9c \\u03bc 1 , \\ud835\\udc9c \\u03bc 3 ) \\u2264 W k \\u2062 ( \\ud835\\udc9c \\u03bc 1 , \\ud835\\udc9c \\u03bc 2 ) + W k \\u2062 ( \\ud835\\udc9c \\u03bc 2 , \\ud835\\udc9c \\u03bc 3 ) subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 subscript \\ud835\\udc9c subscript \\ud835\\udf07 3 subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 subscript \\ud835\\udc9c subscript \\ud835\\udf07 3 W_{k}\\\\left(\\\\mathcal{A}_{\\\\mu_{1}},\\\\mathcal{A}_{\\\\mu_{3}}\\\\right)\\\\leq W_{k}\\\\left(% \\\\mathcal{A}_{\\\\mu_{1}},\\\\mathcal{A}_{\\\\mu_{2}}\\\\right)+W_{k}\\\\left(\\\\mathcal{A}_{\\\\mu% _{2}},\\\\mathcal{A}_{\\\\mu_{3}}\\\\right) italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) \\u2264 italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) + italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) . Thus, there exists: \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc 1 , \\u03bc 3 ) = ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc 1 , \\ud835\\udc9c \\u03bc 3 ) \\u2062 d \\u03b8 ~ ) 1 k \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 3 superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 subscript \\ud835\\udc9c subscript \\ud835\\udf07 3 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\\\displaystyle{\\\\bf{A-GSWD}}_{k}(\\\\mu_{1},\\\\mu_{3})=\\\\left(\\\\int_{\\\\mathcal{R}_{% \\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(\\\\mathcal{A}_{\\\\mu_{1}},\\\\mathcal{A}_{\\\\mu_{3}}% \\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{\\\\frac{1}{k}} bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT (11) \\u2264 ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc 1 , \\ud835\\udc9c \\u03bc 2 ) + W k k \\u2062 ( \\ud835\\udc9c \\u03bc 2 , \\ud835\\udc9c \\u03bc 3 ) \\u2062 d \\u2062 \\u03b8 ~ ) 1 k absent superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 subscript \\ud835\\udc9c subscript \\ud835\\udf07 3 d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\\\displaystyle\\\\leq\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(% \\\\mathcal{A}_{\\\\mu_{1}},\\\\mathcal{A}_{\\\\mu_{2}}\\\\right)+W_{k}^{k}\\\\left(\\\\mathcal{A}_% {\\\\mu_{2}},\\\\mathcal{A}_{\\\\mu_{3}}\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}\\\\right)^{% \\\\frac{1}{k}} \\u2264 ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) + italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT \\u2264 ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc 1 , \\ud835\\udc9c \\u03bc 2 ) \\u2062 d \\u03b8 ~ ) 1 k + ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc 2 , \\ud835\\udc9c \\u03bc 3 ) \\u2062 d \\u03b8 ~ ) 1 k absent superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 subscript \\ud835\\udc9c subscript \\ud835\\udf07 3 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 \\\\displaystyle\\\\leq\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}\\\\left(% \\\\mathcal{A}_{\\\\mu_{1}},\\\\mathcal{A}_{\\\\mu_{2}}\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta}% \\\\right)^{\\\\frac{1}{k}}+\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^{k}% \\\\left(\\\\mathcal{A}_{\\\\mu_{2}},\\\\mathcal{A}_{\\\\mu_{3}}\\\\right)\\\\mathrm{d}\\\\widetilde{% \\\\theta}\\\\right)^{\\\\frac{1}{k}} \\u2264 ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT + ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT where the derivation of Equation 11 is based on the Minkowski inequality (Bahouri et al., 2011 ) , which establishes that \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 {\\\\bf{A-GSWD}}_{k} bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT satisfies the triangle inequality. Since W k \\u2062 ( \\u03bc , \\u03bc ) = 0 subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 0 W_{k}(\\\\mu,\\\\mu)=0 italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = 0 for any \\u03bc \\ud835\\udf07 \\\\mu italic_\\u03bc (Villani et al., 2009 ) , we have \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bc ) = ( \\u222b \\u211b \\u03b8 ~ W k k \\u2062 ( \\ud835\\udc9c \\u03bc , \\ud835\\udc9c \\u03bc ) \\u2062 d \\u03b8 ~ ) 1 k = 0 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 superscript subscript subscript \\u211b ~ \\ud835\\udf03 superscript subscript \\ud835\\udc4a \\ud835\\udc58 \\ud835\\udc58 subscript \\ud835\\udc9c \\ud835\\udf07 subscript \\ud835\\udc9c \\ud835\\udf07 differential-d ~ \\ud835\\udf03 1 \\ud835\\udc58 0 {\\\\bf{A-GSWD}}_{k}(\\\\mu,\\\\mu)=\\\\left(\\\\int_{\\\\mathcal{R}_{\\\\widetilde{\\\\theta}}}W_{k}^% {k}\\\\left(\\\\mathcal{A}_{\\\\mu},\\\\mathcal{A}_{\\\\mu}\\\\right)\\\\mathrm{d}\\\\widetilde{\\\\theta% }\\\\right)^{\\\\frac{1}{k}}=0 bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = ( \\u222b start_POSTSUBSCRIPT caligraphic_R start_POSTSUBSCRIPT over~ start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc end_POSTSUBSCRIPT ) roman_d over~ start_ARG italic_\\u03b8 end_ARG ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_k end_ARG end_POSTSUPERSCRIPT = 0 . Therefore, A-GSWD is a pseudo-metric that satisfies non-negativity, symmetry, the triangle inequality, and \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc , \\u03bc ) = 0 \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 \\ud835\\udf07 \\ud835\\udf07 0 {\\\\bf{A-GSWD}}_{k}(\\\\mu,\\\\mu)=0 bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc , italic_\\u03bc ) = 0 . \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Remark 5.2 . The adaptive slicing A-GSWD, with order k \\u2208 [ 1 , \\u221e ) k 1 k\\\\in[1,\\\\infty) italic_k \\u2208 [ 1 , \\u221e ) , is a true metric if and only if the AGRT \\ud835\\udc9c \\ud835\\udc9c \\\\mathcal{A} caligraphic_A , defined in Definition 4.1 , is an injective mapping. Proof : Given the indiscernibility property for the Wasserstein distance W k subscript \\ud835\\udc4a \\ud835\\udc58 W_{k} italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT (Villani et al., 2009 ) , it follows W k \\u2062 ( \\u03bc 1 , \\u03bc 2 ) = 0 \\u2062 if and only if \\u2062 \\u03bc 1 = \\u03bc 2 subscript \\ud835\\udc4a \\ud835\\udc58 subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 2 0 if and only if subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 2 W_{k}(\\\\mu_{1},\\\\mu_{2})=0\\\\;\\\\text{if and only if}\\\\;\\\\mu_{1}=\\\\mu_{2} italic_W start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = 0 if and only if italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . Consequently, \\ud835\\udc00 \\u2212 \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 k \\u2062 ( \\u03bc 1 , \\u03bc 2 ) = 0 is equivalent to \\ud835\\udc9c \\u03bc 1 \\u2062 ( l , \\u03b8 ~ ) = \\ud835\\udc9c \\u03bc 2 \\u2062 ( l , \\u03b8 ~ ) formulae-sequence \\ud835\\udc00 subscript \\ud835\\udc06\\ud835\\udc12\\ud835\\udc16\\ud835\\udc03 \\ud835\\udc58 subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 2 0 is equivalent to subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 \\ud835\\udc59 ~ \\ud835\\udf03 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 \\ud835\\udc59 ~ \\ud835\\udf03 {\\\\bf{A-GSWD}}_{k}(\\\\mu_{1},\\\\mu_{2})=0\\\\quad\\\\text{is equivalent to}\\\\quad\\\\mathcal{% A}_{\\\\mu_{1}}(l,\\\\widetilde{\\\\theta})=\\\\mathcal{A}_{\\\\mu_{2}}(l,\\\\widetilde{\\\\theta}) bold_A - bold_GSWD start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = 0 is equivalent to caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) . The equality \\ud835\\udc9c \\u03bc 1 \\u2062 ( l , \\u03b8 ~ ) = \\ud835\\udc9c \\u03bc 2 \\u2062 ( l , \\u03b8 ~ ) subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 \\ud835\\udc59 ~ \\ud835\\udf03 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 \\ud835\\udc59 ~ \\ud835\\udf03 \\\\mathcal{A}_{\\\\mu_{1}}(l,\\\\widetilde{\\\\theta})=\\\\mathcal{A}_{\\\\mu_{2}}(l,\\\\widetilde% {\\\\theta}) caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) implies \\u03bc 1 = \\u03bc 2 subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 2 \\\\mu_{1}=\\\\mu_{2} italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT if and only if \\ud835\\udc9c \\ud835\\udc9c \\\\mathcal{A} caligraphic_A is an injective mapping. Therefore, A-GSWD is a metric if and only if \\ud835\\udc9c \\u03bc 1 \\u2062 ( l , \\u03b8 ~ ) = \\ud835\\udc9c \\u03bc 2 \\u2062 ( l , \\u03b8 ~ ) subscript \\ud835\\udc9c subscript \\ud835\\udf07 1 \\ud835\\udc59 ~ \\ud835\\udf03 subscript \\ud835\\udc9c subscript \\ud835\\udf07 2 \\ud835\\udc59 ~ \\ud835\\udf03 \\\\mathcal{A}_{\\\\mu_{1}}(l,\\\\widetilde{\\\\theta})=\\\\mathcal{A}_{\\\\mu_{2}}(l,\\\\widetilde% {\\\\theta}) caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) = caligraphic_A start_POSTSUBSCRIPT italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l , over~ start_ARG italic_\\u03b8 end_ARG ) implies \\u03bc 1 = \\u03bc 2 subscript \\ud835\\udf07 1 subscript \\ud835\\udf07 2 \\\\mu_{1}=\\\\mu_{2} italic_\\u03bc start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_\\u03bc start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , i.e., the AGRT \\ud835\\udc9c \\ud835\\udc9c \\\\mathcal{A} caligraphic_A is an injective mapping. \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Proposition D.1 . (Policy Evaluation) (Dabney et al., 2018 ; Wang et al., 2023 ) ): we consider a quantile approximation \\u03a0 W 1 subscript \\u03a0 subscript \\ud835\\udc4a 1 \\\\Pi_{W_{1}} roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT under the minimal 1-Wasserstein distance W 1 subscript \\ud835\\udc4a 1 W_{1} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , the Bellman operator \\ud835\\udcaf \\u03c0 superscript \\ud835\\udcaf \\ud835\\udf0b \\\\mathcal{T}^{\\\\pi} caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT under a deterministic policy \\u03c0 \\ud835\\udf0b \\\\pi italic_\\u03c0 and Z k + 1 \\u2062 ( \\ud835\\udc2c , \\ud835\\udc1a ) = \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z k \\u2062 ( \\ud835\\udc2c , \\ud835\\udc1a ) subscript \\ud835\\udc4d \\ud835\\udc58 1 \\ud835\\udc2c \\ud835\\udc1a subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d \\ud835\\udc58 \\ud835\\udc2c \\ud835\\udc1a Z_{k+1}(\\\\bm{s},\\\\bm{a})=\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}Z_{k}(\\\\bm{s},\\\\bm{a}) italic_Z start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) = roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) . The sequence Z k \\u2062 ( \\ud835\\udc2c , \\ud835\\udc1a ) subscript \\ud835\\udc4d \\ud835\\udc58 \\ud835\\udc2c \\ud835\\udc1a Z_{k}(\\\\bm{s},\\\\bm{a}) italic_Z start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) converges to a unique fixed point Z \\u03c0 \\u223c similar-to subscript \\ud835\\udc4d \\ud835\\udf0b \\\\overset{\\\\sim}{Z_{\\\\pi}} over\\u223c start_ARG italic_Z start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT end_ARG under the maximal form of \\u221e \\\\infty \\u221e -Wasserstein metric d - \\u221e subscript \\ud835\\udc51 \\\\overset{-}{d}_{\\\\infty} over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT . Proof : We recall a contraction proved in (Dabney et al., 2018 ) over the Wasserstein Metric: d - \\u221e \\u2062 ( \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z 1 , \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 \\u2062 Z 2 ) \\u2264 d - \\u221e \\u2062 ( Z 1 , Z 2 ) subscript \\ud835\\udc51 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d 1 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b subscript \\ud835\\udc4d 2 subscript \\ud835\\udc51 subscript \\ud835\\udc4d 1 subscript \\ud835\\udc4d 2 \\\\overset{-}{d}_{\\\\infty}(\\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi}Z_{1},\\\\Pi_{W_{1}}\\\\mathcal{% T}^{\\\\pi}Z_{2})\\\\leq\\\\overset{-}{d}_{\\\\infty}(Z_{1},Z_{2}) over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) \\u2264 over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT ( italic_Z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) (12) where Equation 12 implies that the combined operator \\u03a0 W 1 \\u2062 \\ud835\\udcaf \\u03c0 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript \\ud835\\udcaf \\ud835\\udf0b \\\\Pi_{W_{1}}\\\\mathcal{T}^{\\\\pi} roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT is an \\u221e \\\\infty \\u221e -contraction. Based on Banach\\u2019s fixed point theorem, \\ud835\\udcaf \\u03c0 superscript \\ud835\\udcaf \\ud835\\udf0b \\\\mathcal{T}^{\\\\pi} caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT has a unique fixed point, i.e., Z \\u03c0 \\u223c similar-to subscript \\ud835\\udc4d \\ud835\\udf0b \\\\overset{\\\\sim}{Z_{\\\\pi}} over\\u223c start_ARG italic_Z start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT end_ARG . Furthermore, the definition of Bellman optimality operator , defined as Equation 6 , implies that all moments of Z \\ud835\\udc4d Z italic_Z are bounded. Therefore, we conclude that the sequence Z k \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) subscript \\ud835\\udc4d \\ud835\\udc58 \\ud835\\udc94 \\ud835\\udc82 Z_{k}(\\\\bm{s},\\\\bm{a}) italic_Z start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) converges to Z \\u03c0 \\u223c similar-to subscript \\ud835\\udc4d \\ud835\\udf0b \\\\overset{\\\\sim}{Z_{\\\\pi}} over\\u223c start_ARG italic_Z start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT end_ARG in d - \\u221e subscript \\ud835\\udc51 \\\\overset{-}{d}_{\\\\infty} over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT \\u221e end_POSTSUBSCRIPT for p \\u2208 [ 1 , \\u221e ] \\ud835\\udc5d 1 p\\\\in[1,\\\\infty] italic_p \\u2208 [ 1 , \\u221e ] . \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Proposition D.2 . (Policy Improvement): Given an old policy \\ud835\\uded1 \\ud835\\udc28 \\u2062 \\ud835\\udc25 \\u2062 \\ud835\\udc1d subscript \\ud835\\uded1 \\ud835\\udc28 \\ud835\\udc25 \\ud835\\udc1d \\\\bm{\\\\pi}_{\\\\bm{old}} bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT , a new policy \\ud835\\uded1 \\ud835\\udc27 \\u2062 \\ud835\\udc1e \\u2062 \\ud835\\udc30 subscript \\ud835\\uded1 \\ud835\\udc27 \\ud835\\udc1e \\ud835\\udc30 \\\\bm{\\\\pi}_{\\\\bm{new}} bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT and Q \\u2062 ( s , a ) = \\ud835\\udd3c \\u2062 [ Z \\u2062 ( s , a ) ] \\ud835\\udc44 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udd3c delimited-[] \\ud835\\udc4d \\ud835\\udc60 \\ud835\\udc4e Q(s,a)=\\\\mathbb{E}[Z(s,a)] italic_Q ( italic_s , italic_a ) = blackboard_E [ italic_Z ( italic_s , italic_a ) ] , suppose 1 holds, there exists Q \\ud835\\uded1 \\ud835\\udc27 \\u2062 \\ud835\\udc1e \\u2062 \\ud835\\udc30 \\u2062 ( s , a ) \\u2265 Q \\ud835\\uded1 \\ud835\\udc28 \\u2062 \\ud835\\udc25 \\u2062 \\ud835\\udc1d \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\uded1 \\ud835\\udc27 \\ud835\\udc1e \\ud835\\udc30 \\ud835\\udc60 \\ud835\\udc4e superscript \\ud835\\udc44 subscript \\ud835\\uded1 \\ud835\\udc28 \\ud835\\udc25 \\ud835\\udc1d \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{new}}}(s,a)\\\\geq Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) \\u2265 italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) when performing Algorithm 1 , \\u2200 s \\u2208 \\ud835\\udcae for-all \\ud835\\udc60 \\ud835\\udcae \\\\forall s\\\\in\\\\mathcal{S} \\u2200 italic_s \\u2208 caligraphic_S and \\u2200 a \\u2208 \\ud835\\udc9c for-all \\ud835\\udc4e \\ud835\\udc9c \\\\forall a\\\\in\\\\mathcal{A} \\u2200 italic_a \\u2208 caligraphic_A if and only if the reward operator family \\u2131 = { \\u2131 r , \\u2131 g } \\u2131 subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}=\\\\left\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\right\\\\} caligraphic_F = { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } satisfies the both 5.3 . Proof : We recall that { \\u2131 r , \\u2131 g } subscript \\u2131 \\ud835\\udc5f subscript \\u2131 \\ud835\\udc54 \\\\left\\\\{\\\\mathcal{F}_{r},\\\\mathcal{F}_{g}\\\\right\\\\} { caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT } are two operators defined as r ~ \\u2062 ( \\u03c4 ) := \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) assign ~ \\ud835\\udc5f \\ud835\\udf0f \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f \\\\widetilde{r}(\\\\tau):=\\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right) over~ start_ARG italic_r end_ARG ( italic_\\u03c4 ) := caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) and g ~ i \\u2062 ( \\u03c4 ) := \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) assign superscript ~ \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f \\\\widetilde{g}^{i}(\\\\tau):=\\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau\\\\right) over~ start_ARG italic_g end_ARG start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ( italic_\\u03c4 ) := caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) , respectively. Suppose 1 holds. Since the two optimization objectives in policy updating, i.e., max \\u2062 \\ud835\\udd3c \\u2062 [ \\u2131 r \\u22c5 p \\u2062 ( \\ud835\\udcaa r | \\u03c4 ) ] max \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc5f \\ud835\\udc5d conditional subscript \\ud835\\udcaa \\ud835\\udc5f \\ud835\\udf0f {\\\\rm{max}}\\\\mathbb{E}[\\\\mathcal{F}_{r}\\\\cdot p\\\\left(\\\\mathcal{O}_{r}|\\\\tau\\\\right)] roman_max blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_\\u03c4 ) ] and min \\u2062 \\ud835\\udd3c \\u2062 [ \\u2131 g \\u22c5 p \\u2062 ( \\ud835\\udcaa g i | \\u03c4 ) ] min \\ud835\\udd3c delimited-[] \\u22c5 subscript \\u2131 \\ud835\\udc54 \\ud835\\udc5d conditional subscript \\ud835\\udcaa subscript \\ud835\\udc54 \\ud835\\udc56 \\ud835\\udf0f {\\\\rm{min}}\\\\mathbb{E}[\\\\mathcal{F}_{g}\\\\cdot p\\\\left(\\\\mathcal{O}_{g_{i}}|\\\\tau% \\\\right)] roman_min blackboard_E [ caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT \\u22c5 italic_p ( caligraphic_O start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT | italic_\\u03c4 ) ] (see Section 4.2 ), and p \\u2062 ( \\ud835\\udcaa | \\u03c4 ) \\ud835\\udc5d conditional \\ud835\\udcaa \\ud835\\udf0f p\\\\left(\\\\mathcal{O}|\\\\tau\\\\right) italic_p ( caligraphic_O | italic_\\u03c4 ) is defined on ( 0 , 1 ] 0 1 (0,1] ( 0 , 1 ] , we can conclude the both 5.3 that ( i ) \\u2131 r subscript \\u2131 \\ud835\\udc5f \\\\mathcal{F}_{r} caligraphic_F start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is monotonically increasing and continuously defined on ( 0 , 1 ] 0 1 (0,1] ( 0 , 1 ] , and the range covers [ r min , r max ] subscript \\ud835\\udc5f subscript \\ud835\\udc5f [r_{\\\\min},r_{\\\\max}] [ italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] ; ( ii ) \\u2131 g subscript \\u2131 \\ud835\\udc54 \\\\mathcal{F}_{g} caligraphic_F start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT is monotonically decreasing and continuously defined on ( 0 , 1 ] 0 1 (0,1] ( 0 , 1 ] , and the range covers [ r min , r max ] subscript \\ud835\\udc5f subscript \\ud835\\udc5f [r_{\\\\min},r_{\\\\max}] [ italic_r start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ] . Then based on Equation 6 , there exists: V \\u03c0 \\u2062 ( s t ) superscript \\ud835\\udc49 \\ud835\\udf0b subscript \\ud835\\udc60 \\ud835\\udc61 \\\\displaystyle V^{\\\\pi}(s_{t}) italic_V start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = \\ud835\\udd3c \\u2062 [ Q \\u2062 ( s t , \\u03c0 \\u2062 ( s t ) ) ] \\u2264 max a \\u2032 \\u2208 \\ud835\\udc9c \\u2062 \\ud835\\udd3c \\u2062 [ Q \\u2062 ( s t , a \\u2032 ) ] absent \\ud835\\udd3c delimited-[] \\ud835\\udc44 subscript \\ud835\\udc60 \\ud835\\udc61 \\ud835\\udf0b subscript \\ud835\\udc60 \\ud835\\udc61 superscript \\ud835\\udc4e \\u2032 \\ud835\\udc9c max \\ud835\\udd3c delimited-[] Q subscript s t superscript a \\u2032 \\\\displaystyle=\\\\mathbb{E}[{Q(s_{t},\\\\pi(s_{t}))}]\\\\leq\\\\underset{a^{\\\\prime}\\\\in% \\\\mathcal{A}}{\\\\rm{max}}\\\\mathbb{E}[{Q(s_{t},a^{\\\\prime})}] = blackboard_E [ italic_Q ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03c0 ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] \\u2264 start_UNDERACCENT italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT \\u2208 caligraphic_A end_UNDERACCENT start_ARG roman_max end_ARG blackboard_E [ roman_Q ( roman_s start_POSTSUBSCRIPT roman_t end_POSTSUBSCRIPT , roman_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] (13) = \\ud835\\udd3c \\u2062 [ Q \\u2062 ( s t , \\u03c0 \\u2032 \\u2062 ( s t ) ) ] absent \\ud835\\udd3c delimited-[] \\ud835\\udc44 subscript \\ud835\\udc60 \\ud835\\udc61 superscript \\ud835\\udf0b \\u2032 subscript \\ud835\\udc60 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}[{Q(s_{t},{\\\\pi^{\\\\prime}}(s_{t}))}] = blackboard_E [ italic_Q ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03c0 start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] where \\ud835\\udd3c \\u03c0 \\u2062 [ \\u22c5 ] = \\u2211 a \\u2208 A \\ud835\\udf45 \\u2062 ( a | s ) \\u2062 [ \\u22c5 ] subscript \\ud835\\udd3c \\ud835\\udf0b delimited-[] \\u22c5 subscript \\ud835\\udc4e \\ud835\\udc34 \\ud835\\udf45 conditional \\ud835\\udc4e \\ud835\\udc60 delimited-[] \\u22c5 \\\\mathbb{E}_{\\\\pi}[\\\\cdot]=\\\\sum_{a\\\\in A}\\\\bm{\\\\pi}(a|s)[\\\\cdot] blackboard_E start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT [ \\u22c5 ] = \\u2211 start_POSTSUBSCRIPT italic_a \\u2208 italic_A end_POSTSUBSCRIPT bold_italic_\\u03c0 ( italic_a | italic_s ) [ \\u22c5 ] , and V \\u03c0 \\u2062 ( s ) = \\ud835\\udd3c \\u03c0 \\u2062 \\ud835\\udd3c \\u2062 [ Z k \\u2062 ( s , a ) ] superscript \\ud835\\udc49 \\ud835\\udf0b \\ud835\\udc60 subscript \\ud835\\udd3c \\ud835\\udf0b \\ud835\\udd3c delimited-[] subscript \\ud835\\udc4d \\ud835\\udc58 \\ud835\\udc60 \\ud835\\udc4e V^{\\\\pi}(s)=\\\\mathbb{E}_{\\\\pi}\\\\mathbb{E}[Z_{k}(s,a)] italic_V start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT ( italic_s ) = blackboard_E start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT blackboard_E [ italic_Z start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_s , italic_a ) ] is the value function. According to Equation 13 and Equation 6 , it yields: Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 \\\\displaystyle Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}} italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s t , \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s t ) ) absent superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 subscript \\ud835\\udc60 \\ud835\\udc61 \\\\displaystyle=Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s_{t},\\\\bm{\\\\pi}_{\\\\bm{old}}(s_{t})) = italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) (14) = r t + 1 + \\u03b3 \\u2062 \\ud835\\udd3c s t + 1 \\u2062 \\ud835\\udd3c \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s t + 1 , \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s t + 1 ) ) absent subscript \\ud835\\udc5f \\ud835\\udc61 1 \\ud835\\udefe subscript \\ud835\\udd3c subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udd3c subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\\\displaystyle=r_{t+1}+\\\\gamma\\\\mathbb{E}_{s_{t+1}}\\\\mathbb{E}_{\\\\bm{\\\\pi}_{\\\\bm{old}% }}Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s_{t+1},{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s_{t+1})) = italic_r start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT + italic_\\u03b3 blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT , bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) ) \\u2264 ( i ) \\u2062 r t + 1 + \\u03b3 \\u2062 \\ud835\\udd3c s t + 1 \\u2062 \\ud835\\udd3c \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 \\u2062 Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s t + 1 , \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 \\u2062 ( s t + 1 ) ) \\ud835\\udc56 subscript \\ud835\\udc5f \\ud835\\udc61 1 \\ud835\\udefe subscript \\ud835\\udd3c subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udd3c subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\\\displaystyle\\\\overset{(i)}{\\\\leq}r_{t+1}+\\\\gamma\\\\mathbb{E}_{s_{t+1}}\\\\mathbb{E}_{% \\\\bm{\\\\pi}_{\\\\bm{new}}}{Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s_{t+1},{\\\\bm{\\\\pi}_{\\\\bm{new}}}(s_{% t+1}))} start_OVERACCENT ( italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG italic_r start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT + italic_\\u03b3 blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT , bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) ) \\u2264 r t + 1 + \\ud835\\udd3c s t + 1 \\ud835\\udd3c \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 [ \\u03b3 r t + 2 \\\\displaystyle\\\\leq r_{t+1}+\\\\mathbb{E}_{s_{t+1}}\\\\mathbb{E}_{\\\\bm{\\\\pi}_{\\\\bm{new}}}% [\\\\gamma r_{t+2} \\u2264 italic_r start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT + blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_\\u03b3 italic_r start_POSTSUBSCRIPT italic_t + 2 end_POSTSUBSCRIPT + \\u03b3 2 \\ud835\\udd3c s t + 2 Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 ( s t + 2 , \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 ( s t + 2 ) ) | ] \\\\displaystyle+{\\\\gamma^{2}}\\\\mathbb{E}_{s_{t+2}}{Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s_{t+2}% ,{\\\\bm{\\\\pi}_{\\\\bm{new}}}(s_{t+2}))}|] + italic_\\u03b3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 2 end_POSTSUBSCRIPT , bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 2 end_POSTSUBSCRIPT ) ) | ] \\u2264 r t + 1 + \\ud835\\udd3c s t + 1 \\u2062 \\ud835\\udd3c \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 \\u2062 [ \\u03b3 \\u2062 r t + 2 + \\u03b3 2 \\u2062 r t + 3 + \\u2026 ] absent subscript \\ud835\\udc5f \\ud835\\udc61 1 subscript \\ud835\\udd3c subscript \\ud835\\udc60 \\ud835\\udc61 1 subscript \\ud835\\udd3c subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 delimited-[] \\ud835\\udefe subscript \\ud835\\udc5f \\ud835\\udc61 2 superscript \\ud835\\udefe 2 subscript \\ud835\\udc5f \\ud835\\udc61 3 \\u2026 \\\\displaystyle\\\\leq r_{t+1}+\\\\mathbb{E}_{s_{t+1}}\\\\mathbb{E}_{\\\\bm{\\\\pi}_{\\\\bm{new}}}% [\\\\gamma r_{t+2}+{\\\\gamma^{2}}r_{t+3}+...] \\u2264 italic_r start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT + blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_\\u03b3 italic_r start_POSTSUBSCRIPT italic_t + 2 end_POSTSUBSCRIPT + italic_\\u03b3 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT italic_t + 3 end_POSTSUBSCRIPT + \\u2026 ] = r t + 1 + \\ud835\\udd3c s t + 1 \\u2062 V \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 \\u2062 ( s t + 1 ) absent subscript \\ud835\\udc5f \\ud835\\udc61 1 subscript \\ud835\\udd3c subscript \\ud835\\udc60 \\ud835\\udc61 1 superscript \\ud835\\udc49 subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\\\displaystyle=r_{t+1}+\\\\mathbb{E}_{s_{t+1}}V^{\\\\bm{\\\\pi}_{\\\\bm{new}}}(s_{t+1}) = italic_r start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT + blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_V start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) = Q \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 absent superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 \\\\displaystyle=Q^{\\\\bm{\\\\pi}_{\\\\bm{new}}} = italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUPERSCRIPT where ( i ) \\ud835\\udc56 (i) ( italic_i ) relies on Equation 13 , and \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 \\\\bm{\\\\pi}_{\\\\bm{new}} bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT corresponds to the maximum Q \\ud835\\udc44 Q italic_Q in the Bellman function. Therefore, we have Q \\ud835\\udf45 \\ud835\\udc8f \\u2062 \\ud835\\udc86 \\u2062 \\ud835\\udc98 \\u2062 ( s , a ) \\u2265 Q \\ud835\\udf45 \\ud835\\udc90 \\u2062 \\ud835\\udc8d \\u2062 \\ud835\\udc85 \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8f \\ud835\\udc86 \\ud835\\udc98 \\ud835\\udc60 \\ud835\\udc4e superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc90 \\ud835\\udc8d \\ud835\\udc85 \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{new}}}(s,a)\\\\geq Q^{\\\\bm{\\\\pi}_{\\\\bm{old}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_n bold_italic_e bold_italic_w end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) \\u2265 italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_o bold_italic_l bold_italic_d end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) . \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Then we provide Lemma D.3 and the proof of Theorem 5.4 . Lemma D.3 . ( Bellemare et al. , 2017 ) : The Bellman operator \\ud835\\udcaf \\u03c0 superscript \\ud835\\udcaf \\ud835\\udf0b \\\\mathcal{T}^{\\\\pi} caligraphic_T start_POSTSUPERSCRIPT italic_\\u03c0 end_POSTSUPERSCRIPT is a p \\ud835\\udc5d p italic_p -contraction under the p \\ud835\\udc5d p italic_p -Wasserstein metric d - p subscript \\ud835\\udc51 \\ud835\\udc5d \\\\overset{-}{d}_{p} over- start_ARG italic_d end_ARG start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT . Theorem 5.4 . (Global Convergence): Given the policy in the i i i italic_i -th policy improvement \\ud835\\uded1 \\ud835\\udc22 superscript \\ud835\\uded1 \\ud835\\udc22 \\\\bm{\\\\pi}^{\\\\bm{i}} bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT , \\ud835\\uded1 \\ud835\\udc22 \\u2192 \\ud835\\uded1 \\u2217 \\u2192 superscript \\ud835\\uded1 \\ud835\\udc22 superscript \\ud835\\uded1 \\\\bm{\\\\pi}^{\\\\bm{i}}\\\\rightarrow\\\\bm{\\\\pi}^{*} bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT \\u2192 bold_italic_\\u03c0 start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT and i \\u2192 \\u221e \\u2192 i i\\\\rightarrow\\\\infty italic_i \\u2192 \\u221e , suppose 1 holds, there exists Q \\ud835\\udf45 \\u2217 \\u2062 ( s , a ) \\u2265 Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 superscript \\ud835\\udf45 \\ud835\\udc60 \\ud835\\udc4e superscript \\ud835\\udc44 superscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}^{*}}(s,a)\\\\geq Q^{\\\\bm{\\\\pi}^{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) \\u2265 italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies the both 5.3 . Proof : Since Proposition D.2 suggests Q \\ud835\\udf45 \\ud835\\udc8a + \\ud835\\udfcf \\u2062 ( s , a ) \\u2265 Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a 1 \\ud835\\udc60 \\ud835\\udc4e superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{i+1}}}(s,a)\\\\geq Q^{\\\\bm{\\\\pi}_{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i bold_+ bold_1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) \\u2265 italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) , the sequence Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) is monotonically increasing if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies the both 5.3 . Furthermore, Lemma D.3 implies that the the state-action distribution Z \\ud835\\udc4d Z italic_Z over \\u211d \\u211d \\\\mathbb{R} blackboard_R has bounded p \\ud835\\udc5d p italic_p -th moment, so the first moment of Z \\ud835\\udc4d Z italic_Z , i.e., Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) , is upper bounded. Therefore, the sequence Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) converges to an upper limit Q \\ud835\\udf45 \\u2217 \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{*}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT \\u2217 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) with \\u2200 s \\u2208 \\ud835\\udcae for-all \\ud835\\udc60 \\ud835\\udcae \\\\forall s\\\\in\\\\mathcal{S} \\u2200 italic_s \\u2208 caligraphic_S and \\u2200 a \\u2208 \\ud835\\udc9c for-all \\ud835\\udc4e \\ud835\\udc9c \\\\forall a\\\\in\\\\mathcal{A} \\u2200 italic_a \\u2208 caligraphic_A . \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 To prove Theorem 5.5 , we provide Lemma D.4 and its proof below. Lemma D.4 . (Convergence rate of neural TD learning): Let m \\ud835\\udc5a m italic_m be the width of the actor-critic networks, and Z t - = 1 N \\u2062 \\u2211 i = 1 N \\u03b4 q i \\u2062 ( \\ud835\\udc2c , \\ud835\\udc1a ) subscript \\ud835\\udc4d \\ud835\\udc61 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udeff subscript \\ud835\\udc5e \\ud835\\udc56 \\ud835\\udc2c \\ud835\\udc1a \\\\overset{-}{Z_{t}}=\\\\frac{1}{N}\\\\sum\\\\limits_{i=1}^{N}\\\\delta_{q_{i}(\\\\bm{s},\\\\bm{a})} over- start_ARG italic_Z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_\\u03b4 start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) end_POSTSUBSCRIPT be an estimator of Z t i subscript superscript \\ud835\\udc4d \\ud835\\udc56 \\ud835\\udc61 Z^{i}_{t} italic_Z start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Suppose 2 holds, In the TD learning, with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 , there exists \\u2016 \\u03a0 W 1 \\u2062 Z t - \\u2212 \\u03a0 W 1 \\u2062 Z t \\u2217 \\u2016 \\u2264 \\u0398 \\u2062 ( m \\u2212 H 4 ) + \\u0398 \\u2062 ( [ ( 1 \\u2212 \\u03b3 ) \\u2062 K ] \\u2212 1 2 \\u2062 [ 1 + log 1 2 \\u2061 \\u03b4 \\u2212 1 ] ) norm subscript \\u03a0 subscript \\ud835\\udc4a 1 subscript \\ud835\\udc4d \\ud835\\udc61 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript subscript \\ud835\\udc4d \\ud835\\udc61 \\u0398 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\u0398 superscript delimited-[] 1 \\ud835\\udefe \\ud835\\udc3e 1 2 delimited-[] 1 superscript 1 2 superscript \\ud835\\udeff 1 \\\\left\\\\|\\\\Pi_{W_{1}}\\\\overset{-}{Z_{t}}-\\\\Pi_{W_{1}}{Z_{t}^{*}}\\\\right\\\\|\\\\leq\\\\Theta(% m^{-\\\\frac{H}{4}})+\\\\Theta({[(1-\\\\gamma)K]^{-\\\\frac{1}{2}}}[1+\\\\log^{\\\\frac{1}{2}}% \\\\delta^{-1}]) \\u2225 roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT over- start_ARG italic_Z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG - roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2225 \\u2264 roman_\\u0398 ( italic_m start_POSTSUPERSCRIPT - divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) + roman_\\u0398 ( [ ( 1 - italic_\\u03b3 ) italic_K ] start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT [ 1 + roman_log start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT italic_\\u03b4 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ] ) (15) Proof : Utilizing Gluing Lemma (Villani, 2009 ; Clement & Desch, 2008 ) for Wasserstein distance W p subscript \\ud835\\udc4a \\ud835\\udc5d W_{p} italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , where we employ the 1 1 1 1 -Wasserstein distance W 1 subscript \\ud835\\udc4a 1 W_{1} italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and the one-dimensional quantile q t i , \\u2217 superscript subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc56 q_{t}^{i,*} italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i , \\u2217 end_POSTSUPERSCRIPT , we establish: \\u2016 \\u03a0 W 1 \\u2062 Z t - \\u2212 \\u03a0 W 1 \\u2062 Z t \\u2217 \\u2016 = \\u2211 i = 1 N \\u2016 q t i - \\u2212 q t i , \\u2217 \\u2016 norm subscript \\u03a0 subscript \\ud835\\udc4a 1 subscript \\ud835\\udc4d \\ud835\\udc61 subscript \\u03a0 subscript \\ud835\\udc4a 1 superscript subscript \\ud835\\udc4d \\ud835\\udc61 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc56 superscript subscript \\ud835\\udc5e \\ud835\\udc61 \\ud835\\udc56 \\\\displaystyle\\\\left\\\\|\\\\Pi_{W_{1}}\\\\overset{-}{Z_{t}}-\\\\Pi_{W_{1}}{Z_{t}^{*}}\\\\right% \\\\|{=}\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|\\\\overset{-}{q_{t}^{i}}-q_{t}^{i,*}\\\\right\\\\| \\u2225 roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT over- start_ARG italic_Z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG - roman_\\u03a0 start_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT \\u2225 = \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 over- start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG - italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i , \\u2217 end_POSTSUPERSCRIPT \\u2225 (16) = \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 absent superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle=\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta_{% K_{td}}^{Q})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q^{*}})\\\\right\\\\| = \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 \\u2264 \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) \\u2016 absent superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle\\\\leq\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\theta_{K_{td}}^{Q})-f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})\\\\right\\\\| \\u2264 \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) \\u2225 + \\u2211 i = 1 N \\u2016 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle+\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta% _{K_{td}}^{Q})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q^{*}})\\\\right\\\\| + \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 \\u2264 ( i ) \\u2062 \\u0398 \\u2062 ( m \\u2212 H 4 ) + \\u2211 i = 1 N \\u2016 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 \\ud835\\udc56 \\u0398 superscript \\ud835\\udc5a \\ud835\\udc3b 4 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle\\\\overset{(i)}{\\\\leq}\\\\Theta(m^{-\\\\frac{H}{4}})+\\\\sum\\\\limits_{i=1}^{N}% \\\\left\\\\|f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta_{K_{td}}^{Q})-f_{i}^{(H)}((\\\\bm{s},% \\\\bm{a}),\\\\theta^{Q^{*}})\\\\right\\\\| start_OVERACCENT ( italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG roman_\\u0398 ( italic_m start_POSTSUPERSCRIPT - divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) + \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 \\u2264 ( i \\u2062 i ) \\u2062 \\u0398 \\u2062 ( m \\u2212 H 4 ) + \\u0398 \\u2062 ( [ ( 1 \\u2212 \\u03b3 ) \\u2062 K t \\u2062 d ] \\u2212 1 2 \\u2062 [ 1 + log 1 2 \\u2061 \\u03b4 \\u2212 1 ] ) \\ud835\\udc56 \\ud835\\udc56 \\u0398 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\u0398 superscript delimited-[] 1 \\ud835\\udefe subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 1 2 delimited-[] 1 superscript 1 2 superscript \\ud835\\udeff 1 \\\\displaystyle\\\\overset{(ii)}{\\\\leq}\\\\Theta(m^{-\\\\frac{H}{4}})+\\\\Theta({[(1-\\\\gamma)K% _{td}]^{-\\\\frac{1}{2}}}[1+\\\\log^{\\\\frac{1}{2}}\\\\delta^{-1}]) start_OVERACCENT ( italic_i italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG roman_\\u0398 ( italic_m start_POSTSUPERSCRIPT - divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) + roman_\\u0398 ( [ ( 1 - italic_\\u03b3 ) italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT [ 1 + roman_log start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT italic_\\u03b4 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ] ) where H \\ud835\\udc3b H italic_H denotes the layers of the neural network. Suppose 2 holds. Then (i) follows from Lemma 5.1 in (Cai et al., 2019 ) , where each quantile represents as a form of local linearization (Koenker, 2005 ; Gannoun et al., 2007 ) : \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) \\u2016 2 \\u2264 1 m H \\u2062 \\u2211 i = 1 N b r superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 superscript norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 2 1 superscript \\ud835\\udc5a \\ud835\\udc3b superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udc4f \\ud835\\udc5f \\\\displaystyle\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta_{K% _{td}}^{Q})-f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})\\\\right\\\\|^{2}\\\\leq\\\\frac{1}{% m^{H}}\\\\sum\\\\limits_{i=1}^{N}b_{r} \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) \\u2225 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \\u2264 divide start_ARG 1 end_ARG start_ARG italic_m start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT (17) | [ ( \\ud835\\udfcf \\u2062 ( W i ( h ) \\u2062 x i ( h \\u2212 1 ) > 0 ) \\u2212 \\ud835\\udfcf \\u2062 ( W i ( 0 ) \\u2062 x i ( h \\u2212 1 ) > 0 ) ) \\u22c5 W i ( h ) \\u2062 x i ( h \\u2212 1 ) ] 2 | superscript delimited-[] \\u22c5 1 superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\u210e superscript subscript \\ud835\\udc65 \\ud835\\udc56 \\u210e 1 0 1 superscript subscript \\ud835\\udc4a \\ud835\\udc56 0 superscript subscript \\ud835\\udc65 \\ud835\\udc56 \\u210e 1 0 superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\u210e superscript subscript \\ud835\\udc65 \\ud835\\udc56 \\u210e 1 2 \\\\displaystyle\\\\left|[(\\\\mathbf{1}(W_{i}^{(h)}x_{i}^{(h-1)}>0)-\\\\mathbf{1}(W_{i}^{% (0)}x_{i}^{(h-1)}>0))\\\\cdot W_{i}^{(h)}x_{i}^{(h-1)}]^{2}\\\\right| | [ ( bold_1 ( italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h ) end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h - 1 ) end_POSTSUPERSCRIPT > 0 ) - bold_1 ( italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h - 1 ) end_POSTSUPERSCRIPT > 0 ) ) \\u22c5 italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h ) end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h - 1 ) end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT | \\u2264 4 \\u2062 C 0 m H \\u2062 \\u2211 i = 1 N [ \\u2211 r = 1 m \\ud835\\udfcf \\u2062 ( | W i , r ( 0 ) \\u2062 x i ( h \\u2212 1 ) | \\u2264 \\u2016 W i , r ( h ) \\u2212 W i , r ( 0 ) \\u2016 2 ) ] absent 4 subscript \\ud835\\udc36 0 superscript \\ud835\\udc5a \\ud835\\udc3b superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 delimited-[] superscript subscript \\ud835\\udc5f 1 \\ud835\\udc5a 1 superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f 0 superscript subscript \\ud835\\udc65 \\ud835\\udc56 \\u210e 1 subscript norm superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f \\u210e superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f 0 2 \\\\displaystyle\\\\leq\\\\frac{4C_{0}}{m^{H}}\\\\sum\\\\limits_{i=1}^{N}[\\\\sum\\\\limits_{r=1}^{% m}\\\\mathbf{1}(\\\\left|W_{i,r}^{(0)}x_{i}^{(h-1)}\\\\right|\\\\leq\\\\left\\\\|W_{i,r}^{(h)}-W% _{i,r}^{(0)}\\\\right\\\\|_{2})] \\u2264 divide start_ARG 4 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG start_ARG italic_m start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_r = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT bold_1 ( | italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h - 1 ) end_POSTSUPERSCRIPT | \\u2264 \\u2225 italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h ) end_POSTSUPERSCRIPT - italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ] \\u2264 4 \\u2062 C 0 m H \\u2062 ( \\u2211 r = 1 m \\u2016 W i , r ( h ) \\u2212 W i , r ( 0 ) \\u2016 2 2 ) 1 2 \\u2062 ( \\u2211 r = 1 m \\u2016 1 W i , r ( 0 ) \\u2016 2 2 ) 1 2 \\u2264 4 \\u2062 C 0 \\u2062 C 1 m H 2 absent 4 subscript \\ud835\\udc36 0 superscript \\ud835\\udc5a \\ud835\\udc3b superscript superscript subscript \\ud835\\udc5f 1 \\ud835\\udc5a superscript subscript norm superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f \\u210e superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f 0 2 2 1 2 superscript superscript subscript \\ud835\\udc5f 1 \\ud835\\udc5a superscript subscript norm 1 superscript subscript \\ud835\\udc4a \\ud835\\udc56 \\ud835\\udc5f 0 2 2 1 2 4 subscript \\ud835\\udc36 0 subscript \\ud835\\udc36 1 superscript \\ud835\\udc5a \\ud835\\udc3b 2 \\\\displaystyle\\\\leq\\\\frac{4C_{0}}{m^{H}}(\\\\sum\\\\limits_{r=1}^{m}\\\\left\\\\|W_{i,r}^{(h)% }-W_{i,r}^{(0)}\\\\right\\\\|_{2}^{2})^{\\\\frac{1}{2}}(\\\\sum\\\\limits_{r=1}^{m}\\\\left\\\\|% \\\\frac{1}{W_{i,r}^{(0)}}\\\\right\\\\|_{2}^{2})^{\\\\frac{1}{2}}\\\\leq\\\\frac{4C_{0}C_{1}}{m% ^{\\\\frac{H}{2}}} \\u2264 divide start_ARG 4 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG start_ARG italic_m start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT end_ARG ( \\u2211 start_POSTSUBSCRIPT italic_r = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT \\u2225 italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_h ) end_POSTSUPERSCRIPT - italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT ( \\u2211 start_POSTSUBSCRIPT italic_r = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT \\u2225 divide start_ARG 1 end_ARG start_ARG italic_W start_POSTSUBSCRIPT italic_i , italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 0 ) end_POSTSUPERSCRIPT end_ARG \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT \\u2264 divide start_ARG 4 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT end_ARG where the constant C 0 > 0 subscript \\ud835\\udc36 0 0 C_{0}>0 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 and C 1 > 0 subscript \\ud835\\udc36 1 0 C_{1}>0 italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0 . Thus we upper bound \\u2211 i = 1 N \\u2016 f i ( H ) \\u2212 f 0 , i ( H ) \\u2016 \\u2264 \\u0398 \\u2062 ( m \\u2212 H 4 ) superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\u0398 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}-f_{0,i}^{(H)}\\\\right\\\\|\\\\leq\\\\Theta(m^{-% \\\\frac{H}{4}}) \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT - italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT \\u2225 \\u2264 roman_\\u0398 ( italic_m start_POSTSUPERSCRIPT - divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) , which holds (i) in Equation 16 . Suppose 3 holds. Then (ii) follows from Lemma 1 in (Rahimi & Recht, 2008 ) , with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 , there exists: \\u2211 i = 1 N \\u2016 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc44 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta_% {K_{td}}^{Q})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q^{*}})\\\\right\\\\| \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 (18) \\u2264 1 1 \\u2212 \\u03b3 \\u2062 \\u2211 i = 1 N \\u2016 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d Q \\u03c0 ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 absent 1 1 \\ud835\\udefe superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 subscript \\ud835\\udc44 \\ud835\\udf0b superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle\\\\leq\\\\frac{1}{\\\\sqrt{1-\\\\gamma}}\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{0,i}^% {(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta_{K_{td}}^{Q_{\\\\pi}})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\theta^{Q^{*}})\\\\right\\\\| \\u2264 divide start_ARG 1 end_ARG start_ARG square-root start_ARG 1 - italic_\\u03b3 end_ARG end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q start_POSTSUBSCRIPT italic_\\u03c0 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 \\u2264 C 3 ( 1 \\u2212 \\u03b3 ) \\u2062 K t \\u2062 d \\u2062 ( 1 + log \\u2061 1 \\u03b4 ) absent subscript \\ud835\\udc36 3 1 \\ud835\\udefe subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 1 1 \\ud835\\udeff \\\\displaystyle\\\\leq\\\\frac{C_{3}}{\\\\sqrt{(1-\\\\gamma)K_{td}}}(1+\\\\sqrt{\\\\log{\\\\frac{1}{% \\\\delta}}}) \\u2264 divide start_ARG italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG ( 1 - italic_\\u03b3 ) italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_ARG end_ARG ( 1 + square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where (iii) holds, and therefore Equation 16 holds. \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Theorem 5.5 . (Global Convergence Rate): Let m m m italic_m and H H H italic_H be the width and the layer of the neural network, K t \\u2062 d = ( 1 \\u2212 \\u03b3 ) \\u2212 3 2 \\u2062 m H 2 subscript K t d superscript 1 \\u03b3 3 2 superscript m H 2 K_{td}=(1-\\\\gamma)^{-\\\\frac{3}{2}}m^{\\\\frac{H}{2}} italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT = ( 1 - italic_\\u03b3 ) start_POSTSUPERSCRIPT - divide start_ARG 3 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT be the iterations required for convergence of the distributional TD learning (defined in Equation 10 ), l Q = 1 T subscript l Q 1 T l_{Q}=\\\\frac{1}{\\\\sqrt{T}} italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_T end_ARG end_ARG be the policy update (in Line 4 of Algorithm 1 ) and \\ud835\\uded5 c = \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 ) subscript \\ud835\\uded5 c \\u0398 1 1 \\u03b3 T \\u0398 1 1 \\u03b3 T superscript m H 4 \\\\bm{\\\\tau}_{c}=\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}})+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)% Tm^{\\\\frac{H}{4}}}) bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG ) be the tolerance (in Line 3 of Algorithm 1 ). Suppose Assumptions 1-3 hold. There exists a global convergence rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) , and a sublinear rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) if the constraints are violated with an error of \\u0398 \\u2062 ( 1 / m H 4 ) \\u0398 1 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\Theta(1/{m^{\\\\frac{H}{4}}}) roman_\\u0398 ( 1 / italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) , with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 . Importantly, this conclusion holds if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies both 5.3 . Proof : Proposition D.2 suggests that the sequence Q \\ud835\\udf45 \\ud835\\udc8a \\u2062 ( s , a ) superscript \\ud835\\udc44 subscript \\ud835\\udf45 \\ud835\\udc8a \\ud835\\udc60 \\ud835\\udc4e Q^{\\\\bm{\\\\pi}_{\\\\bm{i}}}(s,a) italic_Q start_POSTSUPERSCRIPT bold_italic_\\u03c0 start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_s , italic_a ) achieves global convergence if and only if the reward operator family \\u2131 \\u2131 \\\\mathcal{F} caligraphic_F satisfies 5.3 . Then we let \\u25b3 \\u03b8 Q = \\u03b8 t + 1 Q \\u2212 \\u03b8 t Q subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 superscript subscript \\ud835\\udf03 \\ud835\\udc61 1 \\ud835\\udc44 superscript subscript \\ud835\\udf03 \\ud835\\udc61 \\ud835\\udc44 \\\\triangle_{\\\\theta^{Q}}=\\\\theta_{t+1}^{Q}-\\\\theta_{t}^{Q} \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = italic_\\u03b8 start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT - italic_\\u03b8 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT , and suppose the critic networks are H \\ud835\\udc3b H italic_H -layer neural networks. Based on Lemma 6.1 in (Kakade & Langford, 2002 ) , there exists ( 1 \\u2212 \\u03b3 ) \\u2062 [ \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 t ) ] 1 \\ud835\\udefe delimited-[] subscript \\ud835\\udca5 \\ud835\\udc5f superscript \\ud835\\udf45 subscript \\ud835\\udca5 \\ud835\\udc5f subscript \\ud835\\udf45 \\ud835\\udc61 \\\\displaystyle(1-\\\\gamma)[\\\\mathcal{J}_{r}(\\\\bm{\\\\pi^{*}})-{\\\\mathcal{J}_{r}}(\\\\bm{% \\\\pi}_{t})] ( 1 - italic_\\u03b3 ) [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] (19) = \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 \\ud835\\udd3c \\u2062 Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) ] absent \\ud835\\udd3c delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 \\ud835\\udd3c subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 \\\\displaystyle=\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-\\\\mathbb{E}Q_{\\\\pi_{t}}(\\\\bm{% s},\\\\bm{a}^{\\\\prime})] = blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - blackboard_E italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] = \\ud835\\udd3c \\u2062 [ \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2212 \\ud835\\udd3c \\u2062 [ \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u03b8 Q ) T ] ] \\u2062 \\u25b3 \\u03b8 Q absent \\ud835\\udd3c delimited-[] subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T \\ud835\\udd3c delimited-[] subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle=\\\\mathbb{E}[\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{% \\\\mathrm{T}}-\\\\mathbb{E}[\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}^{\\\\prime}),\\\\theta^% {Q})^{\\\\mathrm{T}}]]\\\\triangle_{\\\\theta^{Q}} = blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT - blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT ] ] \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT + \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] \\ud835\\udd3c delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle\\\\ +\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-\\\\nabla_{\\\\theta}f^{(H)}((% \\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}] + blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] + \\ud835\\udd3c \\u2062 [ \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q \\u2212 Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) ] \\ud835\\udd3c delimited-[] subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 \\\\displaystyle\\\\ +\\\\mathbb{E}[\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}^{\\\\prime}),% \\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}-Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a}^{% \\\\prime})] + blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] = 1 l Q [ l Q \\ud835\\udd3c [ \\u2207 \\u03b8 log ( \\ud835\\udf45 t ( \\ud835\\udc82 | \\ud835\\udc94 ) ) T ] \\u25b3 \\u03b8 Q \\u2212 l Q 2 \\u2062 \\u2112 f 2 \\u2225 \\u25b3 \\u03b8 Q \\u2225 2 2 ] \\\\displaystyle=\\\\frac{1}{l_{Q}}\\\\big{[}l_{Q}\\\\mathbb{E}[\\\\nabla_{\\\\theta}\\\\log(\\\\bm{% \\\\pi}_{t}(\\\\bm{a}|\\\\bm{s}))^{\\\\mathrm{T}}]\\\\triangle_{\\\\theta^{Q}}-\\\\frac{l_{Q}^{2}% \\\\mathcal{L}_{f}}{2}\\\\left\\\\|\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\|_{2}^{2}\\\\big{]} = divide start_ARG 1 end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT end_ARG [ italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT roman_log ( bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_a | bold_italic_s ) ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT ] \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG \\u2225 \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] + \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] + l Q \\u2062 \\u2112 f 2 \\u2062 \\u2016 \\u25b3 \\u03b8 Q \\u2016 2 2 \\ud835\\udd3c delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc59 \\ud835\\udc44 subscript \\u2112 \\ud835\\udc53 2 superscript subscript norm subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 2 \\\\displaystyle\\\\ +\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-\\\\nabla_{\\\\theta}f^{(H)}((% \\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}]+\\\\frac{l_{Q}% \\\\mathcal{L}_{f}}{2}\\\\left\\\\|\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\|_{2}^{2} + blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] + divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG \\u2225 \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \\ud835\\udd3c \\u2062 [ \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q \\u2212 Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) ] \\ud835\\udd3c delimited-[] subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 \\\\displaystyle\\\\ +\\\\mathbb{E}[\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}^{\\\\prime}),% \\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}-Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a}^{% \\\\prime})] + blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] \\u2264 ( i ) \\u2062 1 l Q \\u2062 \\ud835\\udd3c \\u2062 [ log \\u2061 ( \\ud835\\udf45 t + 1 \\u2062 ( \\ud835\\udc82 | \\ud835\\udc94 ) \\ud835\\udf45 t \\u2062 ( \\ud835\\udc82 | \\ud835\\udc94 ) ) ] + l Q \\u2062 \\u2112 f 2 \\u2062 \\u2016 \\u25b3 \\u03b8 Q \\u2016 2 2 \\ud835\\udc56 1 subscript \\ud835\\udc59 \\ud835\\udc44 \\ud835\\udd3c delimited-[] subscript \\ud835\\udf45 \\ud835\\udc61 1 conditional \\ud835\\udc82 \\ud835\\udc94 subscript \\ud835\\udf45 \\ud835\\udc61 conditional \\ud835\\udc82 \\ud835\\udc94 subscript \\ud835\\udc59 \\ud835\\udc44 subscript \\u2112 \\ud835\\udc53 2 superscript subscript norm subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 2 \\\\displaystyle\\\\overset{(i)}{\\\\leq}\\\\frac{1}{l_{Q}}\\\\mathbb{E}[\\\\log(\\\\frac{\\\\bm{\\\\pi}_% {t+1}(\\\\bm{a}|\\\\bm{s})}{\\\\bm{\\\\pi}_{t}(\\\\bm{a}|\\\\bm{s})})]+\\\\frac{l_{Q}\\\\mathcal{L}_{f% }}{2}\\\\left\\\\|\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\|_{2}^{2} start_OVERACCENT ( italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG divide start_ARG 1 end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT end_ARG blackboard_E [ roman_log ( divide start_ARG bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ( bold_italic_a | bold_italic_s ) end_ARG start_ARG bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_a | bold_italic_s ) end_ARG ) ] + divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG \\u2225 \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) ] 2 \\ud835\\udd3c superscript delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\displaystyle\\\\ +\\\\sqrt{\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-f^{(H)}((\\\\bm{s},% \\\\bm{a}),\\\\triangle_{\\\\theta^{Q}})]^{2}} + square-root start_ARG blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + \\ud835\\udd3c \\u2062 [ f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] 2 \\ud835\\udd3c superscript delimited-[] superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\displaystyle\\\\ +\\\\sqrt{\\\\mathbb{E}[f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_{\\\\theta^{Q}% })-\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{% \\\\theta^{Q}}]^{2}} + square-root start_ARG blackboard_E [ italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + \\ud835\\udd3c \\u2062 [ \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q \\u2212 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u25b3 \\u03b8 Q ) ] 2 \\ud835\\udd3c superscript delimited-[] subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\displaystyle\\\\ +\\\\sqrt{\\\\mathbb{E}[\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}^{\\\\prime% }),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}-f^{(H)}((\\\\bm{s},\\\\bm{a}^{% \\\\prime}),\\\\triangle_{\\\\theta^{Q}})]^{2}} + square-root start_ARG blackboard_E [ \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + \\ud835\\udd3c \\u2062 [ f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) , \\u25b3 \\u03b8 Q ) \\u2212 Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 \\u2032 ) ] 2 \\ud835\\udd3c superscript delimited-[] superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 superscript \\ud835\\udc82 \\u2032 2 \\\\displaystyle\\\\ +\\\\sqrt{\\\\mathbb{E}[f^{(H)}((\\\\bm{s},\\\\bm{a}^{\\\\prime}),\\\\triangle_{% \\\\theta^{Q}})-Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a}^{\\\\prime})]^{2}} + square-root start_ARG blackboard_E [ italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a start_POSTSUPERSCRIPT \\u2032 end_POSTSUPERSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG = 1 l Q [ \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t ) ] \\u2212 \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t + 1 ) ] ] \\\\displaystyle\\\\ =\\\\frac{1}{l_{Q}}\\\\big{[}\\\\mathbb{E}[\\\\mathcal{D}_{KL}(\\\\bm{\\\\pi^{*}}% ||\\\\bm{\\\\pi}_{t})]-\\\\mathbb{E}[\\\\mathcal{D}_{KL}(\\\\bm{\\\\pi^{*}}||\\\\bm{\\\\pi}_{t+1})]% \\\\big{]} = divide start_ARG 1 end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT end_ARG [ blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] - blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) ] ] + 2 \\u2062 \\ud835\\udd3c \\u2062 [ f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] 2 2 \\ud835\\udd3c superscript delimited-[] superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\displaystyle\\\\ +2\\\\sqrt{\\\\mathbb{E}[f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_{\\\\theta^{Q% }})-\\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{% \\\\theta^{Q}}]^{2}} + 2 square-root start_ARG blackboard_E [ italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + 2 \\u2062 \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) ] 2 + l Q \\u2062 \\u2112 f 2 \\u2062 \\u2016 \\u25b3 \\u03b8 Q \\u2016 2 2 2 \\ud835\\udd3c superscript delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 subscript \\ud835\\udc59 \\ud835\\udc44 subscript \\u2112 \\ud835\\udc53 2 superscript subscript norm subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 2 \\\\displaystyle\\\\ +2\\\\sqrt{\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-f^{(H)}((\\\\bm{s},% \\\\bm{a}),\\\\triangle_{\\\\theta^{Q}})]^{2}}+\\\\frac{l_{Q}\\\\mathcal{L}_{f}}{2}\\\\left\\\\|% \\\\triangle_{\\\\theta^{Q}}\\\\right\\\\|_{2}^{2} + 2 square-root start_ARG blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG \\u2225 \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT where (i) follows from the \\u2112 f subscript \\u2112 \\ud835\\udc53 \\\\mathcal{L}_{f} caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT -Lipschitz property of log \\u2061 ( \\ud835\\udf45 t \\u2062 ( \\ud835\\udc82 | \\ud835\\udc94 ) ) subscript \\ud835\\udf45 \\ud835\\udc61 conditional \\ud835\\udc82 \\ud835\\udc94 \\\\log(\\\\bm{\\\\pi}_{t}(\\\\bm{a}|\\\\bm{s})) roman_log ( bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_a | bold_italic_s ) ) . Suppose 2 holds. Next, we upper bound the term \\ud835\\udd3c \\u2062 [ f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] 2 \\ud835\\udd3c superscript delimited-[] superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\sqrt{\\\\mathbb{E}[f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_{\\\\theta^{Q}})-\\\\nabla_{% \\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}]% ^{2}} square-root start_ARG blackboard_E [ italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG as shown below. \\ud835\\udd3c \\u2062 [ f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q ] 2 \\ud835\\udd3c superscript delimited-[] superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\u2207 \\ud835\\udf03 superscript \\ud835\\udc53 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\displaystyle\\\\sqrt{\\\\mathbb{E}[f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_{\\\\theta^{Q}})-% \\\\nabla_{\\\\theta}f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{% \\\\theta^{Q}}]^{2}} square-root start_ARG blackboard_E [ italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG (20) = \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u2062 \\u25b3 \\u03b8 Q \\u2016 absent superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 subscript \\u2207 \\ud835\\udf03 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b superscript \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 \\ud835\\udc44 T subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle=\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\triangle_{\\\\theta^{Q}})-\\\\nabla_{\\\\theta}f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})% ^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\| = \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 \\u2264 \\u2211 i = 1 N [ \\u2225 f i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 \\u2207 \\u03b8 f 0 , i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u25b3 \\u03b8 Q \\u2225 \\\\displaystyle\\\\leq\\\\sum\\\\limits_{i=1}^{N}\\\\big{[}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}% ),\\\\triangle_{\\\\theta^{Q}})-\\\\nabla_{\\\\theta}f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^% {Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\| \\u2264 \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT [ \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 + \\u2225 \\u2207 \\u03b8 f 0 , i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u25b3 \\u03b8 Q \\u2212 \\u2207 \\u03b8 f i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q ) T \\u25b3 \\u03b8 Q \\u2225 ] \\\\displaystyle+\\\\left\\\\|\\\\nabla_{\\\\theta}f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q})^% {\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}-\\\\nabla_{\\\\theta}f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\theta^{Q})^{\\\\mathrm{T}}\\\\triangle_{\\\\theta^{Q}}\\\\right\\\\|\\\\big{]} + \\u2225 \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - \\u2207 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_T end_POSTSUPERSCRIPT \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT \\u2225 ] = 2 \\u2062 \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2212 f 0 , i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) \\u2016 absent 2 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 superscript subscript \\ud835\\udc53 0 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 \\\\displaystyle=2\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\triangle_{\\\\theta^{Q}})-f_{0,i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_{\\\\theta^{Q}})\\\\right\\\\| = 2 \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) - italic_f start_POSTSUBSCRIPT 0 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) \\u2225 \\u2264 ( i \\u2062 i ) \\u2062 4 \\u2062 C 0 \\u2062 C 1 m H 4 \\ud835\\udc56 \\ud835\\udc56 4 subscript \\ud835\\udc36 0 subscript \\ud835\\udc36 1 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\displaystyle\\\\overset{(ii)}{\\\\leq}\\\\frac{4\\\\sqrt{C_{0}C_{1}}}{m^{\\\\frac{H}{4}}} start_OVERACCENT ( italic_i italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG divide start_ARG 4 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG start_ARG italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG where (ii) follows from Equation 17 . Suppose 3 holds. Then, in order to upper bound \\ud835\\udd3c \\u2062 [ Q \\u03c0 t \\u2062 ( \\ud835\\udc94 , \\ud835\\udc82 ) \\u2212 f ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u25b3 \\u03b8 Q ) ] 2 \\ud835\\udd3c superscript delimited-[] subscript \\ud835\\udc44 subscript \\ud835\\udf0b \\ud835\\udc61 \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udc53 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 subscript \\u25b3 superscript \\ud835\\udf03 \\ud835\\udc44 2 \\\\sqrt{\\\\mathbb{E}[Q_{\\\\pi_{t}}(\\\\bm{s},\\\\bm{a})-f^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\triangle_% {\\\\theta^{Q}})]^{2}} square-root start_ARG blackboard_E [ italic_Q start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_s , bold_italic_a ) - italic_f start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , \\u25b3 start_POSTSUBSCRIPT italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG , taking expectation of Equation 19 from t = 0 \\ud835\\udc61 0 t=0 italic_t = 0 to T \\u2212 1 \\ud835\\udc47 1 T-1 italic_T - 1 , yields ( 1 \\u2212 \\u03b3 ) \\u2062 [ \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 ) ] ] 1 \\ud835\\udefe delimited-[] subscript \\ud835\\udca5 \\ud835\\udc5f superscript \\ud835\\udf45 \\ud835\\udd3c delimited-[] subscript \\ud835\\udca5 \\ud835\\udc5f \\ud835\\udf45 \\\\displaystyle(1-\\\\gamma)\\\\big{[}\\\\mathcal{J}_{r}(\\\\bm{\\\\pi^{*}})-\\\\mathbb{E}[{% \\\\mathcal{J}_{r}}(\\\\bm{\\\\pi})]\\\\big{]} ( 1 - italic_\\u03b3 ) [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - blackboard_E [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] ] (21) = ( 1 \\u2212 \\u03b3 ) \\u2062 1 T \\u2062 \\u2211 t = 0 T \\u2212 1 [ \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 t ) ] absent 1 \\ud835\\udefe 1 \\ud835\\udc47 superscript subscript \\ud835\\udc61 0 \\ud835\\udc47 1 delimited-[] subscript \\ud835\\udca5 \\ud835\\udc5f superscript \\ud835\\udf45 subscript \\ud835\\udca5 \\ud835\\udc5f subscript \\ud835\\udf45 \\ud835\\udc61 \\\\displaystyle=(1-\\\\gamma)\\\\frac{1}{T}\\\\sum\\\\limits_{t=0}^{T-1}[\\\\mathcal{J}_{r}(\\\\bm% {\\\\pi^{*}})-{\\\\mathcal{J}_{r}}(\\\\bm{\\\\pi}_{t})] = ( 1 - italic_\\u03b3 ) divide start_ARG 1 end_ARG start_ARG italic_T end_ARG \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] \\u2264 1 T [ 1 l Q \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t ) ] + 8 \\u2062 T \\u2062 C 0 \\u2062 C 1 m H 4 + T \\u2062 l Q \\u2062 \\u2112 f 2 d \\u03b8 2 \\\\displaystyle\\\\leq\\\\frac{1}{T}\\\\big{[}\\\\frac{1}{l_{Q}}\\\\mathbb{E}[\\\\mathcal{D}_{KL}(% \\\\bm{\\\\pi^{*}}||\\\\bm{\\\\pi}_{t})]+\\\\frac{8T\\\\sqrt{C_{0}C_{1}}}{m^{\\\\frac{H}{4}}}+\\\\frac% {Tl_{Q}\\\\mathcal{L}_{f}}{2}d_{\\\\theta}^{2} \\u2264 divide start_ARG 1 end_ARG start_ARG italic_T end_ARG [ divide start_ARG 1 end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT end_ARG blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] + divide start_ARG 8 italic_T square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG start_ARG italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG + divide start_ARG italic_T italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG italic_d start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2 \\u2211 t = 0 T \\u2212 1 \\u2211 i = 1 N \\u2225 f i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 t + 1 Q \\u2212 \\u03b8 t Q ) \\u2212 f i ( H ) ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2225 ] \\\\displaystyle+2\\\\sum\\\\limits_{t=0}^{T-1}\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}(% (\\\\bm{s},\\\\bm{a}),\\\\theta_{t+1}^{Q}-\\\\theta_{t}^{Q})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),% \\\\theta^{Q^{*}})\\\\right\\\\|\\\\big{]} + 2 \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T - 1 end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT - italic_\\u03b8 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 ] = \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t ) ] l Q \\u2062 T + 8 \\u2062 C 0 \\u2062 C 1 m H 4 + l Q \\u2062 \\u2112 f 2 \\u2062 d \\u03b8 2 \\\\displaystyle=\\\\frac{\\\\mathbb{E}[\\\\mathcal{D}_{KL}(\\\\bm{\\\\pi^{*}}||\\\\bm{\\\\pi}_{t})]}{% l_{Q}T}+\\\\frac{8\\\\sqrt{C_{0}C_{1}}}{m^{\\\\frac{H}{4}}}+\\\\frac{l_{Q}\\\\mathcal{L}_{f}}% {2}d_{\\\\theta}^{2} = divide start_ARG blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT italic_T end_ARG + divide start_ARG 8 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG start_ARG italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG + divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG italic_d start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2 T \\u2062 \\u2211 i = 1 N \\u2016 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 K t \\u2062 d , t Q ) \\u2212 f i ( H ) \\u2062 ( ( \\ud835\\udc94 , \\ud835\\udc82 ) , \\u03b8 Q \\u2217 ) \\u2016 2 \\ud835\\udc47 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 norm superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript subscript \\ud835\\udf03 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 \\ud835\\udc61 \\ud835\\udc44 superscript subscript \\ud835\\udc53 \\ud835\\udc56 \\ud835\\udc3b \\ud835\\udc94 \\ud835\\udc82 superscript \\ud835\\udf03 superscript \\ud835\\udc44 \\\\displaystyle\\\\ +\\\\frac{2}{T}\\\\sum\\\\limits_{i=1}^{N}\\\\left\\\\|f_{i}^{(H)}((\\\\bm{s},\\\\bm% {a}),\\\\theta_{K_{td},t}^{Q})-f_{i}^{(H)}((\\\\bm{s},\\\\bm{a}),\\\\theta^{Q^{*}})\\\\right\\\\| + divide start_ARG 2 end_ARG start_ARG italic_T end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \\u2225 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT , italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) - italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_H ) end_POSTSUPERSCRIPT ( ( bold_italic_s , bold_italic_a ) , italic_\\u03b8 start_POSTSUPERSCRIPT italic_Q start_POSTSUPERSCRIPT \\u2217 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) \\u2225 \\u2264 ( i \\u2062 i \\u2062 i ) \\u2062 \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t ) ] l Q \\u2062 T + 8 \\u2062 C 0 \\u2062 C 1 m H 4 + l Q \\u2062 \\u2112 f 2 \\u2062 d \\u03b8 2 \\\\displaystyle\\\\overset{(iii)}{\\\\leq}\\\\frac{\\\\mathbb{E}[\\\\mathcal{D}_{KL}(\\\\bm{\\\\pi^{*% }}||\\\\bm{\\\\pi}_{t})]}{l_{Q}T}+\\\\frac{8\\\\sqrt{C_{0}C_{1}}}{m^{\\\\frac{H}{4}}}+\\\\frac{l% _{Q}\\\\mathcal{L}_{f}}{2}d_{\\\\theta}^{2} start_OVERACCENT ( italic_i italic_i italic_i ) end_OVERACCENT start_ARG \\u2264 end_ARG divide start_ARG blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] end_ARG start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT italic_T end_ARG + divide start_ARG 8 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG start_ARG italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG + divide start_ARG italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG italic_d start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 \\u2062 C 0 \\u2062 C 1 T \\u2062 m H 4 + 2 \\u2062 C 3 T \\u2062 ( 1 \\u2212 \\u03b3 ) \\u2062 K t \\u2062 d \\u2062 ( 1 + log \\u2061 1 \\u03b4 ) 4 subscript \\ud835\\udc36 0 subscript \\ud835\\udc36 1 \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 2 subscript \\ud835\\udc36 3 \\ud835\\udc47 1 \\ud835\\udefe subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 1 1 \\ud835\\udeff \\\\displaystyle\\\\ +\\\\frac{4\\\\sqrt{C_{0}C_{1}}}{Tm^{\\\\frac{H}{4}}}+\\\\frac{2C_{3}}{T% \\\\sqrt{(1-\\\\gamma)K_{td}}}(1+\\\\sqrt{\\\\log{\\\\frac{1}{\\\\delta}}}) + divide start_ARG 4 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG end_ARG start_ARG italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG + divide start_ARG 2 italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_T square-root start_ARG ( 1 - italic_\\u03b3 ) italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT end_ARG end_ARG ( 1 + square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where (iii) follows from Lemma D.4 ( Equation 16 ). Thus, substituting K t \\u2062 d = ( 1 \\u2212 \\u03b3 ) \\u2212 1 \\u2062 m H 2 subscript \\ud835\\udc3e \\ud835\\udc61 \\ud835\\udc51 superscript 1 \\ud835\\udefe 1 superscript \\ud835\\udc5a \\ud835\\udc3b 2 K_{td}=(1-\\\\gamma)^{-1}m^{\\\\frac{H}{2}} italic_K start_POSTSUBSCRIPT italic_t italic_d end_POSTSUBSCRIPT = ( 1 - italic_\\u03b3 ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT and l Q = \\u0398 \\u2062 ( 1 / T ) subscript \\ud835\\udc59 \\ud835\\udc44 \\u0398 1 \\ud835\\udc47 l_{Q}=\\\\Theta(1/\\\\sqrt{T}) italic_l start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT = roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) into Equation 21 , with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 , yields: \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 r \\u2062 ( \\ud835\\udf45 ) ] \\u2264 C 5 \\u2062 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T + C 6 \\u2062 1 ( 1 \\u2212 \\u03b3 ) \\u2062 m H 4 subscript \\ud835\\udca5 \\ud835\\udc5f superscript \\ud835\\udf45 \\ud835\\udd3c delimited-[] subscript \\ud835\\udca5 \\ud835\\udc5f \\ud835\\udf45 subscript \\ud835\\udc36 5 1 1 \\ud835\\udefe \\ud835\\udc47 subscript \\ud835\\udc36 6 1 1 \\ud835\\udefe superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\displaystyle\\\\mathcal{J}_{r}(\\\\bm{\\\\pi^{*}})-\\\\mathbb{E}[{\\\\mathcal{J}_{r}}(\\\\bm{% \\\\pi})]\\\\leq C_{5}\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}}+C_{6}\\\\frac{1}{(1-\\\\gamma)m^{\\\\frac{% H}{4}}} caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - blackboard_E [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] \\u2264 italic_C start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG + italic_C start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG (22) + C 7 \\u2062 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 + 2 \\u2062 C 3 \\u2062 log \\u2061 1 \\u03b4 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 subscript \\ud835\\udc36 7 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 2 subscript \\ud835\\udc36 3 1 \\ud835\\udeff 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\displaystyle\\\\ +C_{7}\\\\frac{1}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}}+2C_{3}\\\\frac{\\\\sqrt{% \\\\log{\\\\frac{1}{\\\\delta}}}}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}} + italic_C start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG + 2 italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT divide start_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG \\u2264 \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 \\u2062 log \\u2061 1 \\u03b4 ) absent \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 1 \\ud835\\udeff \\\\displaystyle\\\\leq\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}})+\\\\Theta(\\\\frac{1}{(1-% \\\\gamma)Tm^{\\\\frac{H}{4}}}\\\\sqrt{\\\\log{\\\\frac{1}{\\\\delta}}}) \\u2264 roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where C 5 = \\ud835\\udd3c [ \\ud835\\udc9f K \\u2062 L ( \\ud835\\udf45 \\u2217 | | \\ud835\\udf45 t ) ] + \\u2112 f \\u2062 d \\u03b8 2 2 C_{5}=\\\\mathbb{E}[\\\\mathcal{D}_{KL}(\\\\bm{\\\\pi^{*}}||\\\\bm{\\\\pi}_{t})]+\\\\frac{\\\\mathcal{% L}_{f}d_{\\\\theta}^{2}}{2} italic_C start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = blackboard_E [ caligraphic_D start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT | | bold_italic_\\u03c0 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] + divide start_ARG caligraphic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG , C 6 = 8 \\u2062 C 0 \\u2062 C 1 subscript \\ud835\\udc36 6 8 subscript \\ud835\\udc36 0 subscript \\ud835\\udc36 1 C_{6}=8\\\\sqrt{C_{0}C_{1}} italic_C start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT = 8 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG and C 7 = 4 \\u2062 C 0 \\u2062 C 1 + 2 \\u2062 C 3 subscript \\ud835\\udc36 7 4 subscript \\ud835\\udc36 0 subscript \\ud835\\udc36 1 2 subscript \\ud835\\udc36 3 C_{7}=4\\\\sqrt{C_{0}C_{1}}+2C_{3} italic_C start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT = 4 square-root start_ARG italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG + 2 italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT . Therefore, there exists: \\ud835\\udca5 r ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udd3c [ \\ud835\\udca5 r ( \\\\displaystyle\\\\mathcal{J}_{r}(\\\\bm{\\\\pi^{*}})-\\\\mathbb{E}[{\\\\mathcal{J}_{r}}( caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - blackboard_E [ caligraphic_J start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( \\ud835\\udf45 ) ] \\u2264 \\u0398 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) \\\\displaystyle\\\\bm{\\\\pi})]\\\\leq\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}}) bold_italic_\\u03c0 ) ] \\u2264 roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) (23) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 \\u2062 log \\u2061 1 \\u03b4 ) \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 1 \\ud835\\udeff \\\\displaystyle+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}}\\\\sqrt{\\\\log{\\\\frac{1}{% \\\\delta}}}) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where Equation 23 suggests that there exists a global convergence rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) , with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 . Following Line 6 in Algorithm 1 and recalling Equation 19 , Equation 20 and Equation 21 , the convergence process is similarly stated for the constraint approximation \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) , \\u2200 i \\u2208 [ 1 , p ] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 for-all \\ud835\\udc56 1 \\ud835\\udc5d {\\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi}),\\\\ \\\\forall i\\\\in[1,p] caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) , \\u2200 italic_i \\u2208 [ 1 , italic_p ] here \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) ] \\u2212 \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 \\u2217 ) \\ud835\\udd3c delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 superscript \\ud835\\udf45 \\\\displaystyle\\\\mathbb{E}[{\\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi})]-\\\\mathcal{J}^{i}_{g}(% \\\\bm{\\\\pi^{*}}) blackboard_E [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] - caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) \\u2264 \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) absent \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 \\\\displaystyle\\\\leq\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}}) \\u2264 roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) (24) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 \\u2062 log \\u2061 1 \\u03b4 ) \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 1 \\ud835\\udeff \\\\displaystyle\\\\ +\\\\Theta(\\\\frac{1}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}}\\\\sqrt{\\\\log{\\\\frac{1}% {\\\\delta}}}) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) the constraint violation is then bounded below \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) ] \\u2212 \\ud835\\udc83 i \\u2264 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 \\u2217 ) \\u2212 \\ud835\\udc83 i ] + [ \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) ] \\u2212 \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 \\u2217 ) ] \\ud835\\udd3c delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 subscript \\ud835\\udc83 \\ud835\\udc56 delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 superscript \\ud835\\udf45 subscript \\ud835\\udc83 \\ud835\\udc56 delimited-[] \\ud835\\udd3c delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 superscript \\ud835\\udf45 \\\\displaystyle\\\\mathbb{E}[{\\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi})]-\\\\bm{b}_{i}\\\\leq\\\\big{[}% \\\\mathcal{J}^{i}_{g}(\\\\bm{\\\\pi^{*}})-\\\\bm{b}_{i}\\\\big{]}+\\\\big{[}\\\\mathbb{E}[{% \\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi})]-\\\\mathcal{J}^{i}_{g}(\\\\bm{\\\\pi^{*}})\\\\big{]} blackboard_E [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] - bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \\u2264 [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) - bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ] + [ blackboard_E [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] - caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) ] (25) \\u2264 \\ud835\\udf49 c + [ \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) ] \\u2212 \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 \\u2217 ) ] absent subscript \\ud835\\udf49 \\ud835\\udc50 delimited-[] \\ud835\\udd3c delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 superscript \\ud835\\udf45 \\\\displaystyle\\\\leq\\\\bm{\\\\tau}_{c}+\\\\big{[}\\\\mathbb{E}[{\\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi% })]-\\\\mathcal{J}^{i}_{g}(\\\\bm{\\\\pi^{*}})\\\\big{]} \\u2264 bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + [ blackboard_E [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] - caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 start_POSTSUPERSCRIPT bold_\\u2217 end_POSTSUPERSCRIPT ) ] \\u2264 \\ud835\\udf49 c + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 \\u2062 log \\u2061 1 \\u03b4 ) absent subscript \\ud835\\udf49 \\ud835\\udc50 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 1 \\ud835\\udeff \\\\displaystyle\\\\leq\\\\bm{\\\\tau}_{c}+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}})+\\\\Theta(% \\\\frac{1}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}}\\\\sqrt{\\\\log{\\\\frac{1}{\\\\delta}}}) \\u2264 bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where we have \\ud835\\udf49 c = \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 ) subscript \\ud835\\udf49 \\ud835\\udc50 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\bm{\\\\tau}_{c}=\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}})+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)% Tm^{\\\\frac{H}{4}}}) bold_italic_\\u03c4 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG ) , therefore, we obtain: \\ud835\\udd3c \\u2062 [ \\ud835\\udca5 g i \\u2062 ( \\ud835\\udf45 ) ] \\u2212 \\ud835\\udc83 \\ud835\\udd3c delimited-[] subscript superscript \\ud835\\udca5 \\ud835\\udc56 \\ud835\\udc54 \\ud835\\udf45 \\ud835\\udc83 \\\\displaystyle\\\\mathbb{E}[{\\\\mathcal{J}^{i}_{g}}(\\\\bm{\\\\pi})]-\\\\bm{b} blackboard_E [ caligraphic_J start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT ( bold_italic_\\u03c0 ) ] - bold_italic_b \\u2264 i \\u0398 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T ) \\\\displaystyle{}_{i}\\\\leq\\\\Theta(\\\\frac{1}{(1-\\\\gamma)\\\\sqrt{T}}) start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT \\u2264 roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) square-root start_ARG italic_T end_ARG end_ARG ) (26) + \\u0398 \\u2062 ( 1 ( 1 \\u2212 \\u03b3 ) \\u2062 T \\u2062 m H 4 \\u2062 log \\u2061 1 \\u03b4 ) \\u0398 1 1 \\ud835\\udefe \\ud835\\udc47 superscript \\ud835\\udc5a \\ud835\\udc3b 4 1 \\ud835\\udeff \\\\displaystyle+\\\\Theta(\\\\frac{1}{(1-\\\\gamma)Tm^{\\\\frac{H}{4}}}\\\\sqrt{\\\\log{\\\\frac{1}{% \\\\delta}}}) + roman_\\u0398 ( divide start_ARG 1 end_ARG start_ARG ( 1 - italic_\\u03b3 ) italic_T italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT end_ARG square-root start_ARG roman_log divide start_ARG 1 end_ARG start_ARG italic_\\u03b4 end_ARG end_ARG ) where Equation 26 suggests that there exists a sublinear rate of \\u0398 \\u2062 ( 1 / T ) \\u0398 1 \\ud835\\udc47 \\\\Theta(1/\\\\sqrt{T}) roman_\\u0398 ( 1 / square-root start_ARG italic_T end_ARG ) if the constraints are violated with an error of \\u0398 \\u2062 ( 1 / m H 4 ) \\u0398 1 superscript \\ud835\\udc5a \\ud835\\udc3b 4 \\\\Theta(1/{m^{\\\\frac{H}{4}}}) roman_\\u0398 ( 1 / italic_m start_POSTSUPERSCRIPT divide start_ARG italic_H end_ARG start_ARG 4 end_ARG end_POSTSUPERSCRIPT ) , with probability at least 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 . \\u25a0 \\u25a0 \\\\blacksquare \\u25a0 Appendix E Experiment Supplementary E.1 Experimental Setting The parameter setting of AWaVO is shown in Table 2 , and the technical specification of the quadrotor is shown in Table 3 . Table 2: Parameter Setting of AWaVO Parameters Definition Values l \\u03bc , c \\u2062 a \\u2062 r \\u2062 t subscript \\ud835\\udc59 \\ud835\\udf07 \\ud835\\udc50 \\ud835\\udc4e \\ud835\\udc5f \\ud835\\udc61 l_{\\\\mu,cart} italic_l start_POSTSUBSCRIPT italic_\\u03bc , italic_c italic_a italic_r italic_t end_POSTSUBSCRIPT Learning rate of actor in Cartpole (Xu et al., 2021 ) 0.0005 l \\u03b8 , c \\u2062 a \\u2062 r \\u2062 t subscript \\ud835\\udc59 \\ud835\\udf03 \\ud835\\udc50 \\ud835\\udc4e \\ud835\\udc5f \\ud835\\udc61 l_{\\\\theta,cart} italic_l start_POSTSUBSCRIPT italic_\\u03b8 , italic_c italic_a italic_r italic_t end_POSTSUBSCRIPT Learning rate of critic in Cartpole (Xu et al., 2021 ) 0.0005 l \\u03bc , a \\u2062 c \\u2062 r \\u2062 o subscript \\ud835\\udc59 \\ud835\\udf07 \\ud835\\udc4e \\ud835\\udc50 \\ud835\\udc5f \\ud835\\udc5c l_{\\\\mu,acro} italic_l start_POSTSUBSCRIPT italic_\\u03bc , italic_a italic_c italic_r italic_o end_POSTSUBSCRIPT Learning rate of actor in Acrobot (Xu et al., 2021 ) 0.005 l \\u03b8 , a \\u2062 c \\u2062 r \\u2062 o subscript \\ud835\\udc59 \\ud835\\udf03 \\ud835\\udc4e \\ud835\\udc50 \\ud835\\udc5f \\ud835\\udc5c l_{\\\\theta,acro} italic_l start_POSTSUBSCRIPT italic_\\u03b8 , italic_a italic_c italic_r italic_o end_POSTSUBSCRIPT Learning rate of critic in Acrobot (Xu et al., 2021 ) 0.005 l \\u03bc , g \\u2062 u \\u2062 a \\u2062 r \\u2062 d subscript \\ud835\\udc59 \\ud835\\udf07 \\ud835\\udc54 \\ud835\\udc62 \\ud835\\udc4e \\ud835\\udc5f \\ud835\\udc51 l_{\\\\mu,guard} italic_l start_POSTSUBSCRIPT italic_\\u03bc , italic_g italic_u italic_a italic_r italic_d end_POSTSUBSCRIPT Learning rate of actor in Walker and Drone (Zhao et al., 2023 ) 0.001 l \\u03b8 , g \\u2062 u \\u2062 a \\u2062 r \\u2062 d subscript \\ud835\\udc59 \\ud835\\udf03 \\ud835\\udc54 \\ud835\\udc62 \\ud835\\udc4e \\ud835\\udc5f \\ud835\\udc51 l_{\\\\theta,guard} italic_l start_POSTSUBSCRIPT italic_\\u03b8 , italic_g italic_u italic_a italic_r italic_d end_POSTSUBSCRIPT Learning rate of critic in Walker and Drone (Zhao et al., 2023 ) 0.001 \\u03bc \\ud835\\udf07 \\\\mu italic_\\u03bc Actor neural network: fully connected with H \\ud835\\udc3b H italic_H hidden layers ( m \\ud835\\udc5a m italic_m neurons per hidden layer) - \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 Critic neural network: fully connected with H \\ud835\\udc3b H italic_H hidden layers ( m \\ud835\\udc5a m italic_m neurons per hidden layer) - D \\ud835\\udc37 D italic_D Replay memory capacity 10 6 superscript 10 6 10^{6} 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT B \\ud835\\udc35 B italic_B Batch size 128 \\u03b3 \\ud835\\udefe \\\\gamma italic_\\u03b3 Discount rate 0.998 m \\ud835\\udc5a m italic_m the width of neural network 128 H \\ud835\\udc3b H italic_H the layer of neural network 2 T \\ud835\\udc47 T italic_T Length in each episode 500 N \\ud835\\udc41 N italic_N Time steps 20 Table 3: Technical Specification of Hardware No. Component Specific Model 1 Frame QAV250 2 Sensor - Depth Camera Intel RealSense D435i 3 Sensor - Down-view Rangefinder Holybro ST VL53L1X 4 Flight Controller Pixhawk 4 5 Motors T-Motor F60 Pro IV 1750KV 6 Electronic Speed Controller BLHeli-32bit 45A 3-6s 7 On-board Companion Computer DJI Manifold 2-c (CPU Model: Intel Core i7-8550U) 8 Mounts 3D Print for Sensors/ Computer/Controller/Battery E.2 Task Descriptions in the Simulated Platforms Acrobot and Cartpole tasks in OpenAI Gym. In Cartpole (Brockman et al., 2016 ) , the pole movement is constrained within the range of [ \\u2212 2.4 , 2.4 ] 2.4 2.4 [-2.4,2.4] [ - 2.4 , 2.4 ] . Each episode has a maximum length of 200 200 200 200 steps and is terminated if the angle of the pole exceeds 12 12 12 12 degrees. During training, the agent receives a reward of + 1 1 +1 + 1 for each step taken. However, it incurs a penalty of + 1 1 +1 + 1 if ( i ) it enters the areas [ \\u2212 2.4 , \\u2212 2.2 ] 2.4 2.2 [-2.4,-2.2] [ - 2.4 , - 2.2 ] , [ \\u2212 1.3 , \\u2212 1.1 ] 1.3 1.1 [-1.3,-1.1] [ - 1.3 , - 1.1 ] , [ \\u2212 0.1 , 0.1 ] 0.1 0.1 [-0.1,0.1] [ - 0.1 , 0.1 ] , [ 1.1 , 1.3 ] 1.1 1.3 [1.1,1.3] [ 1.1 , 1.3 ] , or [ 2.2 , 2.4 ] 2.2 2.4 [2.2,2.4] [ 2.2 , 2.4 ] , or ( ii ) the angle of the pole exceeds 6 6 6 6 degrees. In Acrobot (Brockman et al., 2016 ) , the agent is rewarded for swinging the end-effector at a height of 0.5 0.5 0.5 0.5 , where each episode has a maximum length of 500 500 500 500 steps. Conversely, it faces a penalty if ( i ) torque is applied to the joint when the first pendulum swings in an anticlockwise direction, or ( ii ) if the second pendulum swings in an anticlockwise direction with respect to the first pendulum. Walker and Drone tasks in GUARD. Walker (Zhao et al., 2023 ) , a bipedal robot, comprises four primary components: a torso, two thighs, two legs, and two feet. Notably, unlike the knee and ankle joints, each hip joint possesses three hinges in the x, y, and z coordinates, enabling versatile turning. Maintaining a fixed torso height, Walker achieves mobility through the control of 10 joint torques. Drone in GUARD (Zhao et al., 2023 ) is designed to emulate a quadrotor, simulating the interaction between the quadrotor and the air by applying four external forces to each of its propellers. These external forces are configured to counteract gravity when no control actions are applied. To maneuver in three-dimensional space, the Drone utilizes four additional control forces applied to its propellers. E.3 Further Details on Constraint Limit Setting In accordance with the benchmark (Xu et al., 2021 ) , we established the constraint limit as 50 50 50 50 in Acrobot, as depicted in Figure 3(a) . In the remaining scenarios, namely Cartpole in Figure 3(b) , Walker in Figure 3(c) , Drone in Figure 3(d) , and the real quadrotor in Figure 5 , the constraint limit serves as a lower boundary, indicating the level of tolerance the constraints can endure. The agent\\u2019s stable performance for specific tasks occurs when it operates below this constraint limit. We hypothesize that there may be potential benefits in establishing a fixed limit, b i subscript \\ud835\\udc4f \\ud835\\udc56 b_{i} italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , by decoupling the cumulative value into specific fixed limits. This is left for future work. E.4 Further Discussion on Probabilistic Interpretation of Sequential Decisions Curves in Figure 7 (a) and (b). The curves in Figure 7 (a), provided as a reference, give the estimated values of external aerodynamic forces (winds) in real-time. These estimates are derived from the signals collected from onboard sensors. In Figure 7 (b), the curves illustrate the quantitative impact of external forces L 0 subscript \\ud835\\udc3f 0 L_{0} italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT on current sequential decisions, specifically, the planned trajectory \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 . This impact is quantified as parts of pulse width modulation signals that are fed into the motors to either resist or cooperate with the measured (or identified) aerodynamic forces. Figure 7 (b) aims to quantitatively interpret and visually convey the decision-making process in response to external forces. Figure 7 (b) becomes particularly important when the agent makes sub-optimal decisions leading to events like quadrotor crashes or collisions. These curves prove valuable for interpreting and performing quantitative analyses of distinct environmental factors, such as winds and obstacles, allowing for an understanding of their magnitudes of influence on the current decision-making process. An instance to interpret Figure 7 (b). In the case of Reference State 02 (RS 02), located in an area with a combination of wind and obstacles, both aerodynamic effects (i.e., external forces) from winds and obstacles act simultaneously on the quadrotor. In Flight Task 3 (FT 3), represented by the red curve, we can observe the influence of external forces (i.e., aerodynamic effects from winds and obstacles) on the current trajectory planning decisions. The value is approximately 0.40 0.40 0.40 0.40 at RS 02, implying that the ongoing trajectory planning decisions have a \\u223c 40 % similar-to absent percent 40 \\\\sim 40\\\\% \\u223c 40 % probability of being influenced by the aerodynamic effects. Comparing FT 1 and FT 2, where the values at RS 02 are approximately 0.20 0.20 0.20 0.20 (FT 1) and 0.18 0.18 0.18 0.18 (FT 2), respectively, we can decouple the aerodynamic effects generated by the wind on the body (FT 1) and obstacles (FT 2). Quantitatively, at RS 02, situated in an area with a mix of wind and obstacles, the red p \\u2062 ( \\u03c4 | L 0 ) F \\u2062 T \\u2062 3 \\ud835\\udc5d subscript conditional \\ud835\\udf0f subscript \\ud835\\udc3f 0 \\ud835\\udc39 \\ud835\\udc47 3 p(\\\\tau|L_{0})_{FT3} italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_F italic_T 3 end_POSTSUBSCRIPT is approximately equal to the sum of p \\u2062 ( \\u03c4 | L 0 ) F \\u2062 T \\u2062 1 \\ud835\\udc5d subscript conditional \\ud835\\udf0f subscript \\ud835\\udc3f 0 \\ud835\\udc39 \\ud835\\udc47 1 p(\\\\tau|L_{0})_{FT1} italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_F italic_T 1 end_POSTSUBSCRIPT (only wind) and p \\u2062 ( \\u03c4 | L 0 ) F \\u2062 T \\u2062 2 \\ud835\\udc5d subscript conditional \\ud835\\udf0f subscript \\ud835\\udc3f 0 \\ud835\\udc39 \\ud835\\udc47 2 p(\\\\tau|L_{0})_{FT2} italic_p ( italic_\\u03c4 | italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_F italic_T 2 end_POSTSUBSCRIPT (only obstacles). E.5 Scalability To explore the full scalability of our methodology, we have implemented it on the Lorenz 96 system (Lorenz & Emanuel, 1998 ; Gorbach et al., 2017 ) , characterized by the following equations: d \\u2062 x i / d \\u2062 t = ( x i + 1 \\u2212 x i \\u2212 2 ) \\u22c5 x i \\u2212 1 \\u2212 x i + f \\u03b8 \\ud835\\udc51 subscript \\ud835\\udc65 \\ud835\\udc56 \\ud835\\udc51 \\ud835\\udc61 \\u22c5 subscript \\ud835\\udc65 \\ud835\\udc56 1 subscript \\ud835\\udc65 \\ud835\\udc56 2 subscript \\ud835\\udc65 \\ud835\\udc56 1 subscript \\ud835\\udc65 \\ud835\\udc56 subscript \\ud835\\udc53 \\ud835\\udf03 {dx_{i}}/{dt}=(x_{i+1}-x_{i-2})\\\\cdot x_{i-1}-x_{i}+f_{\\\\theta} italic_d italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_d italic_t = ( italic_x start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_i - 2 end_POSTSUBSCRIPT ) \\u22c5 italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT , where f \\u03b8 subscript \\ud835\\udc53 \\ud835\\udf03 f_{\\\\theta} italic_f start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT represents a scalar forcing parameter, and x \\u2212 1 = x I \\u2212 1 , x 0 = x I , x I + 1 = x 1 formulae-sequence subscript \\ud835\\udc65 1 subscript \\ud835\\udc65 \\ud835\\udc3c 1 formulae-sequence subscript \\ud835\\udc65 0 subscript \\ud835\\udc65 \\ud835\\udc3c subscript \\ud835\\udc65 \\ud835\\udc3c 1 subscript \\ud835\\udc65 1 x_{-1}=x_{I-1},x_{0}=x_{I},x_{I+1}=x_{1} italic_x start_POSTSUBSCRIPT - 1 end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT italic_I - 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_I + 1 end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , with I \\ud835\\udc3c I italic_I denoting the number of states in the deterministic system. This system serves as a simplified model for weather forecasting. We choose it as a versatile framework for expanding the number of states in our inference task. In our experiment, we range from 50 to 1000 states, with approximately one-third of the states randomly designated as unobserved. We show the results in Figure 8 and Figure 9 . Our methodology successfully infers a system with 1000 states in less than 400 seconds (shown in Figure 9 ). From visual inspection, we observe that the unobserved states are inferred, with the approximation error remaining consistent regardless of the problem\\u2019s dimensionality. Given that many real-world RL problems involve state spaces significantly larger than 1,000 states, our future work will explore such scalability concerns on larger models. Figure 8: Scalability performance on Lorenz 96 system (Lorenz & Emanuel, 1998 ; Gorbach et al., 2017 ) . Figure 9: Average RMSE and computation time of the unobserved state for scalability.\",\n          \"\\\\left[\\\\sum_{t=0}^{\\\\infty}\\\\gamma^{t}r(s_{t},a_{t})\\\\right]. italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] . (1) In this paper, we denote the current policy that is used to collect experience as \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT . 3.2 Analytical Gradients We assume that S \\ud835\\udc46 S italic_S and A \\ud835\\udc34 A italic_A are continuous, differentiable spaces, and P \\ud835\\udc43 P italic_P and r \\ud835\\udc5f r italic_r are also differentiable models. Then, our differentiable environment provides us with following analytical gradients of observation or reward at a later timestep with respect to the action at the previous timestep: \\u2202 s t + 1 + k \\u2202 a t , \\u2202 r t + k \\u2202 a t , subscript \\ud835\\udc60 \\ud835\\udc61 1 \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc61 subscript \\ud835\\udc5f \\ud835\\udc61 \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\frac{\\\\partial s_{t+1+k}}{\\\\partial a_{t}},\\\\frac{\\\\partial r_{t+k}}{\\\\partial a_{% t}}, divide start_ARG \\u2202 italic_s start_POSTSUBSCRIPT italic_t + 1 + italic_k end_POSTSUBSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG , divide start_ARG \\u2202 italic_r start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG , (2) where k \\u2265 0 \\ud835\\udc58 0 k\\\\geq 0 italic_k \\u2265 0 is an integer. With these basic analytical gradients, we can compute the gradient of certain advantage function, which we denote as \\u2202 A \\u2202 a \\ud835\\udc34 \\ud835\\udc4e \\\\frac{\\\\partial A}{\\\\partial a} divide start_ARG \\u2202 italic_A end_ARG start_ARG \\u2202 italic_a end_ARG . In this paper, we use Generalized Advantage Estimator (GAE) (Schulman et al., 2015b ) . See Appendix 7.2.1 for details. 3.3 Policy Update In this section, we discuss how we update policy in two different settings: the policy gradient method based on RP gradient and PPO. 3.3.1 RP Gradient To compute the RP gradient, we rely on the reparameterization trick (Kingma and Welling, 2013 ) . This trick requires us that we can sample an action a \\ud835\\udc4e a italic_a from \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT by sampling a random variable \\u03f5 italic-\\u03f5 \\\\epsilon italic_\\u03f5 from some other independent distribution q \\ud835\\udc5e q italic_q . To that end, we assume that we use a continuous differentiable bijective function g \\u03b8 \\u2062 ( s , \\u22c5 ) : \\u211d n \\u2192 \\u211d n : subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 \\u22c5 \\u2192 superscript \\u211d \\ud835\\udc5b superscript \\u211d \\ud835\\udc5b g_{\\\\theta}(s,\\\\cdot):\\\\mathbb{R}^{n}\\\\rightarrow\\\\mathbb{R}^{n} italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \\u2192 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT that maps \\u03f5 italic-\\u03f5 \\\\epsilon italic_\\u03f5 to an action a \\ud835\\udc4e a italic_a , where n \\ud835\\udc5b n italic_n is the action dimension. Then the following holds because of injectivity, | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | > 0 , \\u2200 \\u03f5 \\u2208 \\u211d n , formulae-sequence subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 0 for-all italic-\\u03f5 superscript \\u211d \\ud835\\udc5b \\\\Big{\\\\lvert}\\\\det(\\\\frac{\\\\partial g_{\\\\theta}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})\\\\Big% {\\\\rvert}>0,\\\\forall\\\\epsilon\\\\in\\\\mathbb{R}^{n}, | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | > 0 , \\u2200 italic_\\u03f5 \\u2208 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , (3) and we can define the following relationship. Definition 3.1 We define \\u03c0 \\u03b8 \\u225c g \\u03b8 normal-\\u225c subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc54 \\ud835\\udf03 \\\\pi_{\\\\theta}\\\\triangleq g_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT if following holds for an arbitrary open set T \\u03f5 \\u2282 \\u211d n subscript \\ud835\\udc47 italic-\\u03f5 superscript \\u211d \\ud835\\udc5b T_{\\\\epsilon}\\\\subset\\\\mathbb{R}^{n} italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT \\u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT : \\u222b T a \\u03c0 \\u03b8 \\u2062 ( s , a ) \\u2062 \\ud835\\udc51 a = \\u222b T \\u03f5 q \\u2062 ( \\u03f5 ) \\u2062 \\ud835\\udc51 \\u03f5 , subscript subscript \\ud835\\udc47 \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e subscript subscript \\ud835\\udc47 italic-\\u03f5 \\ud835\\udc5e italic-\\u03f5 differential-d italic-\\u03f5 \\\\int_{T_{a}}\\\\pi_{\\\\theta}(s,a)da=\\\\int_{T_{\\\\epsilon}}q(\\\\epsilon)d\\\\epsilon, \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_d italic_a = \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q ( italic_\\u03f5 ) italic_d italic_\\u03f5 , where T a = g \\u03b8 \\u2062 ( s , T \\u03f5 ) subscript \\ud835\\udc47 \\ud835\\udc4e subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc47 italic-\\u03f5 T_{a}=g_{\\\\theta}(s,T_{\\\\epsilon}) italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT ) . Lemma 3.2 If \\u03c0 \\u03b8 \\u225c g \\u03b8 normal-\\u225c subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc54 \\ud835\\udf03 \\\\pi_{\\\\theta}\\\\triangleq g_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT , \\u03c0 \\u03b8 \\u2062 ( s , a ) = q \\u2062 ( \\u03f5 ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 , subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\u22c5 \\ud835\\udc5e italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\pi_{\\\\theta}(s,a)=q(\\\\epsilon)\\\\cdot\\\\Big{\\\\lvert}{\\\\det(\\\\frac{\\\\partial g_{\\\\theta}(% s,\\\\epsilon)}{\\\\partial\\\\epsilon})}\\\\Big{\\\\rvert}^{-1}, italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) = italic_q ( italic_\\u03f5 ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , where a = g \\u03b8 \\u2062 ( s , \\u03f5 ) \\ud835\\udc4e subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 a=g_{\\\\theta}(s,\\\\epsilon) italic_a = italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) . The inverse is also true. Proof: See Appendix 7.1.1 . Specifically, we use q = \\ud835\\udca9 \\u2062 ( 0 , I ) \\ud835\\udc5e \\ud835\\udca9 0 \\ud835\\udc3c q=\\\\mathcal{N}(0,I) italic_q = caligraphic_N ( 0 , italic_I ) in this paper, and define g \\u03b8 subscript \\ud835\\udc54 \\ud835\\udf03 g_{\\\\theta} italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT as follows, g \\u03b8 \\u2062 ( s , \\u03f5 ) = \\u03bc \\u03b8 \\u2062 ( s ) + \\u03c3 \\u03b8 \\u2062 ( s ) \\u22c5 \\u03f5 ( \\u2016 \\u03c3 \\u03b8 \\u2062 ( s ) \\u2016 2 > 0 ) , subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udf07 \\ud835\\udf03 \\ud835\\udc60 \\u22c5 subscript \\ud835\\udf0e \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript norm subscript \\ud835\\udf0e \\ud835\\udf03 \\ud835\\udc60 2 0 g_{\\\\theta}(s,\\\\epsilon)=\\\\mu_{\\\\theta}(s)+\\\\sigma_{\\\\theta}(s)\\\\cdot\\\\epsilon\\\\quad({|% |\\\\sigma_{\\\\theta}(s)||}_{2}>0), italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) = italic_\\u03bc start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s ) + italic_\\u03c3 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s ) \\u22c5 italic_\\u03f5 ( | | italic_\\u03c3 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0 ) , which satisfies our assumption. With g \\u03b8 \\u2062 ( s , \\u03f5 ) subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 g_{\\\\theta}(s,\\\\epsilon) italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) and the analytical gradients from Equation 2 , we obtain RP gradient by directly differentiating the objective function in Equation 1 , which we use for gradient ascent. See Appendix 7.2.2 for details. 3.3.2 PPO PPO relies on the observation that we can evaluate a policy \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT with our current policy \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , using its advantage function A \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 A_{\\\\pi_{\\\\bar{\\\\theta}}} italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT as \\u03b7 \\u2062 ( \\u03c0 \\u03b8 ) = \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) + \\u222b s \\u03c1 \\u03c0 \\u03b8 \\u2062 ( s ) \\u2062 \\u222b a \\u03c0 \\u03b8 \\u2062 ( s , a ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) , \\ud835\\udf02 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle\\\\eta(\\\\pi_{\\\\theta})=\\\\eta(\\\\pi_{\\\\bar{\\\\theta}})+\\\\int_{s}\\\\rho_{\\\\pi_{% \\\\theta}}(s)\\\\int_{a}\\\\pi_{\\\\theta}(s,a)A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a), italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) + \\u222b start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) , where \\u03c1 \\u03c0 \\u03b8 \\u2062 ( s ) subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\\\rho_{\\\\pi_{\\\\theta}}(s) italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) is the discounted visitation frequencies. See (Kakade and Langford, 2002 ; Schulman et al., 2015a ) for the details. As far as the difference between \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT and \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT is sufficiently small, we can approximate \\u03c1 \\u03c0 \\u03b8 \\u2062 ( s ) subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\\\rho_{\\\\pi_{\\\\theta}}(s) italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) with \\u03c1 \\u03c0 \\u03b8 \\u00af \\u2062 ( s ) subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}}(s) italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) (Schulman et al., 2015a ) , and get following surrogate loss function: L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b8 ) = \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) + \\u222b s \\u03c1 \\u03c0 \\u03b8 \\u00af \\u2062 ( s ) \\u2062 \\u222b a \\u03c0 \\u03b8 \\u2062 ( s , a ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) . subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\theta})=\\\\eta(\\\\pi_{\\\\bar{\\\\theta}})+% \\\\int_{s}\\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}}(s)\\\\int_{a}\\\\pi_{\\\\theta}(s,a)A_{\\\\pi_{\\\\bar{% \\\\theta}}}(s,a). italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) + \\u222b start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) . (4) Note that we can estimate this loss function with Monte Carlo sampling as described in Appendix 7.2.3 . Since this is a local approximation, the difference between \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT and \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT must be small enough to get an accurate estimate. TRPO (Schulman et al., 2015a ) and PPO (Schulman et al., 2017 ) constrain the difference to be smaller than a certain threshold, and maximize the right term of ( 4 ). In particular, PPO restricts the ratio of probabilities \\u03c0 \\u03b8 \\u2062 ( s i , a i ) subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\pi_{\\\\theta}(s_{i},a_{i}) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i}) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) for every state-action pair ( s i , a i ) subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 (s_{i},a_{i}) ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in the buffer as follows to attain the goal, using a constant \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 1 \\u2212 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p < \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) < 1 + \\u03f5 c \\u2062 l \\u2062 i \\u2062 p . 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\displaystyle 1-\\\\epsilon_{clip}<\\\\frac{\\\\pi_{\\\\theta}(s_{i},a_{i})}{\\\\pi_{\\\\bar{% \\\\theta}}(s_{i},a_{i})}<1+\\\\epsilon_{clip}. 1 - italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT < divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG < 1 + italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT . (5) 4 Approach In this section, we discuss how we can use analytical gradients in the PPO framework while considering their variance and biases. We start our discussion with the definition of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy. 4.1 \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -Policy With the analytical gradient of advantage with respect to an action ( \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) from our differentiable environments, we can define a new class of policies \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , parameterized by \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , as follows. Definition 4.1 Given current policy \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b normal-\\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , we define its \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy as follows: \\u03c0 \\u03b1 \\u2062 ( s , a ~ ) = { \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) | det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | if \\u2203 a \\u2062 s.t. \\u2062 a ~ = f \\u2062 ( a ) = a + \\u03b1 \\u22c5 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) 0 else , subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udc4e cases subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e if \\ud835\\udc4e s.t. ~ \\ud835\\udc4e \\ud835\\udc53 \\ud835\\udc4e \\ud835\\udc4e \\u22c5 \\ud835\\udefc subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e 0 else missing-subexpression \\\\displaystyle\\\\qquad\\\\pi_{\\\\alpha}(s,\\\\tilde{a})=\\\\left\\\\{\\\\begin{array}[]{ccc}\\\\frac{% \\\\pi_{\\\\bar{\\\\theta}}(s,a)}{\\\\lvert\\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}% }}(s,a))\\\\rvert}&\\\\text{ if }&{\\\\exists{a}\\\\text{ s.t. }\\\\tilde{a}=f(a)=a+\\\\alpha% \\\\cdot\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)}\\\\\\\\ 0&\\\\text{ else }&\\\\end{array}\\\\right., italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) = { start_ARRAY start_ROW start_CELL divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG start_ARG | roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | end_ARG end_CELL start_CELL if end_CELL start_CELL \\u2203 italic_a s.t. over~ start_ARG italic_a end_ARG = italic_f ( italic_a ) = italic_a + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL else end_CELL start_CELL end_CELL end_ROW end_ARRAY , (6) where constant \\u2062 | \\u03b1 | < 1 max ( s , a ) \\u2061 | \\u03bb 1 \\u2062 ( s , a ) | . where constant \\ud835\\udefc 1 subscript \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf06 1 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle\\\\qquad\\\\qquad\\\\qquad\\\\qquad\\\\qquad\\\\qquad\\\\text{ where constant }|% \\\\alpha|<\\\\frac{1}{\\\\max_{(s,a)}\\\\lvert\\\\lambda_{1}(s,a)\\\\rvert}. where constant | italic_\\u03b1 | < divide start_ARG 1 end_ARG start_ARG roman_max start_POSTSUBSCRIPT ( italic_s , italic_a ) end_POSTSUBSCRIPT | italic_\\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s , italic_a ) | end_ARG . Here \\u03bb 1 \\u2062 ( s , a ) subscript \\ud835\\udf06 1 \\ud835\\udc60 \\ud835\\udc4e \\\\lambda_{1}(s,a) italic_\\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s , italic_a ) represents the minimum eigenvalue of \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) superscript subscript normal-\\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b normal-\\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) . Lemma 4.2 Mapping f \\ud835\\udc53 f italic_f is injective, and for an arbitrary open set of action T \\u2282 A \\ud835\\udc47 \\ud835\\udc34 T\\\\subset A italic_T \\u2282 italic_A , \\u03c0 \\u03b1 \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 normal-\\u22c5 \\\\pi_{\\\\alpha}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) selects a set of action T ~ = f \\u2062 ( A ) normal-~ \\ud835\\udc47 \\ud835\\udc53 \\ud835\\udc34 \\\\tilde{T}=f(A) over~ start_ARG italic_T end_ARG = italic_f ( italic_A ) with the same probability that \\u03c0 \\u03b8 \\u00af \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b normal-\\u00af \\ud835\\udf03 \\ud835\\udc60 normal-\\u22c5 \\\\pi_{\\\\bar{\\\\theta}}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) selects A \\ud835\\udc34 A italic_A . Proof: See Appendix 7.1.2 . (a) De Jong\\u2019s Function (b) Ackley\\u2019s Function Figure 1 : \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policies for 1-dimensional (a) De Jong\\u2019s function and (b) Ackley\\u2019s function. The original policy is rendered in blue, and alpha policies for different \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 values are rendered in orange and red. Those \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policies are obtained from analytical gradients of the given function f \\u2062 ( x ) \\ud835\\udc53 \\ud835\\udc65 f(x) italic_f ( italic_x ) rendered in black. Note that Ackley\\u2019s \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy becomes invalid when \\u03b1 = 2 \\u22c5 10 \\u2212 3 \\ud835\\udefc \\u22c5 2 superscript 10 3 \\\\alpha=2\\\\cdot 10^{-3} italic_\\u03b1 = 2 \\u22c5 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , because of singularities near 0. In Figure 1 , we provide renderings of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policies for different \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 s when we use 1-dimensional De Jong\\u2019s function and Ackley\\u2019s function (Molga and Smutnicki, 2005 ) as our target functions. The illustration provides us an intuition that when \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 is sufficiently small, \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT can be seen as a policy that selects slightly better action than \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT with the same probability. In fact, we can prove that \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT indeed gives us better estimated expected return in Equation 4 when \\u03b1 > 0 \\ud835\\udefc 0 \\\\alpha>0 italic_\\u03b1 > 0 is sufficiently small. Proposition 4.3 If | \\u03b1 | \\u226a 1 much-less-than \\ud835\\udefc 1 |\\\\alpha|\\\\ll 1 | italic_\\u03b1 | \\u226a 1 , L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b1 ) \\u2212 \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) = O \\u2062 ( | \\u03b1 | ) \\u2062 when \\u2062 \\u03b1 > 0 , subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc42 \\ud835\\udefc when \\ud835\\udefc 0 \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\alpha})-\\\\eta(\\\\pi_{\\\\bar{\\\\theta}})=O(% |\\\\alpha|)\\\\text{ when }\\\\alpha>0, italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) - italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) = italic_O ( | italic_\\u03b1 | ) when italic_\\u03b1 > 0 , (7) \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) \\u2212 L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b1 ) = O \\u2062 ( | \\u03b1 | ) \\u2062 when \\u2062 \\u03b1 < 0 , \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc42 \\ud835\\udefc when \\ud835\\udefc 0 \\\\displaystyle\\\\eta(\\\\pi_{\\\\bar{\\\\theta}})-L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\alpha})=O(|% \\\\alpha|)\\\\text{ when }\\\\alpha<0, italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) - italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) = italic_O ( | italic_\\u03b1 | ) when italic_\\u03b1 < 0 , where L \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udc3f subscript \\ud835\\udf0b normal-\\u00af \\ud835\\udf03 L_{\\\\pi_{\\\\bar{\\\\theta}}} italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT denotes estimated expected return defined in Equation 4 . Proof: See Appendix 7.1.3 . This proposition tells us that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy fits into PPO framework seamlessly, and thus if we update our policy towards \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy, it does not contradict the PPO\\u2019s objective. However, since there is a second order derivative \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) in the definition, it is unclear how we can update our policy \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT towards \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT . In the next section, we show how we can do this and how it is related to RP gradient. 4.2 Relationship between RP gradient and \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy To show how we can approximate \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy, for a deterministic function g \\u03b8 \\u00af subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 g_{\\\\bar{\\\\theta}} italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT such that \\u03c0 \\u03b8 \\u00af \\u225c g \\u03b8 \\u00af \\u225c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}}\\\\triangleq g_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , we define a new function g \\u03b1 subscript \\ud835\\udc54 \\ud835\\udefc g_{\\\\alpha} italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT as follows, and provide a Lemma about it. g \\u03b1 \\u2062 ( s , \\u03f5 ) = a + \\u03b1 \\u22c5 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) , where \\u2062 a = g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) . formulae-sequence subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 \\ud835\\udc4e \\u22c5 \\ud835\\udefc subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e where \\ud835\\udc4e subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 g_{\\\\alpha}(s,\\\\epsilon)=a+\\\\alpha\\\\cdot\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a),% \\\\text{ where }a=g_{\\\\bar{\\\\theta}}(s,\\\\epsilon). italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) = italic_a + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) , where italic_a = italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) . (8) Lemma 4.4 When a = g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\ud835\\udc4e subscript \\ud835\\udc54 normal-\\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 a=g_{\\\\bar{\\\\theta}}(s,\\\\epsilon) italic_a = italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) , det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) \\u22c5 det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) \\u2212 1 = det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) . \\u22c5 subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 superscript subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})\\\\cdot\\\\det(\\\\frac{% \\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})^{-1}=\\\\det(I+\\\\alpha% \\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)). roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) \\u22c5 roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) . (9) Proof: See Appendix 7.1.4 . Note that we can update g \\u03b8 subscript \\ud835\\udc54 \\ud835\\udf03 g_{\\\\theta} italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT to approximate g \\u03b1 subscript \\ud835\\udc54 \\ud835\\udefc g_{\\\\alpha} italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT by minimizing the following loss. L \\u2062 ( \\u03b8 ) = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2016 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2212 g \\u03b1 \\u2062 ( s t , \\u03f5 t ) \\u2016 2 ] . \\ud835\\udc3f \\ud835\\udf03 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript norm subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udefc subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 2 L(\\\\theta)=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[{||g_{\\\\theta}(s_{t},% \\\\epsilon_{t})-g_{\\\\alpha}(s_{t},\\\\epsilon_{t})||}^{2}\\\\right]. italic_L ( italic_\\u03b8 ) = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ | | italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] . (10) In fact, it turns out that minimizing Equation 10 leads our policy \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT to approximate \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , because of the following Proposition. Proposition 4.5 If \\u03c0 \\u03b8 \\u00af \\u225c g \\u03b8 \\u00af normal-\\u225c subscript \\ud835\\udf0b normal-\\u00af \\ud835\\udf03 subscript \\ud835\\udc54 normal-\\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}}\\\\triangleq g_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , for \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 that satisfies the constraint in Definition 4.1 , \\u03c0 \\u03b1 \\u225c g \\u03b1 normal-\\u225c subscript \\ud835\\udf0b \\ud835\\udefc subscript \\ud835\\udc54 \\ud835\\udefc \\\\pi_{\\\\alpha}\\\\triangleq g_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT . Proof: See Appendix 7.1.6 . Note that we can use different advantage function formulations for A \\ud835\\udc34 A italic_A in Equation 8 , such as GAE (Schulman et al., 2015b ) that we use in this work. However, let us we consider the following advantage function A ^ ^ \\ud835\\udc34 \\\\hat{A} over^ start_ARG italic_A end_ARG to see the relationship between RP gradient and \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy. A ^ \\u03c0 \\u03b8 \\u2062 ( s t , a t ) = 1 2 \\u2062 \\ud835\\udd3c s t , a t , \\u2026 \\u223c \\u03c0 \\u03b8 \\u2062 [ \\u2211 k = t \\u221e \\u03b3 k \\u2062 r \\u2062 ( s k , a k ) ] , subscript ^ \\ud835\\udc34 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 1 2 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 delimited-[] superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc58 \\\\hat{A}_{\\\\pi_{\\\\theta}}(s_{t},a_{t})=\\\\frac{1}{2}\\\\mathbb{E}_{s_{t},a_{t},...\\\\sim% \\\\pi_{\\\\theta}}\\\\Big{[}\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}r(s_{k},a_{k})\\\\Big{]}, over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ] , (11) Then, the following Lemma holds. Lemma 4.6 When \\u03b1 = 1 \\ud835\\udefc 1 \\\\alpha=1 italic_\\u03b1 = 1 , if we define g \\u03b1 subscript \\ud835\\udc54 \\ud835\\udefc g_{\\\\alpha} italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT with A ^ normal-^ \\ud835\\udc34 \\\\hat{A} over^ start_ARG italic_A end_ARG , the RP gradient corresponds to \\u2202 L \\u2202 \\u03b8 \\ud835\\udc3f \\ud835\\udf03 \\\\frac{\\\\partial L}{\\\\partial\\\\theta} divide start_ARG \\u2202 italic_L end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG at \\u03b8 = \\u03b8 \\u00af \\ud835\\udf03 normal-\\u00af \\ud835\\udf03 \\\\theta=\\\\bar{\\\\theta} italic_\\u03b8 = over\\u00af start_ARG italic_\\u03b8 end_ARG . Proof: See Appendix 7.1.5 . This Lemma tells us that we can understand the RP gradient as the very first gradient we get when we update our policy toward \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT by minimizing Equation 10 . In other words, \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy is not only a superior policy than the original one in the PPO\\u2019s point of view (Proposition 4.3 ), but also a target policy for RP gradient (Lemma 4.6 ). Therefore, we conclude that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy is a bridge that connects these two different policy update regimes. 4.3 Algorithm Our algorithm is mainly comprised of 3 parts: (1) Update \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT to \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT by minimizing Equation 10 , (2) Adjust \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 for next iteration, and (3) Update \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT by maximizing Equation 4 . In this section, we discuss details about Step 2 and 3, and provide the outline of our algorithm. 4.3.1 Step 2: Adjusting \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 In Definition 4.1 , we can observe that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 controls the influence of analytical gradients in policy updates. If \\u03b1 = 0 \\ud835\\udefc 0 \\\\alpha=0 italic_\\u03b1 = 0 , it is trivial that \\u03c0 \\u03b1 = \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\ud835\\udefc subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\alpha}=\\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT = italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , which means that analytical gradients are ignored. In contrast, as \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 gets bigger, analytical gradients play bigger roles, and \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT becomes increasingly different from \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT . Then, our mission is to find a well-balanced \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 value. Rather than setting it as a fixed hyperparameter, we opt to adjust it adaptively. We first present the following variance and bias criteria to control \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , as it is commonly used to assess the quality of gradients (Parmas et al., 2018 ; Suh et al., 2022 ) . Variance After we approximate \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT in Step 1), we can estimate det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) for every state-action pair in our buffer using Lemma 4.4 , and adjust \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 to bound the estimated values in a certain range, [ 1 \\u2212 \\u03b4 , 1 + \\u03b4 ] 1 \\ud835\\udeff 1 \\ud835\\udeff [1-\\\\delta,1+\\\\delta] [ 1 - italic_\\u03b4 , 1 + italic_\\u03b4 ] . There are two reasons behind this strategy. \\u2022 As shown in Definition 4.1 , we have to keep \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 small enough so that \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT does not become invalid policy. By keeping det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) larger than 1 \\u2212 \\u03b4 1 \\ud835\\udeff 1-\\\\delta 1 - italic_\\u03b4 to keep its positiveness, we guarantee that our policy is not updated towards an invalid policy. \\u2022 Note that det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) = \\u03a0 i = 1 n \\u2062 ( 1 + \\u03b1 \\u2062 \\u03bb i ) \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e superscript subscript \\u03a0 \\ud835\\udc56 1 \\ud835\\udc5b 1 \\ud835\\udefc subscript \\ud835\\udf06 \\ud835\\udc56 \\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a))=\\\\Pi_{i=1}^{n}(1+\\\\alpha% \\\\lambda_{i}) roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) = roman_\\u03a0 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( 1 + italic_\\u03b1 italic_\\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , where \\u03bb i subscript \\ud835\\udf06 \\ud835\\udc56 \\\\lambda_{i} italic_\\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the i \\ud835\\udc56 i italic_i -th eigenvalue of \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) . By constraining this value near 1 by adjusting \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , we can guarantee stable policy updates even when some eigenvalues of \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) have huge magnitudes, which is related to a high variance RP gradient. In Appendix 7.3.1 , we provide empirical evidence that this estimation is related to the sample variance of analytical gradients. Bias By Proposition 4.3 , we already know that when we estimate the right term of Equation 4 after Step 1), it should be a positive value. However, if the analytical gradients were biased, this condition could not be met. In runtime, if we detect such cases, we decrease \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 . In addition, we use one more criterion to adjust \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , which we call the out-of-range ratio. This criterion was designed to promise the minimum amount of policy update by PPO. Out-of-range-ratio We define out-of-range-ratio as follows, out-of-range-ratio = 1 N \\u2062 \\u2211 i = 1 N \\ud835\\udd40 \\u2062 ( | \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) \\u2212 1 | > \\u03f5 c \\u2062 l \\u2062 i \\u2062 p ) , out-of-range-ratio 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 \\ud835\\udd40 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\displaystyle\\\\text{out-of-range-ratio}=\\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\mathbb{I}(|% \\\\frac{\\\\pi_{\\\\theta}(s_{i},a_{i})}{\\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i})}-1|>\\\\epsilon_% {clip}), out-of-range-ratio = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT blackboard_I ( | divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG - 1 | > italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT ) , (12) where N \\ud835\\udc41 N italic_N is the size of the buffer, \\ud835\\udd40 \\ud835\\udd40 \\\\mathbb{I} blackboard_I is the indicator function, and \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT is the constant from Equation 5 . We assess this ratio after the policy update in Step 1), allowing its value to be non-zero when \\u03b1 > 0 \\ud835\\udefc 0 \\\\alpha>0 italic_\\u03b1 > 0 . A non-negligible value of this ratio indicates a potential violation of the PPO\\u2019s restriction outlined in Equation 5 , thereby compromising the effectiveness of PPO. Further elaboration can be found in Appendix 7.3.2 . Therefore, when this ratio exceeds a predetermined threshold, we subsequently reduce the value of \\u03b1 . \\ud835\\udefc \\\\alpha. italic_\\u03b1 . To sum it up, our strategy to control \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 aims at decreasing it when analytical gradients exhibit high variance or bias, or when there is little room for PPO updates. This results in greater dependence on PPO, which can be thought of as a safeguard in our approach. Otherwise, we increase \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , since we can expect higher expected return with a greater \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 as shown in Proposition 4.3 . 4.3.2 Step 3: PPO Update Since we do policy updates based on PPO after the update based on \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , there is a possibility that the PPO update can \\u201crevert\\u201d the update from Step 1). To avoid such situations, we propose to use the following \\u03c0 h subscript \\ud835\\udf0b \\u210e \\\\pi_{h} italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT in the place of \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT in Equation 5 : \\u03c0 h \\u2062 ( s , a ) = 1 2 \\u2062 ( \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) + \\u03c0 \\u03b1 \\u2062 ( s , a ) ) . subscript \\ud835\\udf0b \\u210e \\ud835\\udc60 \\ud835\\udc4e 1 2 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle\\\\pi_{h}(s,a)=\\\\frac{1}{2}(\\\\pi_{\\\\bar{\\\\theta}}(s,a)+\\\\pi_{\\\\alpha}(s,a% )). italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_s , italic_a ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) + italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_a ) ) . By using this virtual policy \\u03c0 h subscript \\ud835\\udf0b \\u210e \\\\pi_{h} italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT , we can restrict the PPO update to be done near both \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT and \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT . See Appendix 7.3.2 for more details. 4.3.3 Pseudocode In Algorithm 1 , we present pseudocode that illustrates the outline of our algorithm, GI-PPO. There are five hyperparameters in the algorithm, which are \\u03b1 0 , \\u03b2 , \\u03b4 d \\u2062 e \\u2062 t , \\u03b4 o \\u2062 o \\u2062 r \\u2062 r , subscript \\ud835\\udefc 0 \\ud835\\udefd subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\alpha_{0},\\\\beta,\\\\delta_{det},\\\\delta_{oorr}, italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03b2 , italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT , italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT , and max \\u2061 ( \\u03b1 ) \\ud835\\udefc \\\\max(\\\\alpha) roman_max ( italic_\\u03b1 ) . We present specific values for these hyperparameters for our experiments in Appendix 7.4.2 . \\u03b1 \\u2190 \\u03b1 0 \\u2190 \\ud835\\udefc subscript \\ud835\\udefc 0 \\\\alpha\\\\leftarrow\\\\alpha_{0} italic_\\u03b1 \\u2190 italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , Initial value; \\u03b2 \\u2190 \\u2190 \\ud835\\udefd absent \\\\beta\\\\leftarrow italic_\\u03b2 \\u2190 Constant multiplier larger than 1 for \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ; \\u03b4 d \\u2062 e \\u2062 t , \\u03b4 o \\u2062 o \\u2062 r \\u2062 r \\u2190 \\u2190 subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f absent \\\\delta_{det},\\\\delta_{oorr}\\\\leftarrow italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT , italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT \\u2190 Constant thresholds; B \\u2190 \\u2190 \\ud835\\udc35 absent B\\\\leftarrow italic_B \\u2190 Experience buffer; while Training not ended do Clear B \\ud835\\udc35 B italic_B ; while Not collected enough experience do Collect experience { s t , \\u03f5 t , a t , r t , s t + 1 } \\u2192 B \\u2192 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 subscript \\ud835\\udc5f \\ud835\\udc61 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\ud835\\udc35 \\\\{s_{t},\\\\epsilon_{t},a_{t},r_{t},s_{t+1}\\\\}\\\\rightarrow B { italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT } \\u2192 italic_B ; end while Estimate advantage A \\ud835\\udc34 A italic_A for every ( s i , a i ) subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 (s_{i},a_{i}) ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in B \\ud835\\udc35 B italic_B using Eq. 14 ; Estimate advantage gradient \\u2202 A \\u2202 a \\ud835\\udc34 \\ud835\\udc4e \\\\frac{\\\\partial A}{\\\\partial a} divide start_ARG \\u2202 italic_A end_ARG start_ARG \\u2202 italic_a end_ARG for every ( s i , a i ) subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 (s_{i},a_{i}) ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in B \\ud835\\udc35 B italic_B using Eq. 15 ; For current \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , approximate \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy by minimizing loss in Equation 10 ; // Variance ; For each \\u03f5 i subscript italic-\\u03f5 \\ud835\\udc56 \\\\epsilon_{i} italic_\\u03f5 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and its corresponding state-action pair ( s i , a i ) subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 (s_{i},a_{i}) ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , estimate det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) by Lemma 4.4 and get its sample minimum ( \\u03c8 m \\u2062 i \\u2062 n subscript \\ud835\\udf13 \\ud835\\udc5a \\ud835\\udc56 \\ud835\\udc5b \\\\psi_{min} italic_\\u03c8 start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT ) and maximum ( \\u03c8 m \\u2062 a \\u2062 x subscript \\ud835\\udf13 \\ud835\\udc5a \\ud835\\udc4e \\ud835\\udc65 \\\\psi_{max} italic_\\u03c8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT ); // Bias ; Evaluate expected additional return in Equation 16 with our current policy to get R \\u03b1 subscript \\ud835\\udc45 \\ud835\\udefc R_{\\\\alpha} italic_R start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ; // Out-of-range-ratio ; Evaluate out-of-range-ratio in Equation 12 with our current policy to get R o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udc45 \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f R_{oorr} italic_R start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT ; if \\u03c8 m \\u2062 i \\u2062 n < 1 \\u2212 \\u03b4 d \\u2062 e \\u2062 t subscript \\ud835\\udf13 \\ud835\\udc5a \\ud835\\udc56 \\ud835\\udc5b 1 subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 \\\\psi_{min}<1-\\\\delta_{det} italic_\\u03c8 start_POSTSUBSCRIPT italic_m italic_i italic_n end_POSTSUBSCRIPT < 1 - italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT or \\u03c8 m \\u2062 a \\u2062 x > 1 + \\u03b4 d \\u2062 e \\u2062 t subscript \\ud835\\udf13 \\ud835\\udc5a \\ud835\\udc4e \\ud835\\udc65 1 subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 \\\\psi_{max}>1+\\\\delta_{det} italic_\\u03c8 start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT > 1 + italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT or R \\u03b1 < 0 subscript \\ud835\\udc45 \\ud835\\udefc 0 R_{\\\\alpha}<0 italic_R start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT < 0 or R o \\u2062 o \\u2062 r \\u2062 r > \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udc45 \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f R_{oorr}>\\\\delta_{oorr} italic_R start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT > italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT then \\u03b1 = \\u03b1 / \\u03b2 \\ud835\\udefc \\ud835\\udefc \\ud835\\udefd \\\\alpha=\\\\alpha/\\\\beta italic_\\u03b1 = italic_\\u03b1 / italic_\\u03b2 ; end if else \\u03b1 = \\u03b1 \\u00d7 \\u03b2 \\ud835\\udefc \\ud835\\udefc \\ud835\\udefd \\\\alpha=\\\\alpha\\\\times\\\\beta italic_\\u03b1 = italic_\\u03b1 \\u00d7 italic_\\u03b2 ; end if \\u03b1 = c \\u2062 l \\u2062 i \\u2062 p \\u2062 ( \\u03b1 , 0 , max \\u2061 ( \\u03b1 ) ) \\ud835\\udefc \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\ud835\\udefc 0 \\ud835\\udefc \\\\alpha=clip(\\\\alpha,0,\\\\max(\\\\alpha)) italic_\\u03b1 = italic_c italic_l italic_i italic_p ( italic_\\u03b1 , 0 , roman_max ( italic_\\u03b1 ) ) ; Do PPO update by maximizing the surrogate loss in Equation 18 ; end while Algorithm 1 GI-PPO 5 Experimental Results In this section, we present experimental results that show our method\\u2019s efficacy for various optimization and complex control problems. To validate our approach, we tested various baseline methods on the environments that we use. The methods are as follows: \\u2022 LR: Policy gradient method based on LR gradient. \\u2022 RP: Policy gradient method based on RP gradient. For physics and traffic problems, we adopted a truncated time window of (Xu et al., 2022 ) to reduce variance. \\u2022 PPO: Proximal Policy Optimization (Schulman et al., 2017 ) . \\u2022 LR+RP: Policy gradient method based on interpolation between LR and RP gradient using sample variance (Parmas et al., 2018 ) . \\u2022 PE: Policy enhancement scheme of (Qiao et al., 2021 ) , for physics environments only. \\u2022 GI-PPO: Our method based on Section 4.3 . Please refer Appendix 7.4 to learn about implementation details of these baseline methods, network architectures, and hyperparameters that we used for all of the experiments. We have implemented our learning method using PyTorch 1.9 Paszke et al. ( 2019 ) . As for hardware, all experiments were run with an Intel\\u00ae Xeon\\u00ae W-2255 CPU @ 3.70GHz, one NVIDIA RTX A5000 graphics card, and 16 GB of memory. Experiment results are averaged across 5 random seeds. Table 1 : Average maximum reward ( \\u2191 \\u2191 \\\\uparrow \\u2191 ) for function optimization problems. Problem LR RP PPO LR+RP GI-PPO Dejong (1) -1.24 * 10 \\u2212 6 absent superscript 10 6 *{10}^{-6} * 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT -1.42 * 10 \\u2212 8 absent superscript 10 8 *{10}^{-8} * 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT -5.21 * 10 \\u2212 5 absent superscript 10 5 *{10}^{-5} * 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT -6.36 * 10 \\u2212 8 absent superscript 10 8 *{10}^{-8} * 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT -3.84 * \\ud835\\udfcf\\ud835\\udfce \\u2212 \\ud835\\udfcf\\ud835\\udfce absent superscript 10 10 \\\\mathbf{*{10}^{-10}} * bold_10 start_POSTSUPERSCRIPT - bold_10 end_POSTSUPERSCRIPT Dejong (64) -0.0007 -9.28 * \\ud835\\udfcf\\ud835\\udfce \\u2212 \\ud835\\udfd5 absent superscript 10 7 \\\\mathbf{*{10}^{-7}} * bold_10 start_POSTSUPERSCRIPT - bold_7 end_POSTSUPERSCRIPT -0.0011 -3.05 * 10 \\u2212 6 absent superscript 10 6 *{10}^{-6} * 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT -1.04 * 10 \\u2212 6 absent superscript 10 6 *{10}^{-6} * 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT Ackley (1) -1.2772 -0.4821 -0.2489 -1.2255 -0.0005 Ackley (64) -0.6378 -0.0089 -0.1376 -0.0326 -0.0036 (a) De Jong (1) (b) De Jong (64) (c) Ackley (1) (d) Ackley (64) Figure 2 : Optimization curves for Dejong\\u2019s and Ackley\\u2019s function of dimension 1 and 64. 5.1 Function Optimization Problems We start with how different learning methods find the maximum point for a given analytical function. We ran these experiments because RL algorithms can be thought of as function optimizers through function sampling (Williams and Peng, 1989 ) . These problems are 1 1 1 1 -step optimization problems, where agents guess an optimal point as an action and get the negative function value as the reward. As we used for rendering \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policies in Figure 1 , we use De Jong\\u2019s function and Ackley\\u2019s function for comparison, as they are popular functions for testing numerical optimization algorithms (Molga and Smutnicki, 2005 ) . Please see Appendix 7.5.1 for the details about the function definitions. In this setting, the optimum occurs at the point x = 0 \\ud835\\udc65 0 x=0 italic_x = 0 for both of the problems. However, their loss landscapes are quite different from one another\\u2014De Jong\\u2019s function has a very smooth landscape that only has one local (global) maximum, while Ackley\\u2019s function has a very rugged landscape with multiple local maxima. Therefore, De Jong\\u2019s function represents environments where RP gradients have lower variance, while Ackley\\u2019s function represents the opposite. Table 1 shows that GI-PPO finds far better optimums than the other methods for most of the functions , except 64-dimensional Dejong\\u2019s function, where the RP method found slightly better optimum than GI-PPO. Optimization curves in Figure 2 also prove that our method converges to the optimum faster than the other methods. Interestingly, the RP method achieved better results than the LR and LR+RP methods for all the functions, which contradicts our assumption that it would not work well for Ackley\\u2019s function. However, we found out that even though the RP method takes some time to find the optimum than the other methods as shown in Figure 2 , when it approaches near-optimum, it converges fast to the optimum based on analytic gradients. Since GI-PPO adaptively changes \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 to favor RP gradient near optimum, it could achieve better results than the other methods. In Appendix 7.3.3 , we provide visual renderings that trace the change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 value during optimization to help understanding, which also shows that higher \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 is maintained for Dejong\\u2019s function than Ackley\\u2019s function, which aligns with our initial assumption. Also note that even though LR+RP also takes advantage of the RP method, and thus achieved a better convergence rate than the two methods when it is far from optimum, it did not work well when it comes to near-optimum. (a) Cartpole (b) Ant (c) Hopper Figure 3 : Learning graphs for 3 problems in differentiable physics simulation: Cartpole, Ant, and Hopper (Xu et al., 2022 ) . In these environments, RP gradients already exhibit lower variance without much bias than LR gradients, because of variance reduction scheme of (Xu et al., 2022 ) . 5.2 Differentiable Physics Simulation Next, we conducted experiments in differentiable physics simulations. We used Cartpole, Ant, and Hopper environments implemented by (Xu et al., 2022 ) for comparisons. However, since the current implementation does not support multiple backpropagations through the same computation graph for these environments, we could not test the LP+RP method for them. Instead, we tried to faithfully implement another policy enhancement (PE) strategy of (Qiao et al., 2021 ) as a comparison, as it showed its efficacy in differentiable physics simulations using analytical gradients. In Figure 3 , we can see that GI-PPO converged to a better policy much faster than the baseline PPO for every environment, which validates our approach. However, the RP method achieved the best results for Ant and Hopper, while GI-PPO converged to the optimal policy slightly faster for Cartpole. To explain this result, we\\u2019d like to point out that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 is upper bounded by out-of-range-ratio in our approach (Section 4.3.1 ). Therefore, even if the RP gradient is very effective, we cannot fully utilize it because we have to use PPO to update the policy up to some extent as a safeguard. In the Ant environment, we could observe that it was the major bottleneck in training\\u2014in fact, GI-PPO could achieve better results than RP when we increased the ratio from 0.5 to 1.0 (Appendix 7.3.4 ). However, when the out-of-range ratio equals 1.0, it becomes more likely that we cannot use PPO as a safeguard, which contradicts our design intention. When it comes to the Hopper environment, we found that the variance of proper \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 values over time was large, so our strategy could not conform to it properly. Overcoming these limitations would be an interesting future work to extend our work. 5.3 Traffic Problems (a) Single Lane (b) 2 Lanes (c) 4 Lanes (d) 10 Lanes Figure 4 : Learning graphs for traffic pace car problem. Each problem has different number of lanes and following human vehicles, which represent discontinuities and dimension of the problem , respectively. Here we demonstrate the effectiveness of GI-PPO in an environment where continuous and discrete operations coexist, which leads to highly biased analytical gradients. We suggest a mixed-autonomy traffic environment as a suitable benchmark, which has previously been explored as a benchmark for gradient-free RL algorithms (Wu et al., 2017 ; Vinitsky et al., 2018 ) . In this paper, we use the pace car problem, where a single autonomous pace car has to control the speed of the other vehicles via interference. The number of lanes, which represent the discontinuities in gradients, and the number of following human vehicles are different for each problem. Please see Appendix 7.5.2 for the details of this environment, and why the analytical gradients are biased. In Figure 3(d) , we can observe that GI-PPO exhibits a faster convergence rate and converges to better policy overall compared to all the other methods in 2, 4, and 10-lane environments. In a single-lane environment, however, LR+RP showed a better convergence rate than GI-PPO. Note that the RP method still performs well for 2 and 4-lane environments just as other baseline methods, even if there were multiple lanes. We assume this is because the RP method also leverages a state value function, which can provide unbiased analytical gradients in the presence of discontinuities. However, it does not perform well in the 10-lane environment, where discontinuities are excessive compared to the other environments. This result shows that GI-PPO can still leverage analytical gradients, even if they were highly biased for policy learning . Even though LP+RP, which is based on a similar spirit as ours, also exhibited some improvements over LP and RP, our method showed better results for more difficult problems because baseline PPO offers more stable learning than baseline LR . Also, the computational cost of GI-PPO was a little more than RP, while that of LR+RP was much more expensive (Appendix 7.7 ). 6 Conclusions We introduced a novel policy learning method that adopts analytical gradients into the PPO framework. Based on the observation that the RP gradient leads our current policy to its \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy, we suggested approximating it explicitly, which allows us to indirectly estimate variance and bias of analytical gradients. We suggested several criteria to detect such variance and bias and introduced an algorithm that manipulates \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 adaptively, which stands for the strength of analytical gradients in policy updates. In our experiments of diverse RL environments, we successfully showed that our method achieves much better results than the baseline PPO by adopting analytical gradients. Even though the interpolated gradient of LR and RP gradient is based on similar motivations, our method performed much better, thanks to the baseline PPO\\u2019s stable learning. Limitations Despite GI-PPO\\u2019s promising results, there are some remaining issues. First, even if we use a large \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , we may not fully approximate the corresponding \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy in a limited number of optimization steps, which may give a false signal for our strategy. We can upper bound the maximum \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 as we did here, but a more rigorous optimization process may be helpful. This is also related to improving the strategy to control \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 adaptively, which would be a promising future work. Also, as discussed in Section 5.2 , our method is tightly bound to PPO\\u2014that is, even when analytical gradients are much more useful as illustrated in differentiable physics problems, we cannot fully utilize them if they exit the PPO\\u2019s bound. Even though it is more suitable for stable updates, it could result in a worse convergence rate. If we could adjust PPO\\u2019s clipping range dynamically, or detect environments where RP gradients are much more reliable, we would be able to overcome this issue. Finally, computational costs can be further reduced. To utilize analytical gradients, we need backpropagation, which usually requires more time than forward steps. This is the reason why the learning methods based on analytical gradients require longer training time than the others (Appendix 7.7 ). When the time window gets longer, the cost grows accordingly. However, as we have shown in our traffic experiments, our method works even when gradients are biased. Therefore, it would be an interesting research direction to see if using a very short time window for backpropagation, which produces more biased gradients, would be worthy of exploring for improved computational efficiency. Acknowledgements. This research is supported in part by the ARO DURIP and IARPA HAYSTAC Grants, ARL Cooperative Agreement W911NF2120076, Dr. Barry Mersky and Capital One E-Nnovate Endowed Professorships. Yi-Ling Qiao would like to thank the support of Meta Fellowship. References Barto et al. [1983] Andrew G Barto, Richard S Sutton, and Charles W Anderson. Neuronlike adaptive elements that can solve difficult learning control problems. IEEE transactions on systems, man, and cybernetics , (5):834\\u2013846, 1983. de Avila Belbute-Peres et al. [2018] Filipe de Avila Belbute-Peres, Kevin Smith, Kelsey Allen, Josh Tenenbaum, and J Zico Kolter. End-to-end differentiable physics for learning and control. Advances in neural information processing systems , 31, 2018. Degrave et al. [2019] Jonas Degrave, Michiel Hermans, Joni Dambre, et al. A differentiable physics engine for deep learning in robotics. Frontiers in neurorobotics , page 6, 2019. Deisenroth and Rasmussen [2011] Marc Deisenroth and Carl E Rasmussen. Pilco: A model-based and data-efficient approach to policy search. In Proceedings of the 28th International Conference on machine learning (ICML-11) , pages 465\\u2013472, 2011. Deisenroth et al. [2013] Marc Peter Deisenroth, Gerhard Neumann, Jan Peters, et al. A survey on policy search for robotics. Foundations and Trends\\u00ae in Robotics , 2(1\\u20132):1\\u2013142, 2013. Freeman et al. [2021] C Daniel Freeman, Erik Frey, Anton Raichuk, Sertan Girgin, Igor Mordatch, and Olivier Bachem. Brax\\u2013a differentiable physics engine for large scale rigid body simulation. arXiv preprint arXiv:2106.13281 , 2021. Fu et al. [2015] C Fu, C Fu, and Michael Michael. Handbook of simulation optimization . Springer, 2015. Geilinger et al. [2020] Moritz Geilinger, David Hahn, Jonas Zehnder, Moritz B\\u00e4cher, Bernhard Thomaszewski, and Stelian Coros. Add: Analytically differentiable dynamics for multi-body systems with frictional contact. ACM Transactions on Graphics (TOG) , 39(6):1\\u201315, 2020. Glynn [1990] Peter W Glynn. Likelihood ratio gradient estimation for stochastic systems. Communications of the ACM , 33(10):75\\u201384, 1990. Greensmith et al. [2004] Evan Greensmith, Peter L Bartlett, and Jonathan Baxter. Variance reduction techniques for gradient estimates in reinforcement learning. Journal of Machine Learning Research , 5(9), 2004. Kakade and Langford [2002] Sham Kakade and John Langford. Approximately optimal approximate reinforcement learning. In In Proc. 19th International Conference on Machine Learning . Citeseer, 2002. Kingma and Welling [2013] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 , 2013. Konda and Tsitsiklis [1999] Vijay Konda and John Tsitsiklis. Actor-critic algorithms. Advances in neural information processing systems , 12, 1999. Makoviichuk and Makoviychuk [2022] Denys Makoviichuk and Viktor Makoviychuk. rl-games: A high-performance framework for reinforcement learning. https://github.com/Denys88/rl_games , May 2022. Metz et al. [2021] Luke Metz, C Daniel Freeman, Samuel S Schoenholz, and Tal Kachman. Gradients are not all you need. arXiv preprint arXiv:2111.05803 , 2021. Molga and Smutnicki [2005] Marcin Molga and Czes\\u0142aw Smutnicki. Test functions for optimization needs. Test functions for optimization needs , 101:48, 2005. Mora et al. [2021] Miguel Angel Zamora Mora, Momchil Peychev, Sehoon Ha, Martin Vechev, and Stelian Coros. Pods: Policy optimization via differentiable simulation. In International Conference on Machine Learning , pages 7805\\u20137817. PMLR, 2021. Mozer [1989] M Mozer. A focused backpropagation algorithm. Complex systems , 3:349\\u2013381, 1989. Murphy [2022] Kevin P Murphy. Probabilistic machine learning: an introduction . MIT press, 2022. Parmas et al. [2018] Paavo Parmas, Carl Edward Rasmussen, Jan Peters, and Kenji Doya. Pipps: Flexible model-based policy search robust to the curse of chaos. In International Conference on Machine Learning , pages 4065\\u20134074. PMLR, 2018. Paszke et al. [2017] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017. Paszke et al. [2019] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems , 32, 2019. Qiao et al. [2021] Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, and Ming C Lin. Efficient differentiable simulation of articulated bodies. In International Conference on Machine Learning , pages 8661\\u20138671. PMLR, 2021. Raffin et al. [2021] Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah Dormann. Stable-baselines3: Reliable reinforcement learning implementations. Journal of Machine Learning Research , 22(268):1\\u20138, 2021. URL http://jmlr.org/papers/v22/20-1364.html . Schulman et al. [2015a] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International conference on machine learning , pages 1889\\u20131897. PMLR, 2015a. Schulman et al. [2015b] John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel. High-dimensional continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438 , 2015b. Schulman et al. [2017] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 , 2017. Suh et al. [2022] Hyung Ju Suh, Max Simchowitz, Kaiqing Zhang, and Russ Tedrake. Do differentiable simulators give better policy gradients? In International Conference on Machine Learning , pages 20668\\u201320696. PMLR, 2022. Sutton et al. [1998] Richard S Sutton, Andrew G Barto, et al. Introduction to reinforcement learning. 1998. Sutton et al. [1999] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for reinforcement learning with function approximation. Advances in neural information processing systems , 12, 1999. Treiber et al. [2000] Martin Treiber, Ansgar Hennecke, and Dirk Helbing. Congested traffic states in empirical observations and microscopic simulations. Physical Review E , 62(2):1805\\u20131824, Aug 2000. Vinitsky et al. [2018] Eugene Vinitsky, Aboudy Kreidieh, Luc Le Flem, Nishant Kheterpal, Kathy Jang, Cathy Wu, Fangyu Wu, Richard Liaw, Eric Liang, and Alexandre M Bayen. Benchmarks for reinforcement learning in mixed-autonomy traffic. In Conference on robot learning , pages 399\\u2013409. PMLR, 2018. Williams [1992] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning , 8(3):229\\u2013256, 1992. Williams and Peng [1989] Ronald J Williams and Jing Peng. Reinforcement learning algorithms as function optimizers. In Proceedings of the International Joint Conference on Neural Networks, Washington DC , volume 2, pages 89\\u201395, 1989. Wu et al. [2017] Cathy Wu, Aboudy Kreidieh, Kanaad Parvate, Eugene Vinitsky, and Alexandre M Bayen. Flow: Architecture and benchmarking for reinforcement learning in traffic control. arXiv preprint arXiv:1710.05465 , 10, 2017. Xu et al. [2022] Jie Xu, Viktor Makoviychuk, Yashraj Narang, Fabio Ramos, Wojciech Matusik, Animesh Garg, and Miles Macklin. Accelerated policy learning with parallel differentiable simulation. arXiv preprint arXiv:2204.07137 , 2022. 7 APPENDIX 7.1 Proofs 7.1.1 Proof of Lemma 3.2 By Definition 3.1 , \\u03c0 \\u03b8 \\u2062 ( s , a ) subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\pi_{\\\\theta}(s,a) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) should satisfy the following condition: \\u222b T \\u03f5 q \\u2062 ( \\u03f5 ) \\u2062 \\ud835\\udc51 \\u03f5 subscript subscript \\ud835\\udc47 italic-\\u03f5 \\ud835\\udc5e italic-\\u03f5 differential-d italic-\\u03f5 \\\\displaystyle\\\\int_{T_{\\\\epsilon}}q(\\\\epsilon)d\\\\epsilon \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q ( italic_\\u03f5 ) italic_d italic_\\u03f5 = \\u222b T a \\u03c0 \\u03b8 \\u2062 ( s , a ) \\u2062 \\ud835\\udc51 a absent subscript subscript \\ud835\\udc47 \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{T_{a}}\\\\pi_{\\\\theta}(s,a)da = \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_d italic_a = \\u222b T \\u03f5 \\u03c0 \\u03b8 \\u2062 ( s , g \\u03b8 \\u2062 ( s , \\u03f5 ) ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2062 \\ud835\\udc51 \\u03f5 (by change of variable) . absent subscript subscript \\ud835\\udc47 italic-\\u03f5 \\u22c5 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 differential-d italic-\\u03f5 (by change of variable) \\\\displaystyle=\\\\int_{T_{\\\\epsilon}}\\\\pi_{\\\\theta}(s,g_{\\\\theta}(s,\\\\epsilon))\\\\cdot% \\\\Big{\\\\lvert}\\\\det(\\\\frac{\\\\partial g_{\\\\theta}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})\\\\Big% {\\\\rvert}d\\\\epsilon\\\\quad\\\\text{(by change of variable)}. = \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | italic_d italic_\\u03f5 (by change of variable) . We denote the set of continuous distributions that satisfy this condition as P \\ud835\\udc43 P italic_P . That is, P \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2208 P \\u2062 if \\u2062 \\u222b T \\u03f5 q \\u2062 ( \\u03f5 ) \\u2062 \\ud835\\udc51 \\u03f5 = \\u222b T \\u03f5 P \\u03b8 \\u2062 ( s , \\u03f5 ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2062 \\ud835\\udc51 \\u03f5 . subscript \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\ud835\\udc43 if subscript subscript \\ud835\\udc47 italic-\\u03f5 \\ud835\\udc5e italic-\\u03f5 differential-d italic-\\u03f5 subscript subscript \\ud835\\udc47 italic-\\u03f5 \\u22c5 subscript \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 differential-d italic-\\u03f5 \\\\displaystyle P_{\\\\theta}(s,\\\\epsilon)\\\\in P\\\\text{ if }\\\\int_{T_{\\\\epsilon}}q(% \\\\epsilon)d\\\\epsilon=\\\\int_{T_{\\\\epsilon}}P_{\\\\theta}(s,\\\\epsilon)\\\\cdot\\\\Big{\\\\lvert}% \\\\det(\\\\frac{\\\\partial g_{\\\\theta}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})\\\\Big{\\\\rvert}d\\\\epsilon. italic_P start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) \\u2208 italic_P if \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_q ( italic_\\u03f5 ) italic_d italic_\\u03f5 = \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_P start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | italic_d italic_\\u03f5 . Clearly, P \\u00af \\u03b8 \\u2062 ( s , \\u03f5 ) = q \\u2062 ( \\u03f5 ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\u22c5 \\ud835\\udc5e italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\bar{P}_{\\\\theta}(s,\\\\epsilon)=q(\\\\epsilon)\\\\cdot\\\\Big{\\\\lvert}\\\\det(\\\\frac{\\\\partial g% _{\\\\theta}(s,\\\\epsilon)}{\\\\partial\\\\epsilon})\\\\Big{\\\\rvert}^{-1} over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) = italic_q ( italic_\\u03f5 ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an element of P \\ud835\\udc43 P italic_P , and is well defined, because of Equation 3 . In fact, P \\u00af \\u03b8 \\u2062 ( s , \\u03f5 ) subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\\\bar{P}_{\\\\theta}(s,\\\\epsilon) over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) is the only element of P \\ud835\\udc43 P italic_P , as the above condition should be met for any T \\u03f5 \\u2282 \\u211d n subscript \\ud835\\udc47 italic-\\u03f5 superscript \\u211d \\ud835\\udc5b T_{\\\\epsilon}\\\\subset\\\\mathbb{R}^{n} italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT \\u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT . That is, if there was another distribution P ~ \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2208 P subscript ~ \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\ud835\\udc43 \\\\tilde{P}_{\\\\theta}(s,\\\\epsilon)\\\\in P over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) \\u2208 italic_P , \\u222b T \\u03f5 ( P \\u00af \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2212 P ~ \\u03b8 \\u2062 ( s , \\u03f5 ) ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2062 \\ud835\\udc51 \\u03f5 = 0 , \\u2200 T \\u03f5 \\u2282 \\u211d n . formulae-sequence subscript subscript \\ud835\\udc47 italic-\\u03f5 \\u22c5 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript ~ \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 differential-d italic-\\u03f5 0 for-all subscript \\ud835\\udc47 italic-\\u03f5 superscript \\u211d \\ud835\\udc5b \\\\displaystyle\\\\int_{T_{\\\\epsilon}}(\\\\bar{P}_{\\\\theta}(s,\\\\epsilon)-\\\\tilde{P}_{% \\\\theta}(s,\\\\epsilon))\\\\cdot\\\\Big{\\\\lvert}\\\\det(\\\\frac{\\\\partial g_{\\\\theta}(s,\\\\epsilon% )}{\\\\partial\\\\epsilon})\\\\Big{\\\\rvert}d\\\\epsilon=0,\\\\forall T_{\\\\epsilon}\\\\subset% \\\\mathbb{R}^{n}. \\u222b start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) - over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | italic_d italic_\\u03f5 = 0 , \\u2200 italic_T start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT \\u2282 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT . Since P ~ \\u03b8 subscript ~ \\ud835\\udc43 \\ud835\\udf03 \\\\tilde{P}_{\\\\theta} over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT is different from P \\u00af \\u03b8 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\\\bar{P}_{\\\\theta} over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT , there exists an open set T ^ \\u03f5 subscript ^ \\ud835\\udc47 italic-\\u03f5 \\\\hat{T}_{\\\\epsilon} over^ start_ARG italic_T end_ARG start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT where P ~ \\u03b8 < P \\u00af \\u03b8 subscript ~ \\ud835\\udc43 \\ud835\\udf03 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\\\tilde{P}_{\\\\theta}<\\\\bar{P}_{\\\\theta} over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT < over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT . Then \\u222b T ^ \\u03f5 ( P \\u00af \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2212 P ~ \\u03b8 \\u2062 ( s , \\u03f5 ) ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2062 \\ud835\\udc51 \\u03f5 > 0 , subscript subscript ^ \\ud835\\udc47 italic-\\u03f5 \\u22c5 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript ~ \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 differential-d italic-\\u03f5 0 \\\\displaystyle\\\\int_{\\\\hat{T}_{\\\\epsilon}}(\\\\bar{P}_{\\\\theta}(s,\\\\epsilon)-\\\\tilde{P}_% {\\\\theta}(s,\\\\epsilon))\\\\cdot\\\\Big{\\\\lvert}\\\\det(\\\\frac{\\\\partial g_{\\\\theta}(s,% \\\\epsilon)}{\\\\partial\\\\epsilon})\\\\Big{\\\\rvert}d\\\\epsilon>0, \\u222b start_POSTSUBSCRIPT over^ start_ARG italic_T end_ARG start_POSTSUBSCRIPT italic_\\u03f5 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) - over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | italic_d italic_\\u03f5 > 0 , which is a contradiction. Therefore, \\u03c0 \\u03b8 \\u2062 ( s , a ) = \\u03c0 \\u03b8 \\u2062 ( s , g \\u03b8 \\u2062 ( s , \\u03f5 ) ) = P \\u00af \\u03b8 \\u2062 ( s , \\u03f5 ) subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\u00af \\ud835\\udc43 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\\\pi_{\\\\theta}(s,a)=\\\\pi_{\\\\theta}(s,g_{\\\\theta}(s,\\\\epsilon))=\\\\bar{P}_{\\\\theta}(s,\\\\epsilon) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) = italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) = over\\u00af start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) . The inverse holds trivially. 7.1.2 Proof of Lemma 4.2 First, we show that f \\ud835\\udc53 f italic_f is an injective function by showing that the determinant of Jacobian \\u2202 f \\u2202 a \\ud835\\udc53 \\ud835\\udc4e \\\\frac{\\\\partial f}{\\\\partial a} divide start_ARG \\u2202 italic_f end_ARG start_ARG \\u2202 italic_a end_ARG is always positive: det ( \\u2202 f \\u2202 a ) \\ud835\\udc53 \\ud835\\udc4e \\\\displaystyle\\\\det({\\\\frac{\\\\partial f}{\\\\partial a}}) roman_det ( divide start_ARG \\u2202 italic_f end_ARG start_ARG \\u2202 italic_a end_ARG ) = det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) absent \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle=\\\\det({I+\\\\alpha\\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)}) = roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) = \\u03a0 i = 1 n ( 1 + \\u03b1 \\u22c5 \\u03bb i ( s , a ) ) > 0 ( \\u2235 | \\u03b1 | < 1 max ( s , a ) \\u2061 | \\u03bb 1 \\u2062 ( s , a ) | ) , \\\\displaystyle=\\\\Pi_{i=1}^{n}(1+\\\\alpha\\\\cdot\\\\lambda_{i}(s,a))>0\\\\quad(\\\\because|% \\\\alpha|<\\\\frac{1}{\\\\max_{(s,a)}\\\\lvert\\\\lambda_{1}(s,a)\\\\rvert}), = roman_\\u03a0 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( 1 + italic_\\u03b1 \\u22c5 italic_\\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_s , italic_a ) ) > 0 ( \\u2235 | italic_\\u03b1 | < divide start_ARG 1 end_ARG start_ARG roman_max start_POSTSUBSCRIPT ( italic_s , italic_a ) end_POSTSUBSCRIPT | italic_\\u03bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s , italic_a ) | end_ARG ) , where \\u03bb i \\u2062 ( s , a ) subscript \\ud835\\udf06 \\ud835\\udc56 \\ud835\\udc60 \\ud835\\udc4e \\\\lambda_{i}(s,a) italic_\\u03bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_s , italic_a ) are the eigenvalues of \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a) \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) sorted in ascending order. Then, for an arbitrary open set of action T \\u2282 A \\ud835\\udc47 \\ud835\\udc34 T\\\\subset A italic_T \\u2282 italic_A , \\u03c0 \\u03b1 \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 \\u22c5 \\\\pi_{\\\\alpha}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) selects T ~ = f \\u2062 ( T ) \\u2282 A ~ \\ud835\\udc47 \\ud835\\udc53 \\ud835\\udc47 \\ud835\\udc34 \\\\tilde{T}=f(T)\\\\subset A over~ start_ARG italic_T end_ARG = italic_f ( italic_T ) \\u2282 italic_A with the same probability that the original policy \\u03c0 \\u03b8 \\u00af \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\u22c5 \\\\pi_{\\\\bar{\\\\theta}}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) selects T \\ud835\\udc47 T italic_T . \\u222b T ~ \\u03c0 \\u03b1 \\u2062 ( s , a ~ ) \\u2062 \\ud835\\udc51 a ~ subscript ~ \\ud835\\udc47 subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udc4e differential-d ~ \\ud835\\udc4e \\\\displaystyle\\\\int_{\\\\tilde{T}}\\\\pi_{\\\\alpha}(s,\\\\tilde{a})d\\\\tilde{a} \\u222b start_POSTSUBSCRIPT over~ start_ARG italic_T end_ARG end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) italic_d over~ start_ARG italic_a end_ARG = \\u222b T \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) | det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | \\u22c5 | det ( \\u2202 f \\u2202 a ) | \\u2062 \\ud835\\udc51 a absent subscript \\ud835\\udc47 \\u22c5 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc53 \\ud835\\udc4e differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{T}\\\\frac{\\\\pi_{\\\\bar{\\\\theta}}(s,a)}{\\\\lvert\\\\det(I+\\\\alpha\\\\nabla% _{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a))\\\\rvert}\\\\cdot\\\\Big{\\\\lvert}\\\\det(\\\\frac{% \\\\partial f}{\\\\partial a})\\\\Big{\\\\rvert}da = \\u222b start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG start_ARG | roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | end_ARG \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_f end_ARG start_ARG \\u2202 italic_a end_ARG ) | italic_d italic_a = \\u222b T \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) | det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | \\u22c5 | det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | \\u2062 \\ud835\\udc51 a absent subscript \\ud835\\udc47 \\u22c5 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{T}\\\\frac{\\\\pi_{\\\\bar{\\\\theta}}(s,a)}{\\\\lvert\\\\det(I+\\\\alpha\\\\nabla% _{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a))\\\\rvert}\\\\cdot\\\\Big{\\\\lvert}\\\\det({I+\\\\alpha% \\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)})\\\\Big{\\\\rvert}da = \\u222b start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG start_ARG | roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | end_ARG \\u22c5 | roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | italic_d italic_a = \\u222b T \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 \\ud835\\udc51 a . absent subscript \\ud835\\udc47 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{T}\\\\pi_{\\\\bar{\\\\theta}}(s,a)da. = \\u222b start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_d italic_a . Therefore, \\u03c0 \\u03b1 \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 \\u22c5 \\\\pi_{\\\\alpha}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) is a valid probability distribution as \\u03c0 \\u03b8 \\u00af \\u2062 ( s , \\u22c5 ) subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\u22c5 \\\\pi_{\\\\bar{\\\\theta}}(s,\\\\cdot) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) . 7.1.3 Proof of Proposition 4.3 For a given state s \\ud835\\udc60 s italic_s , we can estimate the (approximate) expected value of the state under \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT as follows. \\u222b a ~ \\u03c0 \\u03b1 \\u2062 ( s , a ~ ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ~ ) \\u2062 \\ud835\\udc51 a ~ subscript ~ \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 ~ \\ud835\\udc4e differential-d ~ \\ud835\\udc4e \\\\displaystyle\\\\quad\\\\int_{\\\\tilde{a}}\\\\pi_{\\\\alpha}(s,\\\\tilde{a})A_{\\\\pi_{\\\\bar{\\\\theta% }}}(s,\\\\tilde{a})d\\\\tilde{a} \\u222b start_POSTSUBSCRIPT over~ start_ARG italic_a end_ARG end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) italic_d over~ start_ARG italic_a end_ARG = \\u222b a \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) | det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a + \\u03b1 \\u2062 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\u2062 | det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | \\u2062 \\ud835\\udc51 a absent subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udefc subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{a}\\\\frac{\\\\pi_{\\\\bar{\\\\theta}}(s,a)}{\\\\lvert\\\\det(I+\\\\alpha\\\\nabla% _{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a))\\\\rvert}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a+\\\\alpha% \\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a))\\\\lvert\\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_% {\\\\bar{\\\\theta}}}(s,a))\\\\rvert da = \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG start_ARG | roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | end_ARG italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | italic_d italic_a \\u2248 \\u222b a \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 [ A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) + \\u03b1 \\u2062 \\u2016 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2016 2 ] \\u2062 \\ud835\\udc51 a absent subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e delimited-[] subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udefc superscript norm subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e 2 differential-d \\ud835\\udc4e \\\\displaystyle\\\\approx\\\\int_{a}\\\\pi_{\\\\bar{\\\\theta}}(s,a)\\\\left[A_{\\\\pi_{\\\\bar{\\\\theta}}% }(s,a)+\\\\alpha{||\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)||}^{2}\\\\right]da \\u2248 \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) [ italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) + italic_\\u03b1 | | \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] italic_d italic_a = \\u222b a \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 \\ud835\\udc51 a + \\u03b1 \\u2062 \\u222b a \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 \\u2016 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2016 2 \\u2062 \\ud835\\udc51 a . absent subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e differential-d \\ud835\\udc4e \\ud835\\udefc subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e superscript norm subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e 2 differential-d \\ud835\\udc4e \\\\displaystyle=\\\\int_{a}\\\\pi_{\\\\bar{\\\\theta}}(s,a)A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)da+% \\\\alpha\\\\int_{a}\\\\pi_{\\\\bar{\\\\theta}}(s,a)||\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)||% ^{2}da. = \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_d italic_a + italic_\\u03b1 \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) | | \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_a . Therefore, we can see the following holds: L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b1 ) subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udefc \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\alpha}) italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) = \\u222b s \\u03c1 \\u03c0 \\u03b8 \\u00af \\u2062 ( s ) \\u2062 \\u222b a ~ \\u03c0 \\u03b1 \\u2062 ( s , a ~ ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ~ ) \\u2062 \\ud835\\udc51 a ~ absent subscript \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript ~ \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 ~ \\ud835\\udc4e differential-d ~ \\ud835\\udc4e \\\\displaystyle=\\\\int_{s}\\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}}(s)\\\\int_{\\\\tilde{a}}\\\\pi_{\\\\alpha}% (s,\\\\tilde{a})A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,\\\\tilde{a})d\\\\tilde{a} = \\u222b start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) \\u222b start_POSTSUBSCRIPT over~ start_ARG italic_a end_ARG end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_a end_ARG ) italic_d over~ start_ARG italic_a end_ARG \\u2248 \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) + \\u03b1 \\u2062 \\u222b s \\u03c1 \\u03c0 \\u03b8 \\u00af \\u2062 ( s ) \\u2062 \\u222b a \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2062 \\u2016 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2016 2 \\u2062 \\ud835\\udc51 a . absent \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udefc subscript \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e superscript norm subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e 2 differential-d \\ud835\\udc4e \\\\displaystyle\\\\approx\\\\eta(\\\\pi_{\\\\bar{\\\\theta}})+\\\\alpha\\\\int_{s}\\\\rho_{\\\\pi_{\\\\bar{% \\\\theta}}}(s)\\\\int_{a}\\\\pi_{\\\\bar{\\\\theta}}(s,a)||\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(% s,a)||^{2}da. \\u2248 italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) + italic_\\u03b1 \\u222b start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) | | \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d italic_a . Since \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\pi_{\\\\bar{\\\\theta}}(s,a) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) and \\u2016 \\u2207 a A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u2016 2 superscript norm subscript \\u2207 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e 2 ||\\\\nabla_{a}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)||^{2} | | \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT are positive, L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b1 ) subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udefc L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\alpha}) italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) is greater or equal to \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\eta(\\\\pi_{\\\\bar{\\\\theta}}) italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) when \\u03b1 > 0 \\ud835\\udefc 0 \\\\alpha>0 italic_\\u03b1 > 0 . On the contrary, when \\u03b1 < 0 \\ud835\\udefc 0 \\\\alpha<0 italic_\\u03b1 < 0 , L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b1 ) subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udefc L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\alpha}) italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) is smaller or equal to \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\eta(\\\\pi_{\\\\bar{\\\\theta}}) italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) . Since this argument builds upon local approximation, it holds only when | \\u03b1 | \\u226a 1 much-less-than \\ud835\\udefc 1 |\\\\alpha|\\\\ll 1 | italic_\\u03b1 | \\u226a 1 . 7.1.4 Proof of Lemma 4.4 When a = g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\ud835\\udc4e subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 a=g_{\\\\bar{\\\\theta}}(s,\\\\epsilon) italic_a = italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) , g \\u03b1 \\u2062 ( s , \\u03f5 ) subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 \\\\displaystyle g_{\\\\alpha}(s,\\\\epsilon) italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) = g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) + \\u03b1 \\u22c5 \\u2207 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) ) absent subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\u22c5 \\ud835\\udefc subscript \\u2207 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 \\\\displaystyle=g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)+\\\\alpha\\\\cdot\\\\nabla_{g_{\\\\bar{\\\\theta}}% (s,\\\\epsilon)}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)) = italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) \\u21d2 \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 \\u21d2 absent subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle\\\\Rightarrow\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon)}{\\\\partial\\\\epsilon} \\u21d2 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG = \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 + \\u03b1 \\u22c5 \\u2207 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) ) \\u22c5 \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 absent subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\u22c5 \\u22c5 \\ud835\\udefc superscript subscript \\u2207 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle=\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial\\\\epsilon}+% \\\\alpha\\\\cdot\\\\nabla_{g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,g% _{\\\\bar{\\\\theta}}(s,\\\\epsilon))\\\\cdot\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{% \\\\partial\\\\epsilon} = divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG = ( I + \\u03b1 \\u22c5 \\u2207 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) ) ) \\u22c5 \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 absent \\u22c5 \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle=\\\\Big{(}I+\\\\alpha\\\\cdot\\\\nabla_{g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}^{2}A_{% \\\\pi_{\\\\bar{\\\\theta}}}(s,g_{\\\\bar{\\\\theta}}(s,\\\\epsilon))\\\\Big{)}\\\\cdot\\\\frac{\\\\partial g% _{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial\\\\epsilon} = ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) ) \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG \\u21d2 det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) \\u21d2 absent subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle\\\\Rightarrow\\\\det\\\\Big{(}\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon)}{% \\\\partial\\\\epsilon}\\\\Big{)} \\u21d2 roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) = det ( I + \\u03b1 \\u22c5 \\u2207 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) ) ) \\u22c5 det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) absent \\u22c5 \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle=\\\\det\\\\Big{(}I+\\\\alpha\\\\cdot\\\\nabla_{g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}^{2% }A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,g_{\\\\bar{\\\\theta}}(s,\\\\epsilon))\\\\Big{)}\\\\cdot\\\\det\\\\Big{(}% \\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial\\\\epsilon}\\\\Big{)} = roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) ) ) \\u22c5 roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) = det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\u22c5 det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) . absent \\u22c5 \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\displaystyle=\\\\det\\\\Big{(}I+\\\\alpha\\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a% )\\\\Big{)}\\\\cdot\\\\det\\\\Big{(}\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial% \\\\epsilon}\\\\Big{)}. = roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) \\u22c5 roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) . Since | det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | > 0 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 0 \\\\Big{\\\\lvert}\\\\det\\\\Big{(}\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial% \\\\epsilon}\\\\Big{)}\\\\Big{\\\\rvert}>0 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | > 0 (Equation 3 ), we can divide both sides of the above equation with det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 \\\\det\\\\Big{(}\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial\\\\epsilon}\\\\Big{)} roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) and prove Lemma 4.4 . 7.1.5 Proof of Lemma 4.6 From Equation 11 , \\u2207 a A ^ \\u03c0 \\u03b8 \\u2062 ( s t , a t ) = 1 2 \\u2062 \\ud835\\udd3c s t , a t , \\u2026 \\u223c \\u03c0 \\u03b8 \\u2062 [ \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 r \\u2062 ( s k , a k ) \\u2202 a t ] , subscript \\u2207 \\ud835\\udc4e subscript ^ \\ud835\\udc34 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 1 2 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 delimited-[] superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\displaystyle\\\\nabla_{a}\\\\hat{A}_{\\\\pi_{\\\\theta}}(s_{t},a_{t})=\\\\frac{1}{2}\\\\mathbb{% E}_{s_{t},a_{t},...\\\\sim\\\\pi_{\\\\theta}}\\\\Big{[}\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}\\\\frac{% \\\\partial r(s_{k},a_{k})}{\\\\partial a_{t}}\\\\Big{]}, \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ] , which can be rewritten using g \\u03b8 subscript \\ud835\\udc54 \\ud835\\udf03 g_{\\\\theta} italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT as follows. \\u2207 a A ^ \\u03c0 \\u03b8 \\u2062 ( s t , a t ) = 1 2 \\u2062 \\ud835\\udd3c s t , \\u03f5 t , \\u2026 \\u223c q \\u2062 [ \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 r \\u2062 ( s k , g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ] . subscript \\u2207 \\ud835\\udc4e subscript ^ \\ud835\\udc34 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 1 2 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle\\\\nabla_{a}\\\\hat{A}_{\\\\pi_{\\\\theta}}(s_{t},a_{t})=\\\\frac{1}{2}\\\\mathbb{% E}_{s_{t},\\\\epsilon_{t},...\\\\sim q}\\\\Big{[}\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}\\\\frac{% \\\\partial r(s_{k},g_{\\\\theta}(s_{t},\\\\epsilon_{t}))}{\\\\partial g_{\\\\theta}(s_{t},% \\\\epsilon_{t})}\\\\Big{]}. \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ] . (13) Then, by differentiating Equation 10 with respect to \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 after plugging in A ^ ^ \\ud835\\udc34 \\\\hat{A} over^ start_ARG italic_A end_ARG , we can get following relationship: \\u2202 L \\u2062 ( \\u03b8 ) \\u2202 \\u03b8 \\ud835\\udc3f \\ud835\\udf03 \\ud835\\udf03 \\\\displaystyle\\\\frac{\\\\partial L(\\\\theta)}{\\\\partial\\\\theta} divide start_ARG \\u2202 italic_L ( italic_\\u03b8 ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 , \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e 2 \\u22c5 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u22c5 ( g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2212 g \\u03b1 \\u2062 ( s t , \\u03f5 t ) ) ] absent subscript \\ud835\\udd3c subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 similar-to absent \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 \\u22c5 2 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udefc subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...,\\\\sim q}\\\\Big{[}\\\\sum_{t=0}^{% \\\\infty}2\\\\cdot\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial\\\\theta}% \\\\cdot(g_{\\\\theta}(s_{t},\\\\epsilon_{t})-g_{\\\\alpha}(s_{t},\\\\epsilon_{t}))\\\\Big{]} = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 , \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT 2 \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u22c5 ( italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 , \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e 2 \\u22c5 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u22c5 ( g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2212 ( g \\u03b8 \\u2062 ( s t , \\u03f5 t ) + \\u2207 a A ^ \\u03c0 \\u03b8 \\u2062 ( s t , a t ) ) ) ] absent subscript \\ud835\\udd3c subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 similar-to absent \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 \\u22c5 2 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\u2207 \\ud835\\udc4e subscript ^ \\ud835\\udc34 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...,\\\\sim q}\\\\Big{[}\\\\sum_{t=0}^{% \\\\infty}2\\\\cdot\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial\\\\theta}% \\\\cdot(g_{\\\\theta}(s_{t},\\\\epsilon_{t})-(g_{\\\\theta}(s_{t},\\\\epsilon_{t})+\\\\nabla_{a% }\\\\hat{A}_{\\\\pi_{\\\\theta}}(s_{t},a_{t})))\\\\Big{]} = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 , \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT 2 \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u22c5 ( italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - ( italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) + \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ) ] ( \\u2235 \\u03b1 = 1 ) \\\\displaystyle(\\\\because\\\\alpha=1) ( \\u2235 italic_\\u03b1 = 1 ) = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 , \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2212 2 \\u22c5 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u22c5 \\u2207 a A ^ \\u03c0 \\u03b8 \\u2062 ( s t , a t ) ] absent subscript \\ud835\\udd3c subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 similar-to absent \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 \\u22c5 2 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 subscript \\u2207 \\ud835\\udc4e subscript ^ \\ud835\\udc34 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...,\\\\sim q}\\\\Big{[}\\\\sum_{t=0}^{% \\\\infty}-2\\\\cdot\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial\\\\theta}% \\\\cdot\\\\nabla_{a}\\\\hat{A}_{\\\\pi_{\\\\theta}}(s_{t},a_{t})\\\\Big{]} = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 , \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT - 2 \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 , \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2212 2 \\u22c5 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u22c5 1 2 \\u22c5 \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 r ( s k , g \\u03b8 ( s t , \\u03f5 t ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ] \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...,\\\\sim q}\\\\Big{[}\\\\sum_{t=0}^{% \\\\infty}-2\\\\cdot\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial\\\\theta}% \\\\cdot\\\\frac{1}{2}\\\\cdot\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}\\\\frac{\\\\partial r(s_{k},g_{% \\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}\\\\Big{]} = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 , \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT - 2 \\u22c5 divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u22c5 divide start_ARG 1 end_ARG start_ARG 2 end_ARG \\u22c5 \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ] ( \\u2235 Equation 13 ) \\\\displaystyle(\\\\because\\\\text{Equation~{}\\\\ref{eq:7-1-5-int0}}) ( \\u2235 Equation ) = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 , \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2211 k = t \\u221e \\u2212 \\u03b3 k \\u2062 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u22c5 \\u2202 r \\u2062 ( s k , g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ] , absent subscript \\ud835\\udd3c subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 similar-to absent \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 superscript subscript \\ud835\\udc58 \\ud835\\udc61 \\u22c5 superscript \\ud835\\udefe \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...,\\\\sim q}\\\\Big{[}\\\\sum_{t=0}^{% \\\\infty}\\\\sum_{k=t}^{\\\\infty}-\\\\gamma^{k}\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_% {t})}{\\\\partial\\\\theta}\\\\cdot\\\\frac{\\\\partial r(s_{k},g_{\\\\theta}(s_{t},\\\\epsilon_{t}% ))}{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}\\\\Big{]}, = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 , \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT - italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u22c5 divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ] , which equals to RP gradient in Appendix 7.2.2 , but with different sign. However, they turn out to be the same because we minimize L \\u2062 ( \\u03b8 ) \\ud835\\udc3f \\ud835\\udf03 L(\\\\theta) italic_L ( italic_\\u03b8 ) , but maximize \\u03b7 \\u2062 ( \\u03c0 \\u03b8 ) \\ud835\\udf02 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\eta(\\\\pi_{\\\\theta}) italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) . Therefore, we can say that we gain RP gradient as the first gradient when we minimize Equation 10 for particular advantage function A ^ ^ \\ud835\\udc34 \\\\hat{A} over^ start_ARG italic_A end_ARG and \\u03b1 = 1 \\ud835\\udefc 1 \\\\alpha=1 italic_\\u03b1 = 1 . 7.1.6 Proof of Proposition 4.5 By Definition 4.1 and Lemma 4.4 , \\u03c0 \\u03b1 \\u2062 ( s , \\u03b1 ~ ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udefc subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle\\\\frac{\\\\pi_{\\\\alpha}(s,\\\\tilde{\\\\alpha})}{\\\\pi_{\\\\bar{\\\\theta}}(s,a)} divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_\\u03b1 end_ARG ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG = 1 | det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) | absent 1 \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle=\\\\frac{1}{|\\\\det(I+\\\\alpha\\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}% (s,a))|} = divide start_ARG 1 end_ARG start_ARG | roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) | end_ARG = | det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u22c5 | det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 , absent \\u22c5 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\displaystyle=|\\\\det(\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon)}{\\\\partial% \\\\epsilon})|\\\\cdot{|\\\\det(\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon)}{\\\\partial\\\\epsilon% })|^{-1}}, = | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , where a = g \\u03b8 \\u2062 ( s , \\u03f5 ) \\ud835\\udc4e subscript \\ud835\\udc54 \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 a=g_{\\\\theta}(s,\\\\epsilon) italic_a = italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) , and thus a ~ = g \\u03b1 \\u2062 ( s , \\u03f5 ) ~ \\ud835\\udc4e subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 \\\\tilde{a}=g_{\\\\alpha}(s,\\\\epsilon) over~ start_ARG italic_a end_ARG = italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) . Since \\u03c0 \\u03b8 \\u00af \\u225c g \\u03b8 \\u00af \\u225c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}}\\\\triangleq g_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT , following holds: \\u03c0 \\u03b1 \\u2062 ( s , \\u03b1 ~ ) subscript \\ud835\\udf0b \\ud835\\udefc \\ud835\\udc60 ~ \\ud835\\udefc \\\\displaystyle\\\\pi_{\\\\alpha}(s,\\\\tilde{\\\\alpha}) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , over~ start_ARG italic_\\u03b1 end_ARG ) = \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u22c5 | det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 absent \\u22c5 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\displaystyle=\\\\pi_{\\\\bar{\\\\theta}}(s,a)\\\\cdot|\\\\det(\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}% }(s,\\\\epsilon)}{\\\\partial\\\\epsilon})|\\\\cdot{|\\\\det(\\\\frac{\\\\partial g_{\\\\alpha}(s,% \\\\epsilon)}{\\\\partial\\\\epsilon})|^{-1}} = italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_a ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = q \\u2062 ( \\u03f5 ) \\u22c5 | det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 \\u22c5 | det ( \\u2202 g \\u03b8 \\u00af \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u22c5 | det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 absent \\u22c5 \\ud835\\udc5e italic-\\u03f5 superscript subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 subscript \\ud835\\udc54 \\u00af \\ud835\\udf03 \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\displaystyle=q(\\\\epsilon)\\\\cdot|\\\\det(\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,\\\\epsilon% )}{\\\\partial\\\\epsilon})|^{-1}\\\\cdot|\\\\det(\\\\frac{\\\\partial g_{\\\\bar{\\\\theta}}(s,% \\\\epsilon)}{\\\\partial\\\\epsilon})|\\\\cdot{|\\\\det(\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon% )}{\\\\partial\\\\epsilon})|^{-1}} = italic_q ( italic_\\u03f5 ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( \\u2235 Lemma 3.2 ) \\\\displaystyle(\\\\because\\\\text{ Lemma~{}\\\\ref{lemma-rp}}) ( \\u2235 Lemma ) = q \\u2062 ( \\u03f5 ) \\u22c5 | det ( \\u2202 g \\u03b1 \\u2062 ( s , \\u03f5 ) \\u2202 \\u03f5 ) | \\u2212 1 , absent \\u22c5 \\ud835\\udc5e italic-\\u03f5 superscript subscript \\ud835\\udc54 \\ud835\\udefc \\ud835\\udc60 italic-\\u03f5 italic-\\u03f5 1 \\\\displaystyle=q(\\\\epsilon)\\\\cdot{|\\\\det(\\\\frac{\\\\partial g_{\\\\alpha}(s,\\\\epsilon)}{% \\\\partial\\\\epsilon})|^{-1}}, = italic_q ( italic_\\u03f5 ) \\u22c5 | roman_det ( divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ( italic_s , italic_\\u03f5 ) end_ARG start_ARG \\u2202 italic_\\u03f5 end_ARG ) | start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , which implies \\u03c0 \\u03b1 \\u225c g \\u03b1 \\u225c subscript \\ud835\\udf0b \\ud835\\udefc subscript \\ud835\\udc54 \\ud835\\udefc \\\\pi_{\\\\alpha}\\\\triangleq g_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT \\u225c italic_g start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT . 7.2 Formulations 7.2.1 Analytical Gradient of Generalized Advantage Estimator (GAE) GAE [Schulman et al., 2015b ] has been widely used in many RL implementations [Schulman et al., 2017 , Raffin et al., 2021 , Makoviichuk and Makoviychuk, 2022 ] to estimate advantages. GAE finds a balance between variance and bias of the advantage estimation by computing the exponentially-weighted average of the TD residual terms ( \\u03b4 t V superscript subscript \\ud835\\udeff \\ud835\\udc61 \\ud835\\udc49 \\\\delta_{t}^{V} italic_\\u03b4 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT ) Sutton et al. [ 1998 ] , which are defined as follows: \\u03b4 t V = r t + \\u03b3 \\u2062 V \\u2062 ( s t + 1 ) \\u2212 V \\u2062 ( s t ) . superscript subscript \\ud835\\udeff \\ud835\\udc61 \\ud835\\udc49 subscript \\ud835\\udc5f \\ud835\\udc61 \\ud835\\udefe \\ud835\\udc49 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\ud835\\udc49 subscript \\ud835\\udc60 \\ud835\\udc61 \\\\delta_{t}^{V}=r_{t}+\\\\gamma V(s_{t+1})-V(s_{t}). italic_\\u03b4 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT = italic_r start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_\\u03b3 italic_V ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) - italic_V ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) . Then, GAE can be formulated as follows: A t G \\u2062 A \\u2062 E \\u2062 ( \\u03b3 , \\u03bb ) = \\u2211 k = 0 \\u221e ( \\u03b3 \\u2062 \\u03bb ) k \\u2062 \\u03b4 t + k V . superscript subscript \\ud835\\udc34 \\ud835\\udc61 \\ud835\\udc3a \\ud835\\udc34 \\ud835\\udc38 \\ud835\\udefe \\ud835\\udf06 superscript subscript \\ud835\\udc58 0 superscript \\ud835\\udefe \\ud835\\udf06 \\ud835\\udc58 superscript subscript \\ud835\\udeff \\ud835\\udc61 \\ud835\\udc58 \\ud835\\udc49 A_{t}^{GAE}(\\\\gamma,\\\\lambda)=\\\\sum_{k=0}^{\\\\infty}{(\\\\gamma\\\\lambda)}^{k}{\\\\delta_{t% +k}^{V}}. italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT ( italic_\\u03b3 , italic_\\u03bb ) = \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_\\u03b4 start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT . (14) We can compute the gradients for these terms as: \\u2202 A t G \\u2062 A \\u2062 E \\u2202 a t = \\u2211 k = 0 \\u221e ( \\u03b3 \\u2062 \\u03bb ) k \\u2062 \\u2202 \\u03b4 t + k V \\u2202 a t = ( 1 \\u03b3 \\u2062 \\u03bb ) t \\u2062 \\u2211 k = 0 \\u221e ( \\u03b3 \\u2062 \\u03bb ) t + k \\u2062 \\u2202 \\u03b4 t + k V \\u2202 a t = ( 1 \\u03b3 \\u2062 \\u03bb ) t \\u2062 [ \\u2211 k = 0 \\u221e ( \\u03b3 \\u2062 \\u03bb ) t + k \\u2062 \\u2202 \\u03b4 t + k V \\u2202 a t + \\u2211 k = 0 t \\u2212 1 ( \\u03b3 \\u2062 \\u03bb ) k \\u2062 \\u2202 \\u03b4 k V \\u2202 a t ] ( \\u2235 \\u2202 \\u03b4 k V \\u2202 a t = 0 for k < t ) = ( 1 \\u03b3 \\u2062 \\u03bb ) t \\u2062 \\u2211 k = 0 \\u221e ( \\u03b3 \\u2062 \\u03bb ) k \\u2062 \\u2202 \\u03b4 k V \\u2202 a t = ( 1 \\u03b3 \\u2062 \\u03bb ) t \\u2062 \\u2202 A 0 G \\u2062 A \\u2062 E \\u2202 a t . \\\\displaystyle\\\\begin{split}\\\\frac{\\\\partial A_{t}^{GAE}}{\\\\partial a_{t}}&=\\\\sum_{k% =0}^{\\\\infty}{(\\\\gamma\\\\lambda)}^{k}\\\\frac{\\\\partial\\\\delta_{t+k}^{V}}{\\\\partial a_{t% }}\\\\\\\\ &=(\\\\frac{1}{\\\\gamma\\\\lambda})^{t}\\\\sum_{k=0}^{\\\\infty}{(\\\\gamma\\\\lambda)}^{t+k}\\\\frac% {\\\\partial\\\\delta_{t+k}^{V}}{\\\\partial a_{t}}\\\\\\\\ &=(\\\\frac{1}{\\\\gamma\\\\lambda})^{t}\\\\left[\\\\sum_{k=0}^{\\\\infty}{(\\\\gamma\\\\lambda)}^{t+k% }\\\\frac{\\\\partial\\\\delta_{t+k}^{V}}{\\\\partial a_{t}}+\\\\sum_{k=0}^{t-1}{(\\\\gamma% \\\\lambda)}^{k}\\\\frac{\\\\partial\\\\delta_{k}^{V}}{\\\\partial a_{t}}\\\\right]\\\\\\\\ &(\\\\because\\\\frac{\\\\partial\\\\delta_{k}^{V}}{\\\\partial a_{t}}=0\\\\text{ for }k<t)\\\\\\\\ &=(\\\\frac{1}{\\\\gamma\\\\lambda})^{t}\\\\sum_{k=0}^{\\\\infty}{(\\\\gamma\\\\lambda)}^{k}\\\\frac{% \\\\partial\\\\delta_{k}^{V}}{\\\\partial a_{t}}\\\\\\\\ &=(\\\\frac{1}{\\\\gamma\\\\lambda})^{t}\\\\frac{\\\\partial A_{0}^{GAE}}{\\\\partial a_{t}}.% \\\\end{split} start_ROW start_CELL divide start_ARG \\u2202 italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_CELL start_CELL = \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = ( divide start_ARG 1 end_ARG start_ARG italic_\\u03b3 italic_\\u03bb end_ARG ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_t + italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = ( divide start_ARG 1 end_ARG start_ARG italic_\\u03b3 italic_\\u03bb end_ARG ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_t + italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_t + italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG + \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ] end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL ( \\u2235 divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = 0 for italic_k < italic_t ) end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = ( divide start_ARG 1 end_ARG start_ARG italic_\\u03b3 italic_\\u03bb end_ARG ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT ( italic_\\u03b3 italic_\\u03bb ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_\\u03b4 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL = ( divide start_ARG 1 end_ARG start_ARG italic_\\u03b3 italic_\\u03bb end_ARG ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG . end_CELL end_ROW (15) Based on this relationship, we can compute every \\u2202 A t G \\u2062 A \\u2062 E \\u2202 a t superscript subscript \\ud835\\udc34 \\ud835\\udc61 \\ud835\\udc3a \\ud835\\udc34 \\ud835\\udc38 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\frac{\\\\partial A_{t}^{GAE}}{\\\\partial a_{t}} divide start_ARG \\u2202 italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG with only one backpropagation of A 0 G \\u2062 A \\u2062 E superscript subscript \\ud835\\udc34 0 \\ud835\\udc3a \\ud835\\udc34 \\ud835\\udc38 A_{0}^{GAE} italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT , rather than backpropagating for every A t G \\u2062 A \\u2062 E superscript subscript \\ud835\\udc34 \\ud835\\udc61 \\ud835\\udc3a \\ud835\\udc34 \\ud835\\udc38 A_{t}^{GAE} italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G italic_A italic_E end_POSTSUPERSCRIPT . 7.2.2 RP Gradient Formulation To differentiate Equation 1 with respect to \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 , we first rewrite Equation 1 as follows. \\u03b7 \\u2062 ( \\u03c0 \\u03b8 ) \\ud835\\udf02 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\displaystyle\\\\eta(\\\\pi_{\\\\theta}) italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = \\ud835\\udd3c s 0 , a 0 , \\u2026 \\u223c \\u03c0 \\u03b8 \\u2062 [ \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( s t , a t ) ] absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 delimited-[] superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},a_{0},...\\\\sim\\\\pi_{\\\\theta}}\\\\left[\\\\sum_{t=0}^{% \\\\infty}\\\\gamma^{t}r(s_{t},a_{t})\\\\right] = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( s t , g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ) ] . absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[\\\\sum_{t=0}^{% \\\\infty}\\\\gamma^{t}r(s_{t},g_{\\\\theta}(s_{t},\\\\epsilon_{t}))\\\\right]. = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] . Then, we can compute RP gradient as follows. \\u2202 \\u03b7 \\u2062 ( \\u03c0 \\u03b8 ) \\u2202 \\u03b8 \\ud835\\udf02 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udf03 \\\\displaystyle\\\\frac{\\\\partial\\\\eta(\\\\pi_{\\\\theta})}{\\\\partial\\\\theta} divide start_ARG \\u2202 italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG = \\u2202 \\u2202 \\u03b8 \\u2062 \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( s t , g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ) ] absent \\ud835\\udf03 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\frac{\\\\partial}{\\\\partial\\\\theta}\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},..% .\\\\sim q}\\\\left[\\\\sum_{t=0}^{\\\\infty}\\\\gamma^{t}r(s_{t},g_{\\\\theta}(s_{t},\\\\epsilon_{% t}))\\\\right] = divide start_ARG \\u2202 end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2202 \\u2202 \\u03b8 \\u2062 \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( s t , g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ) ] absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] \\ud835\\udf03 superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[\\\\frac{\\\\partial}{% \\\\partial\\\\theta}\\\\sum_{t=0}^{\\\\infty}\\\\gamma^{t}r(s_{t},g_{\\\\theta}(s_{t},\\\\epsilon_% {t}))\\\\right] = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ divide start_ARG \\u2202 end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u2062 \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 r \\u2062 ( s k , g \\u03b8 \\u2062 ( s k , \\u03f5 k ) ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ] absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc58 subscript italic-\\u03f5 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[\\\\sum_{t=0}^{% \\\\infty}\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}{\\\\partial\\\\theta}\\\\sum_{k=t% }^{\\\\infty}\\\\gamma^{k}\\\\frac{\\\\partial r(s_{k},g_{\\\\theta}(s_{k},\\\\epsilon_{k}))}{% \\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}\\\\right] = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ] ( \\u2235 \\u2202 r \\u2062 ( s k , g \\u03b8 \\u2062 ( s k , \\u03f5 k ) ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2260 0 only when k \\u2265 t . ) \\\\displaystyle(\\\\because\\\\frac{\\\\partial r(s_{k},g_{\\\\theta}(s_{k},\\\\epsilon_{k}))}{% \\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}\\\\neq 0\\\\text{ only when }k\\\\geq t.) ( \\u2235 divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG \\u2260 0 only when italic_k \\u2265 italic_t . ) = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u2062 \\u2202 r \\u2062 ( s k , g \\u03b8 \\u2062 ( s k , \\u03f5 k ) ) \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) ] absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc58 subscript italic-\\u03f5 \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[\\\\sum_{t=0}^{% \\\\infty}\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{% t})}{\\\\partial\\\\theta}\\\\frac{\\\\partial r(s_{k},g_{\\\\theta}(s_{k},\\\\epsilon_{k}))}{% \\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{t})}\\\\right] = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ) end_ARG start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG ] = \\ud835\\udd3c s 0 , \\u03f5 0 , \\u2026 \\u223c q \\u2062 [ \\u2211 t = 0 \\u221e \\u2211 k = t \\u221e \\u03b3 k \\u2062 \\u2202 g \\u03b8 \\u2062 ( s t , \\u03f5 t ) \\u2202 \\u03b8 \\u2062 \\u2202 r \\u2062 ( s k , a k ) \\u2202 a t ] . absent subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript italic-\\u03f5 0 \\u2026 \\ud835\\udc5e delimited-[] superscript subscript \\ud835\\udc61 0 superscript subscript \\ud835\\udc58 \\ud835\\udc61 superscript \\ud835\\udefe \\ud835\\udc58 subscript \\ud835\\udc54 \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc61 subscript italic-\\u03f5 \\ud835\\udc61 \\ud835\\udf03 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc58 subscript \\ud835\\udc4e \\ud835\\udc61 \\\\displaystyle=\\\\mathbb{E}_{s_{0},\\\\epsilon_{0},...\\\\sim q}\\\\left[\\\\sum_{t=0}^{% \\\\infty}\\\\sum_{k=t}^{\\\\infty}\\\\gamma^{k}\\\\frac{\\\\partial g_{\\\\theta}(s_{t},\\\\epsilon_{% t})}{\\\\partial\\\\theta}\\\\frac{\\\\partial r(s_{k},a_{k})}{\\\\partial a_{t}}\\\\right]. = blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_q end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT \\u2211 start_POSTSUBSCRIPT italic_k = italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG \\u2202 italic_g start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_\\u03f5 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG divide start_ARG \\u2202 italic_r ( italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ] . We can estimate this RP gradient using Monte Carlo sampling and terms in Equation 2 , and use it for gradient ascent to maximize Equation 1 . 7.2.3 Estimator for Equation 4 Since \\u03b7 \\u2062 ( \\u03c0 \\u03b8 \\u00af ) \\ud835\\udf02 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\eta(\\\\pi_{\\\\bar{\\\\theta}}) italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ) does not depend on \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 , we can ignore the term and rewrite our loss function in Equation 4 using expectation as follows: L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b8 ) subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\theta}) italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = \\u222b s \\u03c1 \\u03c0 \\u03b8 \\u00af \\u2062 ( s ) \\u2062 \\u222b a \\u03c0 \\u03b8 \\u2062 ( s , a ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) absent subscript \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 subscript \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle=\\\\int_{s}\\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}}(s)\\\\int_{a}\\\\pi_{\\\\theta}(s,a)A_{% \\\\pi_{\\\\bar{\\\\theta}}}(s,a) = \\u222b start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s ) \\u222b start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) = \\ud835\\udd3c s \\u223c \\u03c1 \\u03c0 \\u03b8 \\u00af , a \\u223c \\u03c0 \\u03b8 \\u2062 ( s , \\u22c5 ) \\u2062 [ A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ] . absent subscript \\ud835\\udd3c formulae-sequence similar-to \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 similar-to \\ud835\\udc4e subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\u22c5 delimited-[] subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle=\\\\mathbb{E}_{s\\\\sim\\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}},a\\\\sim\\\\pi_{\\\\theta}(s,% \\\\cdot)}\\\\Big{[}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)\\\\Big{]}. = blackboard_E start_POSTSUBSCRIPT italic_s \\u223c italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_a \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , \\u22c5 ) end_POSTSUBSCRIPT [ italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ] . However, note that we did not collect trajectories, or experience buffer, using \\u03c0 \\u03b8 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\pi_{\\\\theta} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT . Therefore, we use another importance sampling function q \\u2062 ( s , a ) \\ud835\\udc5e \\ud835\\udc60 \\ud835\\udc4e q(s,a) italic_q ( italic_s , italic_a ) [Schulman et al., 2015a ] . L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b8 ) subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udf03 \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\theta}) italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) = \\ud835\\udd3c s \\u223c \\u03c1 \\u03c0 \\u03b8 \\u00af , a \\u223c q \\u2062 ( s , \\u22c5 ) \\u2062 [ \\u03c0 \\u03b8 \\u2062 ( s , a ) q \\u2062 ( s , a ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ] . absent subscript \\ud835\\udd3c formulae-sequence similar-to \\ud835\\udc60 subscript \\ud835\\udf0c subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 similar-to \\ud835\\udc4e \\ud835\\udc5e \\ud835\\udc60 \\u22c5 delimited-[] subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\ud835\\udc5e \\ud835\\udc60 \\ud835\\udc4e subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\displaystyle=\\\\mathbb{E}_{s\\\\sim\\\\rho_{\\\\pi_{\\\\bar{\\\\theta}}},a\\\\sim q(s,\\\\cdot)}\\\\Big% {[}\\\\frac{\\\\pi_{\\\\theta}(s,a)}{q(s,a)}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)\\\\Big{]}. = blackboard_E start_POSTSUBSCRIPT italic_s \\u223c italic_\\u03c1 start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_a \\u223c italic_q ( italic_s , \\u22c5 ) end_POSTSUBSCRIPT [ divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s , italic_a ) end_ARG start_ARG italic_q ( italic_s , italic_a ) end_ARG italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ] . Then, we can estimate this value using Monte Carlo estimation as follows, where B \\ud835\\udc35 B italic_B is the experience buffer of size N \\ud835\\udc41 N italic_N , which stores state ( s i subscript \\ud835\\udc60 \\ud835\\udc56 s_{i} italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), action ( a i subscript \\ud835\\udc4e \\ud835\\udc56 a_{i} italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), and their corresponding advantage value ( A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 A_{\\\\pi_{\\\\bar{\\\\theta}}}(s_{i},a_{i}) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) obtained by following policy \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT : L \\u03c0 \\u03b8 \\u00af \\u2062 ( \\u03c0 \\u03b8 ) \\u2248 1 N \\u2062 \\u2211 i = 1 N \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) . subscript \\ud835\\udc3f subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udf0b \\ud835\\udf03 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\displaystyle L_{\\\\pi_{\\\\bar{\\\\theta}}}(\\\\pi_{\\\\theta})\\\\approx\\\\frac{1}{N}\\\\sum_{i=1}% ^{N}\\\\frac{\\\\pi_{\\\\theta}(s_{i},a_{i})}{\\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i})}A_{\\\\pi_{% \\\\bar{\\\\theta}}}(s_{i},a_{i}). italic_L start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) \\u2248 divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . (16) Note that we used \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT in the place of q \\ud835\\udc5e q italic_q , as it is the most natural importance sampling function we can use [Schulman et al., 2015a , 2017 ] . 7.3 Algorithm Here we present the details of our algorithm in Section 4.3 . To be specific, we present 1) an empirical evidence to validate our strategy to control \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 , 2) the exact loss function that we use in PPO update, and 3) provide the change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 during real training to help understanding. 7.3.1 Empirical evidence In Section 4.3 , we argued that the estimate of det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) is related to the sample variance of analytical gradients, and we can get the estimate using Lemma 4.4 . In Figure 5 , we empirically prove the validity of this argument in the differentiable physics environments used in Section 5.2 . In the illustration, we can observe a clear relationship between the sample variance of analytical gradients and the statistics of our estimates. Therefore, we can use these estimates as a cue to control \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 based on the variance of analytical gradients. (a) Cartpole (b) Ant (c) Hopper Figure 5 : The first row shows the sample variance of analytical gradients ( \\u2202 A \\u2202 a ) \\ud835\\udc34 \\ud835\\udc4e (\\\\frac{\\\\partial A}{\\\\partial a}) ( divide start_ARG \\u2202 italic_A end_ARG start_ARG \\u2202 italic_a end_ARG ) , and the second row shows the statistics of estimates of det ( I + \\u03b1 \\u2062 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) for every state-action pair in the buffer after each epoch of training in 3 different differentiable physics environments (Cartpole, Ant, and Hopper). We used a fixed \\u03b1 = 10 \\u2212 2 \\ud835\\udefc superscript 10 2 \\\\alpha=10^{-2} italic_\\u03b1 = 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT . Note that the minimum and maximum estimates in the second row exhibit a clear tendency to deviate from 1 more as the sample variance increases. 7.3.2 Loss function for PPO Update As discussed in Section 3.3.2 , PPO finds a better policy in the proximity of the original policy by restricting the ratio of probabilities \\u03c0 \\u03b8 \\u2062 ( s i , a i ) subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\pi_{\\\\theta}(s_{i},a_{i}) italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i}) italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , as shown in Equation 5 . In fact, PPO uses following surrogate loss function, which is a modified version of Equation 16 , to mandate this: L P \\u2062 P \\u2062 O \\u2062 ( \\u03b8 ) = 1 N \\u2062 \\u2211 i = 1 N min \\u2061 ( \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) , c \\u2062 l \\u2062 i \\u2062 p \\u2062 ( \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) , 1 \\u2212 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p , 1 + \\u03f5 c \\u2062 l \\u2062 i \\u2062 p ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) ) . subscript \\ud835\\udc3f \\ud835\\udc43 \\ud835\\udc43 \\ud835\\udc42 \\ud835\\udf03 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\displaystyle L_{PPO}(\\\\theta)=\\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\min(\\\\frac{\\\\pi_{\\\\theta}% (s_{i},a_{i})}{\\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i})}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s_{i},a_% {i}),clip(\\\\frac{\\\\pi_{\\\\theta}(s_{i},a_{i})}{\\\\pi_{\\\\bar{\\\\theta}}(s_{i},a_{i})},1-% \\\\epsilon_{clip},1+\\\\epsilon_{clip})A_{\\\\pi_{\\\\bar{\\\\theta}}}(s_{i},a_{i})). italic_L start_POSTSUBSCRIPT italic_P italic_P italic_O end_POSTSUBSCRIPT ( italic_\\u03b8 ) = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_min ( divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_c italic_l italic_i italic_p ( divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG , 1 - italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT , 1 + italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) . (17) Note that if out-of-range-ratio defined in Equation 12 is already 1.0, which corresponds to an extreme case, the gradient of L P \\u2062 P \\u2062 O \\u2062 ( \\u03b8 ) subscript \\ud835\\udc3f \\ud835\\udc43 \\ud835\\udc43 \\ud835\\udc42 \\ud835\\udf03 L_{PPO}(\\\\theta) italic_L start_POSTSUBSCRIPT italic_P italic_P italic_O end_POSTSUBSCRIPT ( italic_\\u03b8 ) with respect to \\u03b8 \\ud835\\udf03 \\\\theta italic_\\u03b8 is 0. Therefore, PPO does not contribute to the policy update at all in this case. It justifies our decision to upper bound out-of-range-ratio by restricting \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 . Also note that we proposed to use a virtual policy \\u03c0 h subscript \\ud835\\udf0b \\u210e \\\\pi_{h} italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT instead of \\u03c0 \\u03b8 \\u00af subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\\\pi_{\\\\bar{\\\\theta}} italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT in Section 4.3.2 to restrict PPO update to be done around \\u03c0 \\u03b1 subscript \\ud835\\udf0b \\ud835\\udefc \\\\pi_{\\\\alpha} italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT . This changes the importance sampling function in Equation 17 as follows, which corresponds to our final surrogate loss function to use in PPO update: L G \\u2062 I \\u2062 P \\u2062 P \\u2062 O \\u2062 ( \\u03b8 ) = 1 N \\u2062 \\u2211 i = 1 N min \\u2061 ( \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 h \\u2062 ( s i , a i ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) , c \\u2062 l \\u2062 i \\u2062 p \\u2062 ( \\u03c0 \\u03b8 \\u2062 ( s i , a i ) \\u03c0 h \\u2062 ( s i , a i ) , 1 \\u2212 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p , 1 + \\u03f5 c \\u2062 l \\u2062 i \\u2062 p ) \\u2062 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s i , a i ) ) . subscript \\ud835\\udc3f \\ud835\\udc3a \\ud835\\udc3c \\ud835\\udc43 \\ud835\\udc43 \\ud835\\udc42 \\ud835\\udf03 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u210e subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 subscript \\ud835\\udf0b \\u210e subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d 1 subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 subscript \\ud835\\udc60 \\ud835\\udc56 subscript \\ud835\\udc4e \\ud835\\udc56 \\\\displaystyle L_{GIPPO}(\\\\theta)=\\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\min(\\\\frac{\\\\pi_{% \\\\theta}(s_{i},a_{i})}{\\\\pi_{h}(s_{i},a_{i})}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s_{i},a_{i})% ,clip(\\\\frac{\\\\pi_{\\\\theta}(s_{i},a_{i})}{\\\\pi_{h}(s_{i},a_{i})},1-\\\\epsilon_{clip}% ,1+\\\\epsilon_{clip})A_{\\\\pi_{\\\\bar{\\\\theta}}}(s_{i},a_{i})). italic_L start_POSTSUBSCRIPT italic_G italic_I italic_P italic_P italic_O end_POSTSUBSCRIPT ( italic_\\u03b8 ) = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_min ( divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_c italic_l italic_i italic_p ( divide start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\\u03c0 start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG , 1 - italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT , 1 + italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT ) italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) . (18) (a) De Jong\\u2019s Function (64) (b) Ackley\\u2019s Function (64) Figure 6 : Change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 during solving function optimization problems in Section 5.1 . Since these problems are one-step problems, and observations are all the same, there is no difference between mean, min, and max of estimated determinant. (a) Statistics of training in Ant environment when \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 0.5 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 0.5 \\\\delta_{oorr}=0.5 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 0.5 . (b) Statistics of training in Ant environment when \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 1.0 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 1.0 \\\\delta_{oorr}=1.0 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 1.0 . Figure 7 : Change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 during training in Ant environment in Section 5.2 . In this environment, maximum out-of-range-ratio ( \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\delta_{oorr} italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT ) plays a major role in bounding \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 from growing. Observe that GI-PPO achieves better results than RP when we set \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 1.0 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 1.0 \\\\delta_{oorr}=1.0 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 1.0 . 7.3.3 Example: Function Optimization Problems (Section 5.1 ) Here we present how \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 changes as we solve function optimization problems in Section 5.1 with Figure 6 . There are 4 plots for each of the problems. \\u2022 Alpha: Shows change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 over training epoch. \\u2022 Estimated current performance: Shows expected additional return, which corresponds to Equation 16 ( R \\u03b1 subscript \\ud835\\udc45 \\ud835\\udefc R_{\\\\alpha} italic_R start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT in Algorithm 1 ). \\u2022 Estimate Determinant: Shows statistics of estimated det ( I + \\u03b1 \\u22c5 \\u2207 a 2 A \\u03c0 \\u03b8 \\u00af \\u2062 ( s , a ) ) \\ud835\\udc3c \\u22c5 \\ud835\\udefc superscript subscript \\u2207 \\ud835\\udc4e 2 subscript \\ud835\\udc34 subscript \\ud835\\udf0b \\u00af \\ud835\\udf03 \\ud835\\udc60 \\ud835\\udc4e \\\\det(I+\\\\alpha\\\\cdot\\\\nabla_{a}^{2}A_{\\\\pi_{\\\\bar{\\\\theta}}}(s,a)) roman_det ( italic_I + italic_\\u03b1 \\u22c5 \\u2207 start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_\\u03c0 start_POSTSUBSCRIPT over\\u00af start_ARG italic_\\u03b8 end_ARG end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_s , italic_a ) ) . \\u2022 Out of Range Ratio: Shows out-of-range-ratio in Equation 12 . For these problems, we have set \\u03b1 0 = 10 \\u2212 5 , \\u03b4 d \\u2062 e \\u2062 t = 0.4 , formulae-sequence subscript \\ud835\\udefc 0 superscript 10 5 subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 0.4 \\\\alpha_{0}=10^{-5},\\\\delta_{det}=0.4, italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT , italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT = 0.4 , and \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 0.5 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 0.5 \\\\delta_{oorr}=0.5 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 0.5 . For De Jong\\u2019s function (Figure 5(a) ), we can observe that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 shows steady increase over time, but it is mainly upper bounded by variance criterion and out-of-range-ratio. In the end, \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 stabilizes around 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT . In contrast, for Ackley\\u2019s function (Figure 5(b) ) we can see that \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 increases rapidly at first, but it soon decreases due to the variance and bias criteria. Compare these graphs with optimization curve in Figure 1(d) . Then we would be able to observe that this large \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 contributes to the faster convergence of GI-PPO compared to PPO at the early stage. However, after that, \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 decreases slowly due to the out-of-range-ratio. In the end, \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 reaches approximately 10 \\u2212 6 superscript 10 6 10^{-6} 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT , which is much lower than 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT of De Jong\\u2019s function. These observations align well with our intuition that RP gradient would play bigger role for De Jong\\u2019s function than Ackley\\u2019s function, because De Jong\\u2019s function exhibits RP gradients with much lower variance than those of Ackley\\u2019s. 7.3.4 Example: Physics Simulation Problems (Section 5.2 ) In Section 5.2 , GI-PPO could not achieve better results than RP in Ant and Hopper environments. For Ant environment, we found out that the hyperparameter \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\delta_{oorr} italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT was a bottleneck that bounds GI-PPO\\u2019s performance. In Figure 7 , we illustrated the change of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 during training along the change of out-of-range-ratio. When we set \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 0.5 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 0.5 \\\\delta_{oorr}=0.5 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 0.5 , \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 keeps decreasing over time to keep the ratio around 0.5 0.5 0.5 0.5 , which means the diminishing role of RP gradients in training. In contrast, when we set \\u03b4 o \\u2062 o \\u2062 r \\u2062 r = 1.0 subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f 1.0 \\\\delta_{oorr}=1.0 italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT = 1.0 , after 750 epochs, \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 does not decrease anymore, and out-of-range ratio stays near 1. This means that PPO rarely affects the training \\u2013 policy update is almost driven by RP gradients. Likewise, there are environments where RP gradients are much more effective than the other policy gradients. In those situations, it would be more desirable to solely depend on RP gradients without considering PPO. Since our method considers RP gradients in the PPO viewpoint, it is hard to detect such cases yet. 7.4 Experimental Details 7.4.1 Baseline Methods Here we explain implementation details of the baseline methods that were used for comparisons in Section 5 . First, we\\u2019d like to point out that we used relatively a short time horizon to collect experience, and used the critic network for bootstrapping, instead of collecting experience for the whole trajectory for all the methods. Therefore, the collected experience could be biased. However, we chose to implement in this way, because it allows faster learning than collecting the whole trajectory in terms of number of simulation steps. LR We can estimate original LR gradient as follows, using log-derivative trick [Williams and Peng, 1989 , Glynn, 1990 ] \\u2202 \\u03b7 \\u2062 ( \\u03c0 \\u03b8 ) \\u2202 \\u03b8 \\ud835\\udf02 subscript \\ud835\\udf0b \\ud835\\udf03 \\ud835\\udf03 \\\\displaystyle\\\\frac{\\\\partial\\\\eta(\\\\pi_{\\\\theta})}{\\\\partial\\\\theta} divide start_ARG \\u2202 italic_\\u03b7 ( italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ) end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG = \\u2202 \\u2202 \\u03b8 \\u2062 \\ud835\\udd3c s 0 , a 0 , \\u2026 \\u223c \\u03c0 \\u03b8 \\u2062 [ L \\u2062 ( s 0 , a 0 , \\u2026 ) \\u2062 \\u2211 t = 0 \\u221e log \\u2061 \\u03c0 \\u03b8 \\u2062 ( s 0 , a 0 ) ] absent \\ud835\\udf03 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 delimited-[] \\ud835\\udc3f subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 superscript subscript \\ud835\\udc61 0 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\\\displaystyle=\\\\frac{\\\\partial}{\\\\partial\\\\theta}\\\\mathbb{E}_{s_{0},a_{0},...\\\\sim% \\\\pi_{\\\\theta}}\\\\Big{[}L(s_{0},a_{0},...)\\\\sum_{t=0}^{\\\\infty}\\\\log\\\\pi_{\\\\theta}(s_{0% },a_{0})\\\\Big{]} = divide start_ARG \\u2202 end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_L ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 ) \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT roman_log italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) ] = \\u2202 \\u2202 \\u03b8 \\u2062 \\ud835\\udd3c s 0 , a 0 , \\u2026 \\u223c \\u03c0 \\u03b8 \\u2062 [ \\u2211 t = 0 \\u221e L \\u2062 ( s 0 , a 0 , \\u2026 ) \\u2062 log \\u2061 \\u03c0 \\u03b8 \\u2062 ( s 0 , a 0 ) ] , absent \\ud835\\udf03 subscript \\ud835\\udd3c similar-to subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 delimited-[] superscript subscript \\ud835\\udc61 0 \\ud835\\udc3f subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 subscript \\ud835\\udf0b \\ud835\\udf03 subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\\\displaystyle=\\\\frac{\\\\partial}{\\\\partial\\\\theta}\\\\mathbb{E}_{s_{0},a_{0},...\\\\sim% \\\\pi_{\\\\theta}}\\\\Big{[}\\\\sum_{t=0}^{\\\\infty}L(s_{0},a_{0},...)\\\\log\\\\pi_{\\\\theta}(s_{0% },a_{0})\\\\Big{]}, = divide start_ARG \\u2202 end_ARG start_ARG \\u2202 italic_\\u03b8 end_ARG blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 \\u223c italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_L ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 ) roman_log italic_\\u03c0 start_POSTSUBSCRIPT italic_\\u03b8 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) ] , where L \\u2062 ( s 0 , a 0 , \\u2026 ) = \\u2211 t = 0 \\u221e \\u03b3 t \\u2062 r \\u2062 ( s t , a t ) \\ud835\\udc3f subscript \\ud835\\udc60 0 subscript \\ud835\\udc4e 0 \\u2026 superscript subscript \\ud835\\udc61 0 superscript \\ud835\\udefe \\ud835\\udc61 \\ud835\\udc5f subscript \\ud835\\udc60 \\ud835\\udc61 subscript \\ud835\\udc4e \\ud835\\udc61 L(s_{0},a_{0},...)=\\\\sum_{t=0}^{\\\\infty}\\\\gamma^{t}r(s_{t},a_{t}) italic_L ( italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \\u2026 ) = \\u2211 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \\u221e end_POSTSUPERSCRIPT italic_\\u03b3 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) is the discounted accumulated return. However, this LR gradient often suffers from high variance, because L \\ud835\\udc3f L italic_L varies a lot from trajectory to trajectory. To reduce such variance and faithfully compare our method to LR gradient-based method, we decided to use advantage function in the place of L \\ud835\\udc3f L italic_L , and particularly used GAE [Schulman et al., 2015b ] as the advantage function as we used for PPO. After calculating this LR gradient, we take a gradient ascent step with pre-defined learning rate. RP By using RP gradient in Appendix 7.2.2 , we can perform gradient ascent as we did in LR. Also, because we use short time horizon and critic network, this method is very similar to SHAC [Xu et al., 2022 ] . Please refer to the paper for more details. PPO Our PPO implementation is based on that of RL Games [Makoviichuk and Makoviychuk, 2022 ] . However, to be as fair as possible, we used the same critic network as the other methods, instead of using that implemented in the RL library. Also, we omitted several other additional losses that are not vital to PPO\\u2019s formulation, such as entropy loss. LR+RP After we compute LR ( \\u2207 L \\u2062 R subscript \\u2207 \\ud835\\udc3f \\ud835\\udc45 \\\\nabla_{LR} \\u2207 start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT ) and RP ( \\u2207 R \\u2062 P subscript \\u2207 \\ud835\\udc45 \\ud835\\udc43 \\\\nabla_{RP} \\u2207 start_POSTSUBSCRIPT italic_R italic_P end_POSTSUBSCRIPT ) gradient as shown above, we can interpolate them using their sample variance as follows [Parmas et al., 2018 ] . \\u2207 L \\u2062 R + R \\u2062 P subscript \\u2207 \\ud835\\udc3f \\ud835\\udc45 \\ud835\\udc45 \\ud835\\udc43 \\\\displaystyle\\\\nabla_{LR+RP} \\u2207 start_POSTSUBSCRIPT italic_L italic_R + italic_R italic_P end_POSTSUBSCRIPT = \\u2207 L \\u2062 R \\u22c5 \\u03ba L \\u2062 R + \\u2207 R \\u2062 P \\u22c5 ( 1 \\u2212 \\u03ba L \\u2062 R ) , absent \\u22c5 subscript \\u2207 \\ud835\\udc3f \\ud835\\udc45 subscript \\ud835\\udf05 \\ud835\\udc3f \\ud835\\udc45 \\u22c5 subscript \\u2207 \\ud835\\udc45 \\ud835\\udc43 1 subscript \\ud835\\udf05 \\ud835\\udc3f \\ud835\\udc45 \\\\displaystyle=\\\\nabla_{LR}\\\\cdot\\\\kappa_{LR}+\\\\nabla_{RP}\\\\cdot(1-\\\\kappa_{LR}), = \\u2207 start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT \\u22c5 italic_\\u03ba start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT + \\u2207 start_POSTSUBSCRIPT italic_R italic_P end_POSTSUBSCRIPT \\u22c5 ( 1 - italic_\\u03ba start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT ) , \\u03ba L \\u2062 R subscript \\ud835\\udf05 \\ud835\\udc3f \\ud835\\udc45 \\\\displaystyle\\\\kappa_{LR} italic_\\u03ba start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT = \\u03c3 R \\u2062 P 2 \\u03c3 R \\u2062 P 2 + \\u03c3 L \\u2062 R 2 , absent superscript subscript \\ud835\\udf0e \\ud835\\udc45 \\ud835\\udc43 2 superscript subscript \\ud835\\udf0e \\ud835\\udc45 \\ud835\\udc43 2 superscript subscript \\ud835\\udf0e \\ud835\\udc3f \\ud835\\udc45 2 \\\\displaystyle=\\\\frac{\\\\sigma_{RP}^{2}}{\\\\sigma_{RP}^{2}+\\\\sigma_{LR}^{2}}, = divide start_ARG italic_\\u03c3 start_POSTSUBSCRIPT italic_R italic_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_\\u03c3 start_POSTSUBSCRIPT italic_R italic_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_\\u03c3 start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG , where \\u03c3 R \\u2062 P subscript \\ud835\\udf0e \\ud835\\udc45 \\ud835\\udc43 \\\\sigma_{RP} italic_\\u03c3 start_POSTSUBSCRIPT italic_R italic_P end_POSTSUBSCRIPT and \\u03c3 L \\u2062 R subscript \\ud835\\udf0e \\ud835\\udc3f \\ud835\\udc45 \\\\sigma_{LR} italic_\\u03c3 start_POSTSUBSCRIPT italic_L italic_R end_POSTSUBSCRIPT are sample standard deviation of RP and LR gradients. We gain these terms by computing trace of covariance matrix of the sample gradients from different trajectories. Since we have to compute this sample statistics, we have to do multiple different backpropagations for different trajectories, which incur a lot of computation time. Also, we found out that computing covariance matrix is also time consuming when controller has a large number of parameters. Therefore, we decided to use only limited number of sample gradients (16) to compute sample variance, and also truncate the gradient to smaller length (512) to facilitate computation. PE We tried to faithfully re-implement policy enhancement scheme of [Qiao et al., 2021 ] . 7.4.2 Network architecture and Hyperparameters In this section, we provide network architectures and hyperparameters that we used for experiments in Section 5 . For each of the experiments, we used the same network architectures, the same length of time horizons before policy update, and the same optimization procedure for critic updates, etc. We present these common settings first for each of the problems. For GI-PPO, there are hyperparameters for update towards \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy, and those for PPO update. We denote the hyperparameters for \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy update by appending ( \\u03b1 ) \\ud835\\udefc (\\\\alpha) ( italic_\\u03b1 ) , and those for PPO update by appending (PPO). For the definition of hyperparameters for \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -policy update, please see Algorithm 1 for details. Function Optimization Problems (Section 5.1 ) For these problems, common settings are as follows. \\u2022 Actor Network: MLP with [ 32 , 32 ] 32 32 [32,32] [ 32 , 32 ] layers and ELU activation function \\u2022 Critic Network: MLP with [ 32 , 32 ] 32 32 [32,32] [ 32 , 32 ] layers and ELU activation function \\u2022 Critic Hyperparameters: Learning rate = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , Iterations = 16, Batch Size = 4 \\u2022 Number of parallel environments: 64 \\u2022 Horizon Length: 1 \\u2022 \\u03b3 \\ud835\\udefe \\\\gamma italic_\\u03b3 (Discount factor): 0.99 \\u2022 \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 (GAE): 0.95 Hyperparameters for LR are as follows. \\u2022 Learning Rate: Dejong(1), Dejong(64) = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , Ackley(1) = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Ackley(64) = 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear 1 1 1 Learning rate decreases linearly to the minimum value as learning progresses. Hyperparameters for RP are as follows. \\u2022 Learning Rate: Dejong(1), Dejong(64) = 10 \\u2212 2 superscript 10 2 10^{-2} 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , Ackley(1), Ackley(64) = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for LR+RP are as follows. \\u2022 Learning Rate: Dejong(1), Dejong(64) = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , Ackley(1) = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Ackley(64) = 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for PPO are as follows. \\u2022 Learning Rate: Dejong(1), Ackley(1) = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Dejong(64), Ackley(64) = 10 \\u2212 2 superscript 10 2 10^{-2} 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Constant \\u2022 Batch Size for Actor Update: 64 \\u2022 Number of Epochs for Actor Update: 5 \\u2022 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 Hyperparameters for GI-PPO are as follows. \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Learning Rate: 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Batch Size for Actor Update: 64 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Number of Epochs for Actor Update: 16 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b1 0 subscript \\ud835\\udefc 0 \\\\alpha_{0} italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT : 10 \\u2212 5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) max \\u2061 ( \\u03b1 ) \\ud835\\udefc \\\\max(\\\\alpha) roman_max ( italic_\\u03b1 ) : 1.0 1.0 1.0 1.0 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b2 \\ud835\\udefd \\\\beta italic_\\u03b2 : 1.1 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 d \\u2062 e \\u2062 t subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 \\\\delta_{det} italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT : 0.4 0.4 0.4 0.4 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\delta_{oorr} italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT : 0.5 0.5 0.5 0.5 \\u2022 (PPO) Learning Rate: Dejong(1), Ackley(1) = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Dejong(64), Ackley(64) = 10 \\u2212 2 superscript 10 2 10^{-2} 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT \\u2022 (PPO) Learning Rate Scheduler: Constant \\u2022 (PPO) Batch Size for Actor Update: 64 \\u2022 (PPO) Number of Epochs for Actor Update: 5 \\u2022 (PPO) \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 Differentiable Physics Problems (Section 5.2 ) For these problems, common settings are as follows. \\u2022 Actor Network: MLP with [ 64 , 64 ] 64 64 [64,64] [ 64 , 64 ] (Cartpole), and [ 128 , 64 , 32 ] 128 64 32 [128,64,32] [ 128 , 64 , 32 ] (Ant, Hopper) layers and ELU activation function \\u2022 Critic Network: MLP with [ 64 , 64 ] 64 64 [64,64] [ 64 , 64 ] layers and ELU activation function \\u2022 Critic Hyperparameters: Learning rate = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT (Cartpole), 2 \\u22c5 10 \\u2212 3 \\u22c5 2 superscript 10 3 2\\\\cdot 10^{-3} 2 \\u22c5 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT (Ant), and 2 \\u22c5 10 \\u2212 4 \\u22c5 2 superscript 10 4 2\\\\cdot 10^{-4} 2 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT (Hopper), Iterations = 16, Batch Size = 4 \\u2022 Number of parallel environments: 64(Cartpole, Ant), 256(Hopper) \\u2022 Horizon Length: 32 \\u2022 \\u03b3 \\ud835\\udefe \\\\gamma italic_\\u03b3 (Discount factor): 0.99 \\u2022 \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 (GAE): 0.95 Hyperparameters for LR are as follows. \\u2022 Learning Rate: 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for RP are as follows. \\u2022 Learning Rate: Cartpole = 10 \\u2212 2 superscript 10 2 10^{-2} 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , Ant, Hopper = 2 \\u22c5 10 \\u2212 3 \\u22c5 2 superscript 10 3 2\\\\cdot 10^{-3} 2 \\u22c5 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for PPO are as follows. \\u2022 Learning Rate: Cartpole = 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Ant, Hopper = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Cartpole = Adaptive 2 2 2 Learning rate is adaptively controlled, so that the KL divergence between the updated policy and the original policy is maintained at certain value, 0.008 in this case. , Ant, Hopper = Constant \\u2022 Batch Size for Actor Update: 2048 \\u2022 Number of Epochs for Actor Update: 5 \\u2022 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 Hyperparameters for GI-PPO are as follows. \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Learning Rate: Cartpole = 10 \\u2212 2 superscript 10 2 10^{-2} 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT , Ant = 5 \\u22c5 10 \\u2212 4 \\u22c5 5 superscript 10 4 5\\\\cdot 10^{-4} 5 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Hopper = 5 \\u22c5 10 \\u2212 3 \\u22c5 5 superscript 10 3 5\\\\cdot 10^{-3} 5 \\u22c5 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Batch Size for Actor Update: Cartpole, Ant = 2048, Hopper = 8192 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Number of Epochs for Actor Update: 16 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b1 0 subscript \\ud835\\udefc 0 \\\\alpha_{0} italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT : Cartpole, Ant = 5 \\u22c5 10 \\u2212 1 \\u22c5 5 superscript 10 1 5\\\\cdot 10^{-1} 5 \\u22c5 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , Hopper = 5 \\u22c5 10 \\u2212 3 \\u22c5 5 superscript 10 3 5\\\\cdot 10^{-3} 5 \\u22c5 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) max \\u2061 ( \\u03b1 ) \\ud835\\udefc \\\\max(\\\\alpha) roman_max ( italic_\\u03b1 ) : 1.0 1.0 1.0 1.0 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b2 \\ud835\\udefd \\\\beta italic_\\u03b2 : 1.02 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 d \\u2062 e \\u2062 t subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 \\\\delta_{det} italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT : 0.4 0.4 0.4 0.4 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\delta_{oorr} italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT : Cartpole, Hopper = 0.75 0.75 0.75 0.75 , Ant = 0.5 0.5 0.5 0.5 \\u2022 (PPO) Learning Rate: Cartpole = 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , Ant, Hopper = 10 \\u2212 4 superscript 10 4 10^{-4} 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 (PPO) Learning Rate Scheduler: Cartpole = Adaptive, Ant, Hopper = Constant \\u2022 (PPO) Batch Size for Actor Update: 2048 \\u2022 (PPO) Number of Epochs for Actor Update: 5 \\u2022 (PPO) \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 Traffic Problems (Section 5.3 ) For these problems, common settings are as follows. \\u2022 Actor Network: MLP with [ 512 , 64 , 64 ] 512 64 64 [512,64,64] [ 512 , 64 , 64 ] layers and ELU activation function \\u2022 Critic Network: MLP with [ 64 , 64 ] 64 64 [64,64] [ 64 , 64 ] layers and ELU activation function \\u2022 Critic Hyperparameters: Learning rate = 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT , Iterations = 16, Batch Size = 4 \\u2022 Number of parallel environments: 64 \\u2022 Horizon Length: 32 \\u2022 \\u03b3 \\ud835\\udefe \\\\gamma italic_\\u03b3 (Discount factor): 0.99 \\u2022 \\u03c4 \\ud835\\udf0f \\\\tau italic_\\u03c4 (GAE): 0.95 Hyperparameters for LR are as follows. \\u2022 Learning Rate: 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for RP are as follows. \\u2022 Learning Rate: 10 \\u2212 3 superscript 10 3 10^{-3} 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for LR+RP are as follows. \\u2022 Learning Rate: 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Linear Hyperparameters for PPO are as follows. \\u2022 Learning Rate: 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 Learning Rate Scheduler: Constant \\u2022 Batch Size for Actor Update: 2048 \\u2022 Number of Epochs for Actor Update: 5 \\u2022 \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 Hyperparameters for GI-PPO are as follows. \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Learning Rate: 10 \\u2212 5 superscript 10 5 10^{-5} 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Batch Size for Actor Update: 2048 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) Number of Epochs for Actor Update: 16 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b1 0 subscript \\ud835\\udefc 0 \\\\alpha_{0} italic_\\u03b1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT : 10 \\u2212 1 superscript 10 1 10^{-1} 10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) max \\u2061 ( \\u03b1 ) \\ud835\\udefc \\\\max(\\\\alpha) roman_max ( italic_\\u03b1 ) : 1.0 1.0 1.0 1.0 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b2 \\ud835\\udefd \\\\beta italic_\\u03b2 : 1.1 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 d \\u2062 e \\u2062 t subscript \\ud835\\udeff \\ud835\\udc51 \\ud835\\udc52 \\ud835\\udc61 \\\\delta_{det} italic_\\u03b4 start_POSTSUBSCRIPT italic_d italic_e italic_t end_POSTSUBSCRIPT : 0.4 0.4 0.4 0.4 \\u2022 ( \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 ) \\u03b4 o \\u2062 o \\u2062 r \\u2062 r subscript \\ud835\\udeff \\ud835\\udc5c \\ud835\\udc5c \\ud835\\udc5f \\ud835\\udc5f \\\\delta_{oorr} italic_\\u03b4 start_POSTSUBSCRIPT italic_o italic_o italic_r italic_r end_POSTSUBSCRIPT : 0.5 0.5 0.5 0.5 \\u2022 (PPO) Learning Rate: 3 \\u22c5 10 \\u2212 4 \\u22c5 3 superscript 10 4 3\\\\cdot 10^{-4} 3 \\u22c5 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT \\u2022 (PPO) Learning Rate Scheduler: Constant \\u2022 (PPO) Batch Size for Actor Update: 2048 \\u2022 (PPO) Number of Epochs for Actor Update: 5 \\u2022 (PPO) \\u03f5 c \\u2062 l \\u2062 i \\u2062 p subscript italic-\\u03f5 \\ud835\\udc50 \\ud835\\udc59 \\ud835\\udc56 \\ud835\\udc5d \\\\epsilon_{clip} italic_\\u03f5 start_POSTSUBSCRIPT italic_c italic_l italic_i italic_p end_POSTSUBSCRIPT : 0.2 0.2 0.2 0.2 7.5 Problem Definitions Here we present details about the problems we suggested in Section 5 . (a) De Jong\\u2019s Function (b) Ackley\\u2019s Function Figure 8 : Landscape of target functions in 2 dimensions. 7.5.1 Function Optimization Problems (Section 5.1 ) (N-dimensional) De Jong\\u2019s function ( F D subscript \\ud835\\udc39 \\ud835\\udc37 F_{D} italic_F start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) and Ackley\\u2019s function ( F A subscript \\ud835\\udc39 \\ud835\\udc34 F_{A} italic_F start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ) are defined for n \\ud835\\udc5b n italic_n -dimensional vector x \\ud835\\udc65 x italic_x and are formulated as follows [Molga and Smutnicki, 2005 ] : F D \\u2062 ( x ) subscript \\ud835\\udc39 \\ud835\\udc37 \\ud835\\udc65 \\\\displaystyle F_{D}(x) italic_F start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_x ) = \\u2211 i = 1 n x i 2 , absent superscript subscript \\ud835\\udc56 1 \\ud835\\udc5b superscript subscript \\ud835\\udc65 \\ud835\\udc56 2 \\\\displaystyle=\\\\sum_{i=1}^{n}{x_{i}}^{2}, = \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , F A \\u2062 ( x ) subscript \\ud835\\udc39 \\ud835\\udc34 \\ud835\\udc65 \\\\displaystyle F_{A}(x) italic_F start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ( italic_x ) = \\u2212 20 \\u22c5 e \\u2062 x \\u2062 p \\u2062 ( \\u2212 0.2 \\u22c5 1 n \\u2062 \\u2211 i = 1 n x i 2 ) \\u2212 absent limit-from \\u22c5 20 \\ud835\\udc52 \\ud835\\udc65 \\ud835\\udc5d \\u22c5 0.2 1 \\ud835\\udc5b superscript subscript \\ud835\\udc56 1 \\ud835\\udc5b superscript subscript \\ud835\\udc65 \\ud835\\udc56 2 \\\\displaystyle=-20\\\\cdot exp(-0.2\\\\cdot\\\\sqrt{\\\\frac{1}{n}\\\\sum_{i=1}^{n}{{x_{i}}^{2% }}})- = - 20 \\u22c5 italic_e italic_x italic_p ( - 0.2 \\u22c5 square-root start_ARG divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ) - e \\u2062 x \\u2062 p \\u2062 ( 1 n \\u2062 \\u2211 i = 1 n c \\u2062 o \\u2062 s \\u2062 ( 2 \\u2062 \\u03c0 \\u2062 x i ) ) + 20 + e \\u2062 x \\u2062 p \\u2062 ( 1 ) . \\ud835\\udc52 \\ud835\\udc65 \\ud835\\udc5d 1 \\ud835\\udc5b superscript subscript \\ud835\\udc56 1 \\ud835\\udc5b \\ud835\\udc50 \\ud835\\udc5c \\ud835\\udc60 2 \\ud835\\udf0b subscript \\ud835\\udc65 \\ud835\\udc56 20 \\ud835\\udc52 \\ud835\\udc65 \\ud835\\udc5d 1 \\\\displaystyle\\\\qquad\\\\qquad\\\\qquad exp(\\\\frac{1}{n}\\\\sum_{i=1}^{n}cos(2\\\\pi x_{i}))+% 20+exp(1). italic_e italic_x italic_p ( divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_c italic_o italic_s ( 2 italic_\\u03c0 italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) + 20 + italic_e italic_x italic_p ( 1 ) . As we mentioned in Section 5.1 , we multiply -1 to these functions to make these problems maximization problems. Also, even though these two functions have their optimum at x = 0 \\ud835\\udc65 0 x=0 italic_x = 0 , they exhibit very different landscape as shown in Figure 8 . When it comes to the formal definition as RL environments, we can define these problems as follows. \\u2022 Episode Length: 1 \\u2022 Observation: [ 0 ] delimited-[] 0 [0] [ 0 ] \\u2022 Action: n \\ud835\\udc5b n italic_n -dimensional vector \\ud835\\udc31 \\ud835\\udc31 \\\\mathbf{x} bold_x , all of which element is in [ \\u2212 1 , 1 ] 1 1 [-1,1] [ - 1 , 1 ] . \\u2022 Reward: De Jong\\u2019s Function = F D \\u2062 ( 5.12 \\u2062 \\ud835\\udc31 ) subscript \\ud835\\udc39 \\ud835\\udc37 5.12 \\ud835\\udc31 F_{D}(5.12\\\\mathbf{x}) italic_F start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( 5.12 bold_x ) , Ackley\\u2019s Function = F A \\u2062 ( 32.768 \\u2062 \\ud835\\udc31 ) subscript \\ud835\\udc39 \\ud835\\udc34 32.768 \\ud835\\udc31 F_{A}(32.768\\\\mathbf{x}) italic_F start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ( 32.768 bold_x ) 7.5.2 Traffic Problems (Section 5.3 ) Before introducing pace car problem, which we specifically discussed in this paper, we\\u2019d like to briefly point out the traffic model that we used to simulate motions of individual vehicles in the traffic environment. Traffic Model In our traffic simulation, the state s \\u2208 \\u211d 2 \\u2062 N \\ud835\\udc60 superscript \\u211d 2 \\ud835\\udc41 s\\\\in\\\\mathbb{R}^{2N} italic_s \\u2208 blackboard_R start_POSTSUPERSCRIPT 2 italic_N end_POSTSUPERSCRIPT is defined as a concatenation of all vehicle states, q n \\u2208 \\u211d 2 subscript \\ud835\\udc5e \\ud835\\udc5b superscript \\u211d 2 q_{n}\\\\in\\\\mathbb{R}^{2} italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \\u2208 blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , where 1 \\u2264 n \\u2264 N 1 \\ud835\\udc5b \\ud835\\udc41 1\\\\leq n\\\\leq N 1 \\u2264 italic_n \\u2264 italic_N stands for vehicle ID. q n subscript \\ud835\\udc5e \\ud835\\udc5b q_{n} italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT can be represented simply with the vehicle\\u2019s position ( x n subscript \\ud835\\udc65 \\ud835\\udc5b x_{n} italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) and velocity ( v n subscript \\ud835\\udc63 \\ud835\\udc5b v_{n} italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ). q n subscript \\ud835\\udc5e \\ud835\\udc5b \\\\displaystyle q_{n} italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = [ x n v n ] absent matrix subscript \\ud835\\udc65 \\ud835\\udc5b subscript \\ud835\\udc63 \\ud835\\udc5b \\\\displaystyle=\\\\begin{bmatrix}x_{n}\\\\\\\\ v_{n}\\\\end{bmatrix} = [ start_ARG start_ROW start_CELL italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] s \\ud835\\udc60 \\\\displaystyle s italic_s = [ q 1 T , \\u2026 , q N T ] T , absent superscript matrix superscript subscript \\ud835\\udc5e 1 \\ud835\\udc47 \\u2026 superscript subscript \\ud835\\udc5e \\ud835\\udc41 \\ud835\\udc47 \\ud835\\udc47 \\\\displaystyle=\\\\begin{bmatrix}q_{1}^{T},\\\\ldots,q_{N}^{T}\\\\end{bmatrix}^{T}, = [ start_ARG start_ROW start_CELL italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , \\u2026 , italic_q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , where n \\ud835\\udc5b n italic_n is the vehicle ID. Since this traffic state s \\ud835\\udc60 s italic_s changes over time, we represent the traffic state at timestep t \\ud835\\udc61 t italic_t as s t subscript \\ud835\\udc60 \\ud835\\udc61 s_{t} italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . Then our differentiable traffic simulator is capable of providing the gradient of the simulation state at the next timestep t + 1 \\ud835\\udc61 1 t+1 italic_t + 1 with respect to the state at the current timestep t \\ud835\\udc61 t italic_t , or d \\u2062 s t + 1 d \\u2062 s t \\ud835\\udc51 subscript \\ud835\\udc60 \\ud835\\udc61 1 \\ud835\\udc51 subscript \\ud835\\udc60 \\ud835\\udc61 \\\\frac{ds_{t+1}}{ds_{t}} divide start_ARG italic_d italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_d italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG . This is possible because we use the Intelligent Driver Model (IDM) to model car-following behavior in our simulator [Treiber et al., 2000 ] , which is differentiable. IDM describes vehicle speed x \\u02d9 \\u02d9 \\ud835\\udc65 \\\\dot{x} over\\u02d9 start_ARG italic_x end_ARG and acceleration v \\u02d9 \\u02d9 \\ud835\\udc63 \\\\dot{v} over\\u02d9 start_ARG italic_v end_ARG as a function of desired velocity v 0 subscript \\ud835\\udc63 0 v_{0} italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , safe time headway in meters T \\ud835\\udc47 T italic_T , maximum acceleration a \\ud835\\udc4e a italic_a , comfortable deceleration b \\ud835\\udc4f b italic_b , the minimum distance between vehicles in meters \\u03b4 \\ud835\\udeff \\\\delta italic_\\u03b4 , vehicle length l \\ud835\\udc59 l italic_l , and difference in speed with the vehicle in front \\u0394 \\u2062 v \\u03b1 \\u0394 subscript \\ud835\\udc63 \\ud835\\udefc \\\\Delta v_{\\\\alpha} roman_\\u0394 italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT as follows: x \\u02d9 \\u03b1 subscript \\u02d9 \\ud835\\udc65 \\ud835\\udefc \\\\displaystyle{\\\\dot{x}}_{\\\\alpha} over\\u02d9 start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT = d \\u2062 x \\u03b1 d \\u2062 t = v \\u03b1 , absent d subscript \\ud835\\udc65 \\ud835\\udefc d \\ud835\\udc61 subscript \\ud835\\udc63 \\ud835\\udefc \\\\displaystyle={\\\\frac{\\\\mathrm{d}x_{\\\\alpha}}{\\\\mathrm{d}t}}=v_{\\\\alpha}, = divide start_ARG roman_d italic_x start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT end_ARG start_ARG roman_d italic_t end_ARG = italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , v \\u02d9 \\u03b1 subscript \\u02d9 \\ud835\\udc63 \\ud835\\udefc \\\\displaystyle{\\\\dot{v}}_{\\\\alpha} over\\u02d9 start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT = d \\u2062 v \\u03b1 d \\u2062 t = a \\u2062 ( 1 \\u2212 ( v \\u03b1 v 0 ) \\u03b4 \\u2212 ( s * \\u2062 ( v \\u03b1 , \\u0394 \\u2062 v \\u03b1 ) s \\u03b1 ) 2 ) , absent d subscript \\ud835\\udc63 \\ud835\\udefc d \\ud835\\udc61 \\ud835\\udc4e 1 superscript subscript \\ud835\\udc63 \\ud835\\udefc subscript \\ud835\\udc63 0 \\ud835\\udeff superscript superscript \\ud835\\udc60 subscript \\ud835\\udc63 \\ud835\\udefc \\u0394 subscript \\ud835\\udc63 \\ud835\\udefc subscript \\ud835\\udc60 \\ud835\\udefc 2 \\\\displaystyle={\\\\frac{\\\\mathrm{d}v_{\\\\alpha}}{\\\\mathrm{d}t}}=a\\\\,\\\\left(1-\\\\left({% \\\\frac{v_{\\\\alpha}}{v_{0}}}\\\\right)^{\\\\delta}-\\\\left({\\\\frac{s^{*}(v_{\\\\alpha},\\\\Delta v% _{\\\\alpha})}{s_{\\\\alpha}}}\\\\right)^{2}\\\\right), = divide start_ARG roman_d italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT end_ARG start_ARG roman_d italic_t end_ARG = italic_a ( 1 - ( divide start_ARG italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT end_ARG start_ARG italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT italic_\\u03b4 end_POSTSUPERSCRIPT - ( divide start_ARG italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , roman_\\u0394 italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) end_ARG start_ARG italic_s start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , s \\u03b1 subscript \\ud835\\udc60 \\ud835\\udefc \\\\displaystyle s_{\\\\alpha} italic_s start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT = x \\u03b1 \\u2212 1 \\u2212 x \\u03b1 \\u2212 l \\u03b1 \\u2212 1 , absent subscript \\ud835\\udc65 \\ud835\\udefc 1 subscript \\ud835\\udc65 \\ud835\\udefc subscript \\ud835\\udc59 \\ud835\\udefc 1 \\\\displaystyle=x_{\\\\alpha-1}-x_{\\\\alpha}-l_{\\\\alpha-1}, = italic_x start_POSTSUBSCRIPT italic_\\u03b1 - 1 end_POSTSUBSCRIPT - italic_x start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT - italic_l start_POSTSUBSCRIPT italic_\\u03b1 - 1 end_POSTSUBSCRIPT , s * \\u2062 ( v \\u03b1 , \\u0394 \\u2062 v \\u03b1 ) superscript \\ud835\\udc60 subscript \\ud835\\udc63 \\ud835\\udefc \\u0394 subscript \\ud835\\udc63 \\ud835\\udefc \\\\displaystyle s^{*}(v_{\\\\alpha},\\\\Delta v_{\\\\alpha}) italic_s start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT , roman_\\u0394 italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT ) = s 0 + v \\u03b1 \\u2062 T + v \\u03b1 \\u2062 \\u0394 \\u2062 v \\u03b1 2 \\u2062 a \\u2062 b , absent subscript \\ud835\\udc60 0 subscript \\ud835\\udc63 \\ud835\\udefc \\ud835\\udc47 subscript \\ud835\\udc63 \\ud835\\udefc \\u0394 subscript \\ud835\\udc63 \\ud835\\udefc 2 \\ud835\\udc4e \\ud835\\udc4f \\\\displaystyle=s_{0}+v_{\\\\alpha}\\\\,T+{\\\\frac{v_{\\\\alpha}\\\\,\\\\Delta v_{\\\\alpha}}{2\\\\,{% \\\\sqrt{a\\\\,b}}}}, = italic_s start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT italic_T + divide start_ARG italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT roman_\\u0394 italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT end_ARG start_ARG 2 square-root start_ARG italic_a italic_b end_ARG end_ARG , \\u0394 \\u2062 v \\u03b1 \\u0394 subscript \\ud835\\udc63 \\ud835\\udefc \\\\displaystyle\\\\Delta v_{\\\\alpha} roman_\\u0394 italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT = v \\u03b1 \\u2212 v \\u03b1 \\u2212 1 , absent subscript \\ud835\\udc63 \\ud835\\udefc subscript \\ud835\\udc63 \\ud835\\udefc 1 \\\\displaystyle=v_{\\\\alpha}-v_{\\\\alpha-1}, = italic_v start_POSTSUBSCRIPT italic_\\u03b1 end_POSTSUBSCRIPT - italic_v start_POSTSUBSCRIPT italic_\\u03b1 - 1 end_POSTSUBSCRIPT , where \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 means the order of the vehicle in the lane. Therefore, ( \\u03b1 \\u2212 1 ) \\ud835\\udefc 1 (\\\\alpha-1) ( italic_\\u03b1 - 1 ) -th vehicle runs right in front of \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 -th vehicle, and this relationship plays an important role in IDM. Also note that the computed acceleration term ( v \\u02d9 \\u02d9 \\ud835\\udc63 {\\\\dot{v}} over\\u02d9 start_ARG italic_v end_ARG ) is differentiable with respect to the other IDM variables. IDM is just one of many car-following models used in traffic simulation literature. We choose IDM for its prevalence in previous mixed autonomy literature, however, any ODE-based car-following model will also work in our simulator as far as it is differentiable. In our simulator, automatic differentiation governs the gradient computation. Lane Under IDM, lane membership is one of the most vital variables for simulation. This is because IDM builds on the leader-follower relationship. When a vehicle changes its lane with lateral movement, as shown as red arrows in Figure 9 , such relationships could change, and our gradients do not convey any information about it, because lane membership is a discrete variable in nature. Note that this lateral movement also affects the longitudinal movement, rendered in green arrows in Figure 9 , of a vehicle, and gradient from it is valid as far as the lane membership does not change. However, when the lane membership changes, even if our simulator gives gradient, it tells us only \\u201cpartial\\u201d information in the sense that it only gives information about longitudinal behavior. Therefore, we could say that analytical gradients we get from this environment is \\u201cincomplete\\u201d (not useless at all, because it still gives us information about longitudinal movement), and thus biased. Pace Car Problem In this problem, there is a single autonomous vehicle that we have to control to regulate other human driven vehicles, which follow IDM, to run at the given target speed. Since human driven vehicles control their speeds based on the relationship to their leading vehicles, our autonomous vehicle has to control itself to run in front of those human driven vehicles and adjust their speeds to the target speed. The number of lanes and human driven vehicles varies across different environments as follows. \\u2022 Single Lane: Number of lanes = 1, Number of vehicles per lane = 1 \\u2022 2 Lanes: Number of lanes = 2, Number of vehicles per lane = 2 \\u2022 4 Lanes: Number of lanes = 4, Number of vehicles per lane = 4 \\u2022 10 Lanes: Number of lanes = 10, Number of vehicles per lane = 1 See Figure 10 for 10-lane environment. Then we can formally define RL environments as follows, where N \\ud835\\udc41 N italic_N is the number of human driven vehicles in total, and v t \\u2062 g \\u2062 t subscript \\ud835\\udc63 \\ud835\\udc61 \\ud835\\udc54 \\ud835\\udc61 v_{tgt} italic_v start_POSTSUBSCRIPT italic_t italic_g italic_t end_POSTSUBSCRIPT is the target speed. \\u2022 Episode Length: 1000 \\u2022 Observation: s \\u2208 \\u211d 2 \\u2062 N \\ud835\\udc60 superscript \\u211d 2 \\ud835\\udc41 s\\\\in\\\\mathbb{R}^{2N} italic_s \\u2208 blackboard_R start_POSTSUPERSCRIPT 2 italic_N end_POSTSUPERSCRIPT \\u2022 Action: \\ud835\\udc1a \\u2208 \\u211d 2 \\ud835\\udc1a superscript \\u211d 2 \\\\mathbf{a}\\\\in\\\\mathbb{R}^{2} bold_a \\u2208 blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( \\ud835\\udc1a 0 subscript \\ud835\\udc1a 0 \\\\mathbf{a}_{0} bold_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = Acceleration, \\ud835\\udc1a 1 subscript \\ud835\\udc1a 1 \\\\mathbf{a}_{1} bold_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = Steering) \\u2022 Reward: 1 \\u2212 1 N \\u2062 \\u2211 i = 1 N min \\u2061 ( | v i \\u2212 v t \\u2062 g \\u2062 t | v t \\u2062 g \\u2062 t , 1 ) 1 1 \\ud835\\udc41 superscript subscript \\ud835\\udc56 1 \\ud835\\udc41 subscript \\ud835\\udc63 \\ud835\\udc56 subscript \\ud835\\udc63 \\ud835\\udc61 \\ud835\\udc54 \\ud835\\udc61 subscript \\ud835\\udc63 \\ud835\\udc61 \\ud835\\udc54 \\ud835\\udc61 1 1-\\\\frac{1}{N}\\\\sum_{i=1}^{N}\\\\min(\\\\frac{|v_{i}-v_{tgt}|}{v_{tgt}},1) 1 - divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \\u2211 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT roman_min ( divide start_ARG | italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_v start_POSTSUBSCRIPT italic_t italic_g italic_t end_POSTSUBSCRIPT | end_ARG start_ARG italic_v start_POSTSUBSCRIPT italic_t italic_g italic_t end_POSTSUBSCRIPT end_ARG , 1 ) However, to facilitate learning, we additionally adopted following termination conditions to finish unpromising trials early. \\u2022 Terminate when autonomous vehicle collides with human driven vehicle \\u2022 Terminate when autonomous vehicle goes out of lane \\u2022 Terminate when autonomous vehicle runs too far away from the other vehicles \\u2022 Terminate when autonomous vehicle falls behind the other vehicles When one of these conditions is met, it gets reward of \\u2212 1 1 -1 - 1 and the trial terminates. 7.6 Renderings 7.6.1 Traffic Simulation Gradient flow As described in Appendix 7.5.2 , analytical gradients are only valid along longitudinal direction, as illustrated with green arrows in Figure 9 . When a vehicle changes lane with lateral movement, as shown with red arrows, even though such change would incur different behaviors of following vehicles in multiple lanes, analytical gradients cannot convey such information. However, they still tell us information about longitudinal behavior - which is one of the motivations of our research, to use analytical gradients even in these biased environments. Figure 9 : Traffic Environment. In traffic flows, only partial gradients of forward simulation are known; acceleration along a (longitudinal) traffic lane is continuous and admits gradient flow (green), while (lateral) lane-changing is a discrete event and thus prohibits gradient flow (red). Analytical gradients convey only partial information about traffic dynamics. Pace Car Problem We additionally provide renderings of the 10-lane pace car problem defined in Appendix 7.5.2 . In Figure 10 , we can observe 10 parallel lanes, 10 human driven vehicles rendered in yellow, and the autonomous vehicle rendered in blue that we have to control. As shown there, human driven vehicles adjust their speeds based on IDM when the autonomous vehicle blocks their way. Therefore, the autonomous vehicle has to learn how to change their lanes, and also how to run in appropriate speed to regulate the following vehicles. Our experimental results in Section 5.3 show that our method achieves better score than the baseline methods by adopting biased analytical gradients in PPO. (a) 0 0 -th frame (b) 150 150 150 150 -th frame (c) 300 300 300 300 -th frame (d) 450 450 450 450 -th frame Figure 10 : 10-Lane pace car environment. The autonomous vehicle (Blue) has to interfere paths of the other human driven vehicles (Yellow) to limit their speeds to 10 m / s \\ud835\\udc5a \\ud835\\udc60 m/s italic_m / italic_s . Even though it is a hard problem to achieve high score, our method achieved far better score than the baseline methods. 7.7 Computational Costs We provide wall clock training times for each method in traffic environments to finish all the training epochs in Table 2 . All of the trainings were done based on the settings in Appendix 7.5.2 . Note that the longer training time does not always mean that the method is worse than the others \\u2013 the method could have achieved better results in shorter time, while requiring much longer time to complete all the training epochs. In Table 2 , we can observe that GI-PPO requires a little more time than RP, as it computes analytical gradients as RP does, but requires an additional time for controlling \\u03b1 \\ud835\\udefc \\\\alpha italic_\\u03b1 and doing PPO update. However, the additional cost is not so significant. In contrast, LR+RP consumes much more time than the other methods, even though it is based on the same spirit as ours. This is because it has to backpropagate through each trajectory in the experience buffer to estimate the sample variance of the gradients. Therefore, we can see that our method attains better results than LR+RP (Figure 3(d) ) with lower computational cost. Table 2 : Average (wall clock) training time (sec) for traffic problems. Problem LR RP PPO LR+RP GI-PPO Single Lane 120 282 181 1335 332 2 Lanes 142 330 218 1513 411 4 Lanes 304 646 366 2093 813 10 Lanes 244 496 294 2103 533\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_page_url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"https://arxiv.org/list/cs/2023-08?skip=0&show=2000\",\n          \"https://arxiv.org/list/cs/2024-01?skip=2000&show=2000\",\n          \"https://arxiv.org/list/cs/2023-12?skip=8000&show=2000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    del df\n",
        "    import gc\n",
        "    gc.collect() # Принудительная очистка мусора"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q71y6ucCLCHm",
        "outputId": "be86ac73-8941-4f00-84a2-c6f0b18f8df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "355"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#далее идет часть с небольшой очисткой кода, при перезапуске его не активирую, сразу читаю сохраненный файл, но сам код не стала комментировать"
      ],
      "metadata": {
        "id": "XVlKUwP1rBf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "jDhSmcWjomFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['full_text'])\n",
        "df = df[df['full_text'].apply(lambda x: isinstance(x, str))]"
      ],
      "metadata": {
        "id": "uGUQ7REr0vB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "    text = re.sub(r\"License:.*\", \"\", text)\n",
        "    text = re.sub(r\"HTML conversions.*\", \"\", text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "2q1nT5qtorzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['full_text'] = df['full_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "dbUCLj9Ko9LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['full_text'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd_6zmvSpCqg",
        "outputId": "36c35924-2403-47fa-904f-cc0ec19a164c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    \\theta}(x_{i}),y_{i}), underitalic_θ start_ARG...\n",
            "1    Infinite-Dimensional Diffusion Models \\name Ja...\n",
            "2    In recent years, cutting-edge technologies hav...\n",
            "3    prefix=Mousa Tayseer, orcid=0000-0002-0408-054...\n",
            "4    \\mathrm{w}}_{t}+\\mathrm{d}\\mathbf{L}_{t},\\qqua...\n",
            "Name: full_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[3, 'full_text']"
      ],
      "metadata": {
        "id": "2COBZxNCm2xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc[4, 'full_text']"
      ],
      "metadata": {
        "id": "Rs8C7AlJnpzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFm_rHaayqr-",
        "outputId": "b1600eb0-b512-49c2-8cb8-3b6cc567b582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2801"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#перезаписала файл с уже очищенным датасетом\n",
        "#output_path = '/content/drive/MyDrive/Project_final/arxiv_0.2.csv'\n",
        "#df.to_csv(output_path, index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "qUOGluwTqMhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['subjects'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "ksX22Y85RYOW",
        "outputId": "14f49507-0411-4242-84e6-ab37f2c852cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subjects\n",
              "Computer Vision and Pattern Recognition (cs.CV)                                                                                                       349\n",
              "Computation and Language (cs.CL)                                                                                                                      130\n",
              "Machine Learning (cs.LG)                                                                                                                              127\n",
              "Robotics (cs.RO)                                                                                                                                       79\n",
              "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)                                                                                              78\n",
              "                                                                                                                                                     ... \n",
              "Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Emerging Technologies (cs.ET)                                                                      1\n",
              "Tissues and Organs (q-bio.TO); Machine Learning (cs.LG)                                                                                                 1\n",
              "Systems and Control (eess.SY); Dynamical Systems (math.DS); Adaptation and Self-Organizing Systems (nlin.AO); Classical Physics (physics.class-ph)      1\n",
              "Artificial Intelligence (cs.AI); Multimedia (cs.MM)                                                                                                     1\n",
              "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)                                  1\n",
              "Name: count, Length: 835, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subjects</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Computer Vision and Pattern Recognition (cs.CV)</th>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Computation and Language (cs.CL)</th>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Machine Learning (cs.LG)</th>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Robotics (cs.RO)</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Machine Learning (cs.LG); Artificial Intelligence (cs.AI)</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Emerging Technologies (cs.ET)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tissues and Organs (q-bio.TO); Machine Learning (cs.LG)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Systems and Control (eess.SY); Dynamical Systems (math.DS); Adaptation and Self-Organizing Systems (nlin.AO); Classical Physics (physics.class-ph)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Artificial Intelligence (cs.AI); Multimedia (cs.MM)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>835 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.groupby('subjects').filter(lambda x: len(x) > 50)"
      ],
      "metadata": {
        "id": "6D__Yo4pTG3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['subjects'] = df['subjects'].apply(lambda x: x.split(';')[0].strip())"
      ],
      "metadata": {
        "id": "GrASyTqATKlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['subjects'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "VNyr03_6UgcC",
        "outputId": "fa8c5e43-f08c-4ca8-e23a-640a15fccdeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subjects\n",
              "Computer Vision and Pattern Recognition (cs.CV)    404\n",
              "Computation and Language (cs.CL)                   207\n",
              "Machine Learning (cs.LG)                           205\n",
              "Robotics (cs.RO)                                    79\n",
              "Numerical Analysis (math.NA)                        69\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subjects</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Computer Vision and Pattern Recognition (cs.CV)</th>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Computation and Language (cs.CL)</th>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Machine Learning (cs.LG)</th>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Robotics (cs.RO)</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Numerical Analysis (math.NA)</th>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subject_counts = df['subjects'].value_counts()"
      ],
      "metadata": {
        "id": "1aKQZxIvVVhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_samples_per_class = 50\n",
        "frequent_subjects = subject_counts[subject_counts >= min_samples_per_class].index"
      ],
      "metadata": {
        "id": "uEQ0XV7fVa_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['subjects'].isin(frequent_subjects)].copy()"
      ],
      "metadata": {
        "id": "8D5_ffJwVfYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset for training and evaluation\n"
      ],
      "metadata": {
        "id": "kMi0J7wHzPtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Label' not in df.columns:\n",
        "    df['label'] = df['subjects'].astype('category').cat.codes\n",
        "else:\n",
        "    df = df.rename(columns={\"Label\": \"label\"})"
      ],
      "metadata": {
        "id": "hUiWxn0w51nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = df['subjects'].astype('category').cat.categories.tolist()\n",
        "num_labels = len(categories)\n",
        "id2label = {i: label for i, label in enumerate(categories)}"
      ],
      "metadata": {
        "id": "IhhvUkGiVrhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "13lVP-nkyA8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = Dataset.from_pandas(df[['full_text', 'label', 'subjects']])\n",
        "ds = ds.train_test_split(test_size=0.1, seed=42)"
      ],
      "metadata": {
        "id": "MdRMVmGVxOVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load model\n",
        "import torch\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-uncased\", num_labels=num_labels, problem_type=\"single_label_classification\"\n",
        ")"
      ],
      "metadata": {
        "id": "hfXAVnkLziQQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758,
          "referenced_widgets": [
            "7b11fdb82b5a40d4a98f326fd8e4e745",
            "704752b443df474cb97e54aea46985bc",
            "205d8fad8d8f49dab1dddeb150f013fd",
            "0028f0191b6b41059542e293eaca28e7",
            "4e19b0472efc4c36b54363de01dad668",
            "bb945a23753a4099bf187c0aec0ed44f",
            "5bb203b9782a43a188ee15535d3d8728",
            "9b11e90eabb948f387ead33bb9976b62",
            "7aca66a119cd4f8f8232a6699927972d",
            "9147369bfa66476da0ce834f7db43d0f",
            "ccb40f6e3a914e06880d7368a2658190",
            "5bc179d657b848349d5cfd636c1e3e4a",
            "e166cbe35215468283ce262ef205ddce",
            "d72afe914b1c4303bbad9acac7e83a37",
            "77b978347a48449dbef27a2efc2a3d17",
            "135c7c3f24d54b74bae271cd06f6bb65",
            "6d97de5dde394f22b8ad31f919043224",
            "a2dc215aa36f485090b62e57da1ee380",
            "7235955c386e4d82b08a8171d567904d",
            "2fbd8bf0586b46cd87f58dd4cfeab6da",
            "e0952a6a5ee84454b604c5e561380c72",
            "fe17c8d3e334404ea3ad108194e7d143",
            "ca66f480062644808bbd94906d1f138b",
            "4314a384aaec4fb8b066407ed555248b",
            "c20efaccaa4443afbf1852a7ef0b7997",
            "1275cc93ca5445dca0227c99f355d4dc",
            "b15f90ea390e436fb133ef2c12585fe2",
            "d3a69df3e82642cc8eee3b862c3623da",
            "40fe4184e7c74ef5a7ef3c5a26ad9699",
            "37174384e2b747348596b4a883b2be03",
            "62c72f28503c42aa9e64a6db86115e0c",
            "106fc24b01f042039785cb5cffac1c73",
            "27c18f1877784e80a9e7807efdf0b5da",
            "263a24663ad94ca2a73100c92ad5802e",
            "ccd2eadb2d0b4f6794f1ee1bd8535e00",
            "035d857ab72049b982b1a136eb7d69cb",
            "ed02f5656e064ad1908901fd1cf74f53",
            "b64531f1ac4f44bebffe53d2f54ce6f5",
            "33b1466fc8f74982ad0e9e5ff496cd02",
            "41115563e3604a629491f2fa1880e7bd",
            "9afa61177bfd4ec7aa9caf0ac79522ac",
            "3743d5cdb22f44cdb147084eb194f0bc",
            "70784c26fb6b42f981146269bb85b1a9",
            "7ffc2791e7e248f2b0717a227f8b3b74",
            "4200b9132ff84d42975af593d332b53a",
            "694ba1f192354a4ea0466e6ce0f12fa9",
            "854e51b8a9f94d709075b267877af549",
            "91ab4c7573b6499b800a7f35a5a69df9",
            "a15d882dd38b4ed7939c5219b7baa690",
            "1b91e78b5c6548769255f2046979ea78",
            "22f7bce7483d49589c4174274e013b2a",
            "04e9611fa3df436bbe48f2913aea0421",
            "30dc69f98f18449c86fa9fa643837e81",
            "14bbefe5baf54e20bb07c3f797f8f0a8",
            "3b616c580dc54b6cb0e09f36614dd815",
            "01b34c12ab684531b069da04bd38ece3",
            "ed8f9cc1d97e4e22a3690fac6f039f6f",
            "28ee26adad6e4fa7bcdb9f75fbe270b5",
            "43c6a8b3c5674fb5acabd2d21115ae90",
            "47e95e0ca8734ddd955bf2e0450931d3",
            "fd4eeb589fdc44e2b051939dbc91949d",
            "a246f4a67af84331ab02aac791134715",
            "ab813acc197c419d98b1af4088051a75",
            "2209e4f7d16c489f904b04f86fa3f722",
            "ac3667a75ee24358a071f8bc62e1764d",
            "39f3f1f759394ed2987d8d0bfc106a72"
          ]
        },
        "outputId": "4ef716f6-f353-4a1f-edb3-0314c236142e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b11fdb82b5a40d4a98f326fd8e4e745"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bc179d657b848349d5cfd636c1e3e4a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca66f480062644808bbd94906d1f138b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "263a24663ad94ca2a73100c92ad5802e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4200b9132ff84d42975af593d332b53a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01b34c12ab684531b069da04bd38ece3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: google-bert/bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "classifier.weight                          | MISSING    | \n",
            "classifier.bias                            | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    column_name = \"full_text\"\n",
        "    texts = [str(t) if t is not None else \"\" for t in examples[column_name]]\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False\n",
        "    )"
      ],
      "metadata": {
        "id": "aHiwiuuS0B_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "1LrZ34MS03Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = ds.map(preprocess_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "aNsxFC-Y0Cgb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "22e5271e152e428890d102b68ea60acb",
            "5ef4f0bd34bb48489a17d8401784d7bc",
            "1e1e0d77e6a945429ec2acf340435b1d",
            "7784e9bf37eb4beca3cb9d661773fcdc",
            "534e1c433a8c46f4b88902f97d62c583",
            "2cda448a628e41e899cdd753fa9a5f4d",
            "4b1fd950e1e74b40b23179198695c8e4",
            "91da17095459474faa7467a796506e3e",
            "cd0f4a1662ce4aa29b1778996d4c7924",
            "5dd735a53bcb49268890485366020078",
            "56530b7ea63641e8b6584745acbb6d2c",
            "9c9137772fff440992f7899da331cbc6",
            "db349704cfad43108e4040745e9f6b98",
            "2ccd4c286cff4117a994d0f835f776cd",
            "718d898431934d4da0748e454a9893da",
            "00c95e8387bb4da09512c51a5661f24f",
            "bd91960025a84084bfe4ec396195776c",
            "faa69db8dd4341688b167052bc34e1c1",
            "0bd088d751d54c2f8fb36618b7e922aa",
            "85ed2af400744119b7b595e46712a3ec",
            "d3493f9a27744e8aaf7b4308167c645d",
            "e5db58b7f309424e8178b5e2f045a29f"
          ]
        },
        "outputId": "de19fdfd-515f-4ac0-ef53-82cba55ebb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/867 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22e5271e152e428890d102b68ea60acb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/97 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c9137772fff440992f7899da331cbc6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Trainer --- Contrastive Loss"
      ],
      "metadata": {
        "id": "cef0Gtfc10vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "5fdQyR5LBqbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveTrainer(Trainer):\n",
        "    def __init__(self, *args, contrastive_alpha=0.01, temperature=0.1, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.contrastive_alpha = contrastive_alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        classification_loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        embeddings = outputs.hidden_states[-1][:, 0, :]\n",
        "\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "        similarity_matrix = torch.matmul(embeddings, embeddings.T) / self.temperature\n",
        "\n",
        "        labels = labels.view(-1, 1)\n",
        "        mask = torch.eq(labels, labels.T).float().to(self.args.device)\n",
        "\n",
        "        mask = mask - torch.eye(mask.shape[0]).to(self.args.device)\n",
        "\n",
        "        exp_sim = torch.exp(similarity_matrix) * (1 - torch.eye(mask.shape[0]).to(self.args.device))\n",
        "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-5)\n",
        "\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(dim=1) / (mask.sum(dim=1) + 1e-5)\n",
        "        contrastive_loss = -mean_log_prob_pos.mean()\n",
        "\n",
        "        total_loss = classification_loss + (self.contrastive_alpha * contrastive_loss)\n",
        "\n",
        "        return (total_loss, outputs) if return_outputs else total_loss"
      ],
      "metadata": {
        "id": "U04CEV_s0CjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA"
      ],
      "metadata": {
        "id": "2MKHGpXqC6FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft transformers datasets evaluate accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggVh1y144J2Q",
        "outputId": "d92204b4-4764-4ac3-dec2-92e33d1401ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType"
      ],
      "metadata": {
        "id": "ioByzbN90Cl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=16, lora_alpha=16, lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "ppprP6hSDaCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65997235-435d-46c9-bb87-25cac6ca892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:285: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training arguments"
      ],
      "metadata": {
        "id": "C60wy1EUz0mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "lKJyZZ_L4ugh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-contrastive-lora\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=64,\n",
        "    num_train_epochs=15,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False\n",
        ")"
      ],
      "metadata": {
        "id": "lizcuuS_xnGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "66NZWqBYEZh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = ContrastiveTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    contrastive_alpha=0.05,\n",
        "    temperature=0.07,\n",
        "    callbacks=[EarlyStoppingCallback(\n",
        "        early_stopping_patience=3,\n",
        "        early_stopping_threshold=0.001\n",
        "    )]\n",
        ")"
      ],
      "metadata": {
        "id": "uvF8jkn-Eekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MXRmMGIrEyvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "a7b7633d-c782-4c25-8115-b8f920fb0708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [168/210 01:54 < 00:29, 1.45 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.068810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.962356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.939284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.880717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.850470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.846411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.812491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.816339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.772683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.788495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.791620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.783533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=168, training_loss=0.9218007950555711, metrics={'train_runtime': 115.3814, 'train_samples_per_second': 112.713, 'train_steps_per_second': 1.82, 'total_flos': 1398627534311424.0, 'train_loss': 0.9218007950555711, 'epoch': 12.0})"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "be1fqNIK0AR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "GOIAVQ17xrib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'input_ids': torch.tensor([item['input_ids'] for item in batch]),\n",
        "        'attention_mask': torch.tensor([item['attention_mask'] for item in batch]),\n",
        "        'labels': torch.tensor([item['label'] for item in batch])\n",
        "    }\n",
        "\n",
        "def plot_results(model, dataset, title=\"BERT Contrastive\"):\n",
        "    model.eval()\n",
        "    predictions, references = [], []\n",
        "\n",
        "\n",
        "    full_label_names = df['subjects'].astype('category').cat.categories.tolist()\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=16,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=f\"Оценка {title}\"):\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in batch.items() if k != 'labels'}\n",
        "        labels = batch['labels'].to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "            predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
        "            references.extend(labels.cpu().numpy())\n",
        "\n",
        "    if not references or not predictions:\n",
        "        print(\"Ошибка: Списки предсказаний или реальных меток пусты. Нечего оценивать.\")\n",
        "        return\n",
        "\n",
        "    present_labels = np.unique(np.concatenate([references, predictions]))\n",
        "\n",
        "    valid_present_labels = [lbl for lbl in present_labels if lbl < len(full_label_names)]\n",
        "\n",
        "    if not valid_present_labels:\n",
        "        print(\"Ошибка: Нет допустимых меток для оценки.\")\n",
        "        return\n",
        "\n",
        "    present_names = [full_label_names[i] for i in valid_present_labels]\n",
        "\n",
        "    print(f\"n--- Отчет для {title} ---\")\n",
        "    print(classification_report(\n",
        "        references,\n",
        "        predictions,\n",
        "        labels=valid_present_labels,\n",
        "        target_names=present_names,\n",
        "        zero_division=0\n",
        "    ))\n",
        "\n",
        "    cm = confusion_matrix(references, predictions, labels=valid_present_labels)\n",
        "\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    show_labels = True if len(valid_present_labels) < 50 else False\n",
        "\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=False,\n",
        "        fmt='d',\n",
        "        cmap='Purples',\n",
        "        xticklabels=present_names if show_labels else False,\n",
        "        yticklabels=present_names if show_labels else False\n",
        "    )\n",
        "\n",
        "    plt.title(f'Confusion Matrix: {title}n(Отображено классов: {len(valid_present_labels)})')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LVOKiCUIbc7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(model, tokenized_ds[\"test\"], title=\"BERT + LoRA + Contrastive\")"
      ],
      "metadata": {
        "id": "yKW5bDgXlTOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51b238c2-8282-4ad7-d098-d6f05b7238bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Оценка BERT + LoRA + Contrastive: 100%|██████████| 7/7 [00:00<00:00, 14.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n--- Отчет для BERT + LoRA + Contrastive ---\n",
            "                                                 precision    recall  f1-score   support\n",
            "\n",
            "               Computation and Language (cs.CL)       0.88      0.82      0.85        28\n",
            "Computer Vision and Pattern Recognition (cs.CV)       0.79      0.90      0.84        41\n",
            "                       Machine Learning (cs.LG)       0.60      0.60      0.60        20\n",
            "                   Numerical Analysis (math.NA)       1.00      1.00      1.00         4\n",
            "                               Robotics (cs.RO)       0.00      0.00      0.00         4\n",
            "\n",
            "                                       accuracy                           0.78        97\n",
            "                                      macro avg       0.65      0.66      0.66        97\n",
            "                                   weighted avg       0.75      0.78      0.77        97\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "HdntcZbIdiuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving model"
      ],
      "metadata": {
        "id": "azNkV45Bl2HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотерела разные варианты сохранений"
      ],
      "metadata": {
        "id": "aQh5FQuwvL5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#account = <your-hf-account-name>\n",
        "#peft_model_id = f\"{account}/bloomz-560-m-peft-method\"\n",
        "#model.push_to_hub(peft_model_id)"
      ],
      "metadata": {
        "id": "RA-IHJLvh3or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import shutil"
      ],
      "metadata": {
        "id": "29VTo9HhuvE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.copytree(\"./bert_contrastive_model\", \"/content/drive/MyDrive/my_bert_model\")"
      ],
      "metadata": {
        "id": "JMj0xKF4ux6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "pvEAHzvKt8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_directory = \"./bert_contrastive_model\""
      ],
      "metadata": {
        "id": "fQhoJ4hDuJMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"/content/drive/MyDrive/my_bert_model\"\n",
        "\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "categories = df['subjects'].astype('category').cat.categories\n",
        "id2label = {i: label for i, label in enumerate(categories)}\n",
        "label2id = {label: i for i, label in enumerate(categories)}\n",
        "\n",
        "with open(os.path.join(save_directory, \"label_config.json\"), \"w\") as f:\n",
        "    json.dump({\"id2label\": id2label, \"label2id\": label2id}, f)"
      ],
      "metadata": {
        "id": "0K4ZsDPoz1rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "9A0OJ10s0dQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig"
      ],
      "metadata": {
        "id": "eTMymy3NkWvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_for_inference(model_path):\n",
        "    with open(f\"{model_path}/label_config.json\", \"r\") as f:\n",
        "        config_data = json.load(f)\n",
        "        id2label = config_data[\"id2label\"]\n",
        "\n",
        "    config = PeftConfig.from_pretrained(model_path)\n",
        "    base_model = BertForSequenceClassification.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        num_labels=len(id2label)\n",
        "    )\n",
        "\n",
        "    model = PeftModel.from_pretrained(base_model, model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    return model, tokenizer, id2label\n",
        "\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/my_bert_model\"\n",
        "inf_model, inf_tokenizer, id_map = load_model_for_inference(model_path)\n",
        "\n",
        "def predict_category(text):\n",
        "    inputs = inf_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256).to(inf_model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = inf_model(**inputs).logits\n",
        "        prediction = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    return id_map[str(prediction)]"
      ],
      "metadata": {
        "id": "KjSstNBEvb2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "99f257ea429f46cfb71fb49e5b57db0a",
            "0d6312732a814f70babe00ddfeca5b1b",
            "81352711a554447ba65a5ec6da009d42",
            "69898a8fe490401286a57d4cf3259eba",
            "85761e51f53b4126b24ad82ddd38bbcc",
            "6c205abfba6249f89e9998e1f52178df",
            "fc207b48240944cc961381890be21a5e",
            "e273e60f8c7e48ca810e1d6749e70bea",
            "32b775ef2ee94d39a78e5d666f079f9b",
            "e77180ee27204ddcbc26feb109461a0b",
            "634710a9278e48599f25b123feb75d05"
          ]
        },
        "outputId": "bba255dc-0a77-459b-c566-3224693382cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f257ea429f46cfb71fb49e5b57db0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: google-bert/bert-base-uncased\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "classifier.weight                          | MISSING    | \n",
            "classifier.bias                            | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_paper = \"Recent advancements in large language models (LLMs) have prompted interest in deploying these models on mobile devices to enable new applications without relying on cloud connectivity. However, the efficiency constraints of deploying LLMs on resource-limited devices present significant challenges. In this paper, we conduct a comprehensive measurement study to evaluate the efficiency tradeoffs between mobile-based, edge-based, and cloud-based deployments for LLM applications.\" #поменять текст\n",
        "print(f\"Предсказанная категория: {predict_category(new_paper)}\")"
      ],
      "metadata": {
        "id": "bLYTR-N-wBYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c4057b-8cb5-4dd1-ac1c-3a23bb69c121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанная категория: Computer Vision and Pattern Recognition (cs.CV)\n"
          ]
        }
      ]
    }
  ]
}