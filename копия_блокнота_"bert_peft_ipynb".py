# -*- coding: utf-8 -*-
"""Копия блокнота "BERT_PEFT.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IQLpxPnt22855VaVqx1PriA01q4S0JBX

# Load dataset
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

#df = pd.read_csv('/content/drive/MyDrive/Project_final/arxiv_half.csv')

#df_small = df.sample(frac=0.2, random_state=42)

#output_path = '/content/drive/MyDrive/Project_final/arxiv_0.2.csv'
#df_small.to_csv(output_path, index=False, encoding='utf-8')

df = pd.read_csv('/content/drive/MyDrive/arxiv_0.2.csv')

df.head()

del df
    import gc
    gc.collect() # Принудительная очистка мусора

#далее идет часть с небольшой очисткой кода, при перезапуске его не активирую, сразу читаю сохраненный файл, но сам код не стала комментировать

import re

df = df.dropna(subset=['full_text'])
df = df[df['full_text'].apply(lambda x: isinstance(x, str))]

def clean_text(text):
    if not isinstance(text, str):
        return text
    text = re.sub(r"License:.*", "", text)
    text = re.sub(r"HTML conversions.*", "", text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['full_text'] = df['full_text'].apply(clean_text)

print(df['full_text'].head())

#df.loc[3, 'full_text']

#df.loc[4, 'full_text']

len(df)

#перезаписала файл с уже очищенным датасетом
#output_path = '/content/drive/MyDrive/Project_final/arxiv_0.2.csv'
#df.to_csv(output_path, index=False, encoding='utf-8')

df['subjects'].value_counts()

df = df.groupby('subjects').filter(lambda x: len(x) > 50)

df['subjects'] = df['subjects'].apply(lambda x: x.split(';')[0].strip())

df['subjects'].value_counts()

subject_counts = df['subjects'].value_counts()

min_samples_per_class = 50
frequent_subjects = subject_counts[subject_counts >= min_samples_per_class].index

df = df[df['subjects'].isin(frequent_subjects)].copy()

"""# Prepare dataset for training and evaluation

"""

if 'Label' not in df.columns:
    df['label'] = df['subjects'].astype('category').cat.codes
else:
    df = df.rename(columns={"Label": "label"})

categories = df['subjects'].astype('category').cat.categories.tolist()
num_labels = len(categories)
id2label = {i: label for i, label in enumerate(categories)}

from datasets import Dataset, DatasetDict
from sklearn.model_selection import train_test_split

ds = Dataset.from_pandas(df[['full_text', 'label', 'subjects']])
ds = ds.train_test_split(test_size=0.1, seed=42)

# @title Load model
import torch
from transformers import AutoTokenizer, BertForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
model = BertForSequenceClassification.from_pretrained(
    "google-bert/bert-base-uncased", num_labels=num_labels, problem_type="single_label_classification"
)

def preprocess_function(examples):
    column_name = "full_text"
    texts = [str(t) if t is not None else "" for t in examples[column_name]]
    return tokenizer(
        texts,
        truncation=True,
        max_length=256,
        padding=False
    )

from transformers import DataCollatorWithPadding

tokenized_ds = ds.map(preprocess_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

"""# Custom Trainer --- Contrastive Loss"""

import torch.nn.functional as F
from transformers import TrainingArguments, Trainer

class ContrastiveTrainer(Trainer):
    def __init__(self, *args, contrastive_alpha=0.01, temperature=0.1, **kwargs):
        super().__init__(*args, **kwargs)
        self.contrastive_alpha = contrastive_alpha
        self.temperature = temperature

    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")

        outputs = model(**inputs, output_hidden_states=True)
        logits = outputs.get("logits")

        loss_fct = torch.nn.CrossEntropyLoss()
        classification_loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))

        embeddings = outputs.hidden_states[-1][:, 0, :]

        embeddings = F.normalize(embeddings, p=2, dim=1)

        similarity_matrix = torch.matmul(embeddings, embeddings.T) / self.temperature

        labels = labels.view(-1, 1)
        mask = torch.eq(labels, labels.T).float().to(self.args.device)

        mask = mask - torch.eye(mask.shape[0]).to(self.args.device)

        exp_sim = torch.exp(similarity_matrix) * (1 - torch.eye(mask.shape[0]).to(self.args.device))
        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-5)

        mean_log_prob_pos = (mask * log_prob).sum(dim=1) / (mask.sum(dim=1) + 1e-5)
        contrastive_loss = -mean_log_prob_pos.mean()

        total_loss = classification_loss + (self.contrastive_alpha * contrastive_loss)

        return (total_loss, outputs) if return_outputs else total_loss

"""# LoRA"""

!pip install -q peft transformers datasets evaluate accelerate

from peft import LoraConfig, get_peft_model, TaskType

peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    r=16, lora_alpha=16, lora_dropout=0.1,
    target_modules=["query", "value"]
)
model = get_peft_model(model, peft_config)

"""# Training arguments"""

from transformers import TrainingArguments, Trainer, EarlyStoppingCallback

training_args = TrainingArguments(
    output_dir="./bert-contrastive-lora",
    learning_rate=2e-4,
    per_device_train_batch_size=64,
    num_train_epochs=15,
    eval_strategy="epoch",
    save_strategy="epoch",
    fp16=False,
    load_best_model_at_end=True,
    metric_for_best_model='eval_loss',
    greater_is_better=False
)

"""# Train"""

trainer = ContrastiveTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_ds["train"],
    eval_dataset=tokenized_ds["test"],
    data_collator=data_collator,
    contrastive_alpha=0.05,
    temperature=0.07,
    callbacks=[EarlyStoppingCallback(
        early_stopping_patience=3,
        early_stopping_threshold=0.001
    )]
)

trainer.train()

"""# Evaluation"""

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

def collate_fn(batch):
    return {
        'input_ids': torch.tensor([item['input_ids'] for item in batch]),
        'attention_mask': torch.tensor([item['attention_mask'] for item in batch]),
        'labels': torch.tensor([item['label'] for item in batch])
    }

def plot_results(model, dataset, title="BERT Contrastive"):
    model.eval()
    predictions, references = [], []


    full_label_names = df['subjects'].astype('category').cat.categories.tolist()

    test_loader = torch.utils.data.DataLoader(
        dataset,
        batch_size=16,
        collate_fn=collate_fn
    )

    for batch in tqdm(test_loader, desc=f"Оценка {title}"):
        inputs = {k: v.to("cuda") for k, v in batch.items() if k != 'labels'}
        labels = batch['labels'].to("cuda")

        with torch.no_grad():
            logits = model(**inputs).logits
            predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())
            references.extend(labels.cpu().numpy())

    if not references or not predictions:
        print("Ошибка: Списки предсказаний или реальных меток пусты. Нечего оценивать.")
        return

    present_labels = np.unique(np.concatenate([references, predictions]))

    valid_present_labels = [lbl for lbl in present_labels if lbl < len(full_label_names)]

    if not valid_present_labels:
        print("Ошибка: Нет допустимых меток для оценки.")
        return

    present_names = [full_label_names[i] for i in valid_present_labels]

    print(f"n--- Отчет для {title} ---")
    print(classification_report(
        references,
        predictions,
        labels=valid_present_labels,
        target_names=present_names,
        zero_division=0
    ))

    cm = confusion_matrix(references, predictions, labels=valid_present_labels)

    plt.figure(figsize=(15, 12))
    show_labels = True if len(valid_present_labels) < 50 else False

    sns.heatmap(
        cm,
        annot=False,
        fmt='d',
        cmap='Purples',
        xticklabels=present_names if show_labels else False,
        yticklabels=present_names if show_labels else False
    )

    plt.title(f'Confusion Matrix: {title}n(Отображено классов: {len(valid_present_labels)})')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.tight_layout()
    plt.show()

plot_results(model, tokenized_ds["test"], title="BERT + LoRA + Contrastive")

import os

"""# Saving model

Смотерела разные варианты сохранений
"""

#from huggingface_hub import notebook_login

#account = <your-hf-account-name>
#peft_model_id = f"{account}/bloomz-560-m-peft-method"
#model.push_to_hub(peft_model_id)

#import shutil

#shutil.copytree("./bert_contrastive_model", "/content/drive/MyDrive/my_bert_model")

import json

#save_directory = "./bert_contrastive_model"

save_directory = "/content/drive/MyDrive/my_bert_model"

if not os.path.exists(save_directory):
    os.makedirs(save_directory)

model.save_pretrained(save_directory)
tokenizer.save_pretrained(save_directory)

categories = df['subjects'].astype('category').cat.categories
id2label = {i: label for i, label in enumerate(categories)}
label2id = {label: i for i, label in enumerate(categories)}

with open(os.path.join(save_directory, "label_config.json"), "w") as f:
    json.dump({"id2label": id2label, "label2id": label2id}, f)

"""# Inference"""

from peft import PeftModel, PeftConfig

def load_model_for_inference(model_path):
    with open(f"{model_path}/label_config.json", "r") as f:
        config_data = json.load(f)
        id2label = config_data["id2label"]

    config = PeftConfig.from_pretrained(model_path)
    base_model = BertForSequenceClassification.from_pretrained(
        config.base_model_name_or_path,
        num_labels=len(id2label)
    )

    model = PeftModel.from_pretrained(base_model, model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)

    model.to("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    return model, tokenizer, id2label


model_path = "/content/drive/MyDrive/my_bert_model"
inf_model, inf_tokenizer, id_map = load_model_for_inference(model_path)

def predict_category(text):
    inputs = inf_tokenizer(text, return_tensors="pt", truncation=True, max_length=256).to(inf_model.device)

    with torch.no_grad():
        logits = inf_model(**inputs).logits
        prediction = torch.argmax(logits, dim=-1).item()

    return id_map[str(prediction)]

new_paper = "Recent advancements in large language models (LLMs) have prompted interest in deploying these models on mobile devices to enable new applications without relying on cloud connectivity. However, the efficiency constraints of deploying LLMs on resource-limited devices present significant challenges. In this paper, we conduct a comprehensive measurement study to evaluate the efficiency tradeoffs between mobile-based, edge-based, and cloud-based deployments for LLM applications." #поменять текст
print(f"Предсказанная категория: {predict_category(new_paper)}")